{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import sys\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from matplotlib import colors\n",
    "from scipy.stats import mannwhitneyu, wilcoxon\n",
    "from sklearn.metrics import auc, roc_curve\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from scipy.stats import spearmanr\n",
    "\n",
    "sys.path.append(r'H:/anthony/repos/NWB_analysis')\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "from nwb_wrappers import nwb_reader_functions as nwb_read\n",
    "import src.utils.utils_imaging as imaging_utils\n",
    "import src.utils.utils_io as io\n",
    "from src.behavior import compute_performance, plot_single_session\n",
    "import warnings\n",
    "\n",
    "# Set plot parameters.\n",
    "plt.rcParams['pdf.fonttype'] = 42\n",
    "plt.rcParams['ps.fonttype'] = 42\n",
    "plt.rcParams['svg.fonttype'] = 'none'\n",
    "sns.set_theme(context='paper', style='ticks', palette='deep', font='sans-serif', font_scale=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to the directory containing the processed data.\n",
    "processed_dir = r\"//sv-nas1.rcp.epfl.ch/Petersen-Lab/analysis/Anthony_Renard/data_processed/mice\"\n",
    "nwb_dir = r\"//sv-nas1.rcp.epfl.ch/Petersen-Lab/analysis/Anthony_Renard/NWB\"\n",
    "\n",
    "# Session metadata file.\n",
    "db_path = r\"//sv-nas1.rcp.epfl.ch/Petersen-Lab/analysis/Anthony_Renard/mice_info/session_metadata.xlsx\"\n",
    "\n",
    "# # Rewarded and non-rewarded NWB files.\n",
    "# group_yaml_rew = r\"//sv-nas1.rcp.epfl.ch/Petersen-Lab/analysis/Anthony_Renard/mice_info/groups/imaging_rewarded.yaml\"\n",
    "# group_yaml_non_rew = r\"//sv-nas1.rcp.epfl.ch/Petersen-Lab/analysis/Anthony_Renard/mice_info/groups/imaging_non_rewarded.yaml\"\n",
    "# nwb_list_rew = io.read_group_yaml(group_yaml_rew)\n",
    "# nwb_list_non_rew = io.read_group_yaml(group_yaml_non_rew)\n",
    "# nwb_list = nwb_list_rew + nwb_list_non_rew"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Response to sensory mapping trials across learning\n",
    "\n",
    "Here I look at the evolution of the response of the population across learning day. This is computed on the 50 whisker stimulation presentated at the end of each session after disengagement.\n",
    "\n",
    "- PSTH\n",
    "- amplitude of the population response\n",
    "- number of responsive neurons\n",
    "- stability of the response\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1. Responses to unmotivated mapping trials across learning days.\n",
    "\n",
    "- Amplitude of the response\n",
    "- Number of significant cells\n",
    "- variance across days\n",
    "- dimensionality across days\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['GF305', 'GF306', 'GF307', 'GF308', 'GF310', 'GF311', 'GF313', 'GF314', 'GF317', 'GF318', 'GF319', 'GF323', 'GF333', 'GF334', 'GF348', 'GF350', 'MI062', 'MI069', 'MI072', 'MI075', 'MI076', 'AR132', 'AR133', 'AR135', 'AR137', 'AR139', 'AR127', 'AR131', 'AR143', 'AR144']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load data needed to compute before and after learning.\n",
    "\n",
    "sampling_rate = 30\n",
    "win = (1, 1.3)  # from stimulus onset to 300 ms after.\n",
    "win = (int(win[0] * sampling_rate), int(win[1] * sampling_rate))\n",
    "baseline_win = (0, 1)\n",
    "baseline_win = (int(baseline_win[0] * sampling_rate), int(baseline_win[1] * sampling_rate))\n",
    "days = ['-2', '-1', '0', '+1', '+2']\n",
    "# Correlation matrix for a specific cell type\n",
    "cell_type = None\n",
    "variance_explained_thr = 0.7\n",
    "\n",
    "_, _, mice, _ = io.select_sessions_from_db(db_path,\n",
    "                                            nwb_dir,\n",
    "                                            two_p_imaging='yes')\n",
    "print(mice)\n",
    "len(mice)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['GF305_27112020_083119', 'GF305_28112020_103938', 'GF305_29112020_103331', 'GF305_30112020_110255', 'GF305_02122020_132229']\n",
      "['GF306_27112020_104436', 'GF306_28112020_125555', 'GF306_29112020_131929', 'GF306_30112020_133249', 'GF306_02122020_161611']\n",
      "['GF308_17112020_105052', 'GF308_18112020_093627', 'GF308_19112020_103527', 'GF308_20112020_122826', 'GF308_21112020_135515']\n",
      "['GF311_17112020_155501', 'GF311_18112020_151838', 'GF311_19112020_160412', 'GF311_20112020_171609', 'GF311_21112020_180049']\n",
      "['GF313_27112020_141857', 'GF313_28112020_154236', 'GF313_29112020_154625', 'GF313_30112020_154904', 'GF313_03122020_082147']\n",
      "['GF314_27112020_160459', 'GF314_28112020_171800', 'GF314_29112020_174831', 'GF314_30112020_171906', 'GF314_03122020_102249']\n",
      "['GF317_15122020_081931', 'GF317_16122020_082007', 'GF317_17122020_080715', 'GF317_18122020_104834', 'GF317_20122020_120604']\n",
      "['GF318_15122020_095616', 'GF318_16122020_095516', 'GF318_17122020_144100', 'GF318_18122020_132105', 'GF318_19122020_155806']\n",
      "['GF319_24122020_120204', 'GF319_25122020_142951', 'GF319_26122020_144746', 'GF319_27122020_135842', 'GF319_28122020_132438']\n",
      "['GF323_07012021_092005', 'GF323_08012021_083725', 'GF323_09012021_111716', 'GF323_11012021_084126', 'GF323_12012021_090219']\n",
      "['GF334_21012021_160130', 'GF334_22012021_153815', 'GF334_24012021_173019', 'GF334_25012021_163843', 'GF334_26012021_171010']\n",
      "['GF348_29052021_100151', 'GF348_30052021_110107', 'GF348_31052021_102411', 'GF348_01062021_095758', 'GF348_02062021_084344']\n",
      "['GF350_29052021_124022', 'GF350_30052021_123155', 'GF350_31052021_135001', 'GF350_01062021_122420', 'GF350_02062021_142138']\n",
      "['MI062_30092021_091006', 'MI062_01102021_091233', 'MI062_02102021_105027', 'MI062_03102021_103851', 'MI062_04102021_092339']\n",
      "['MI069_19122021_100830', 'MI069_20122021_095058', 'MI069_21122021_090648', 'MI069_22122021_090212', 'MI069_23122021_085758']\n",
      "['MI072_19122021_140553', 'MI072_20122021_125805', 'MI072_21122021_132704', 'MI072_22122021_132651', 'MI072_23122021_132111']\n",
      "['MI075_19122021_152533', 'MI075_20122021_155245', 'MI075_21122021_151949', 'MI075_22122021_152806', 'MI075_23122021_150004']\n",
      "['MI076_19122021_120004', 'MI076_20122021_113038', 'MI076_21122021_112146', 'MI076_22122021_114039', 'MI076_23122021_113818']\n",
      "['AR132_20240424_112338', 'AR132_20240425_102625', 'AR132_20240426_093953', 'AR132_20240427_122605', 'AR132_20240428_122206']\n",
      "['AR133_20240424_130306', 'AR133_20240425_115233', 'AR133_20240426_113430', 'AR133_20240427_142253', 'AR133_20240428_134911']\n",
      "['AR137_20240424_172627', 'AR137_20240425_170755', 'AR137_20240426_152510', 'AR137_20240427_171535', 'AR137_20240428_163224']\n",
      "['AR139_20240424_185913', 'AR139_20240425_181627', 'AR139_20240426_165725', 'AR139_20240427_183701', 'AR139_20240428_180459']\n",
      "['AR127_20240221_133407', 'AR127_20240222_152629', 'AR127_20240223_131820', 'AR127_20240224_140853', 'AR127_20240225_142858']\n",
      "['AR131_20240301_145952', 'AR131_20240302_123034', 'AR131_20240303_171032', 'AR131_20240304_133332', 'AR131_20240305_140141']\n",
      "['AR143_20240518_174556', 'AR143_20240519_141725', 'AR143_20240520_130137', 'AR143_20240521_125833', 'AR143_20240522_172846']\n"
     ]
    }
   ],
   "source": [
    "average_response = {}\n",
    "responsive_p_values = {}\n",
    "std = {}\n",
    "dimensionality = {}\n",
    "metadata = {}\n",
    "\n",
    "for mouse_id in mice:\n",
    "    # Disregard these mice as the number of trials is too low.\n",
    "    if mouse_id in ['GF307', 'GF310', 'GF333', 'AR144', 'AR135']:\n",
    "        continue\n",
    "    session_list, nwb_files, _, db_filtered = io.select_sessions_from_db(db_path,\n",
    "                                                                        nwb_dir,\n",
    "                                                                        two_p_imaging='yes',\n",
    "                                                                        subject_id=mouse_id,\n",
    "                                                                        day=days,)\n",
    "    print(session_list)\n",
    "\n",
    "    data = []\n",
    "    mdata_list = []\n",
    "    for session_id in session_list:\n",
    "        arr, mdata = imaging_utils.load_session_2p_imaging(mouse_id,\n",
    "                                                            session_id,\n",
    "                                                            processed_dir)\n",
    "        arr = imaging_utils.substract_baseline(arr, 3, baseline_win)\n",
    "        data.append(arr)\n",
    "        mdata_list.append(mdata)\n",
    "\n",
    "    # Extract UM trials.\n",
    "    for i, arr in enumerate(data):\n",
    "        arr = imaging_utils.extract_trials(arr, mdata_list[i], 'UM', n_trials=None)\n",
    "        data[i] = arr\n",
    "\n",
    "    # # Select UM trials.\n",
    "    # data = [arr[:, -1] for arr in data]\n",
    "    # # Remove trials with NaNs.\n",
    "    # data = [arr[:, ~np.isnan(arr).all(axis=(0,2))] for arr in data]\n",
    "\n",
    "    # Select cell type.\n",
    "    if cell_type:\n",
    "        cell_type_mask = mdata['cell_types']==cell_type\n",
    "        data = [arr[cell_type_mask] for arr in data]\n",
    "\n",
    "    # Get some metadata.\n",
    "    reward_group = io.get_reward_group_from_db(db_path, session_list[0])\n",
    "    metadata[mouse_id] = {}\n",
    "    metadata[mouse_id]['reward_group'] = reward_group\n",
    "    metadata[mouse_id]['cell_types'] = mdata['cell_types']\n",
    "\n",
    "\n",
    "    # Compute average response for each trial, each day.\n",
    "    # --------------------------------------------------\n",
    "\n",
    "    average_response[mouse_id] = []\n",
    "    for day in data:\n",
    "        average_response[mouse_id].append(np.nanmean(day[:, :, win[0]:win[1]], axis=2))\n",
    "\n",
    "\n",
    "    # Compute standard deviation of population response.\n",
    "    # ----------------------------------------------------  \n",
    "\n",
    "    std[mouse_id] = []\n",
    "    for day in data:\n",
    "        std[mouse_id].append(np.std(np.nanmean(day[:, :, win[0]:win[1]], axis=2), axis=0))\n",
    "\n",
    "\n",
    "    # Test responsiveness.\n",
    "    # --------------------\n",
    "\n",
    "    baseline_avg = []\n",
    "    response_avg = []\n",
    "    for day in data:\n",
    "        baseline_avg.append(np.nanmean(day[:, :, baseline_win[0]:baseline_win[1]], axis=2))\n",
    "        response_avg.append(np.nanmean(day[:, :, win[0]:win[1]], axis=2))\n",
    "\n",
    "    # Compare response amplitude to baseline.\n",
    "    n_cells = data[0].shape[0]\n",
    "    p_values = [np.zeros(n_cells) for _ in range(len(data))]\n",
    "    for iday, day in enumerate(data):\n",
    "        for icell in range(n_cells):\n",
    "            _, p_values[iday][icell] = wilcoxon(baseline_avg[iday][icell], response_avg[iday][icell])\n",
    "    p_values = np.stack(p_values, axis=0)\n",
    "    responsive_p_values[mouse_id] = p_values\n",
    "\n",
    "\n",
    "    # Compute dimensionality of the population response.\n",
    "    # --------------------------------------------------\n",
    "\n",
    "    dimensionality[mouse_id] = []\n",
    "    pca_results = []\n",
    "    for day in data:\n",
    "        X = np.mean(day[:,:,win[0]:win[1]], axis=2)\n",
    "        X = X.T\n",
    "        X = StandardScaler(with_mean=True, with_std=True).fit_transform(X)\n",
    "        pca = PCA()\n",
    "        model = pca.fit(X)\n",
    "        n_comp = np.sum(model.explained_variance_ratio_.cumsum() < variance_explained_thr) + 1\n",
    "        dimensionality[mouse_id].append(n_comp)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert to pandas and plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "mouse_ids = average_response.keys()\n",
    "\n",
    "df = []\n",
    "for mouse_id in mouse_ids:\n",
    "    for iday in range(len(days)):\n",
    "        amp = np.nanmean(np.nanmean(average_response[mouse_id][iday], axis=1), axis=0) * 100\n",
    "        s = np.mean(std[mouse_id][iday])\n",
    "        n_resp_05 = np.sum(responsive_p_values[mouse_id][iday] <= 0.05) / responsive_p_values[mouse_id][iday].size * 100\n",
    "        n_resp_01 = np.sum(responsive_p_values[mouse_id][iday] <= 0.01) / responsive_p_values[mouse_id][iday].size * 100\n",
    "        dim = dimensionality[mouse_id][iday]\n",
    "        temp = pd.DataFrame([[amp, s, n_resp_05, n_resp_01, dim, days[iday], mouse_id, metadata[mouse_id]['reward_group']]],\n",
    "                            columns=['population_response', 'population_std', 'n_responsive_thr_0.05', 'n_responsive_thr_0.01', 'dimensionality', 'day', 'mouse_id', 'reward_group'])\n",
    "        df.append(temp)\n",
    "df = pd.concat(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aprenard\\AppData\\Local\\Temp\\ipykernel_20692\\3808517441.py:9: MatplotlibDeprecationWarning: Keeping empty pdf files is deprecated since 3.8 and support will be removed in 3.10.\n",
      "  with PdfPages(os.path.join(output_dir, pdf_file)) as pdf:\n"
     ]
    }
   ],
   "source": [
    "output_dir = r'//sv-nas1.rcp.epfl.ch/Petersen-Lab/analysis/Anthony_Renard/analysis_output/sensory_plasticity'\n",
    "if cell_type:\n",
    "    pdf_file = f'responses_across_learning_{cell_type}.pdf'\n",
    "    df_file = f'responses_across_learning_{cell_type}.csv'\n",
    "else:\n",
    "    pdf_file = f'responses_across_learning.pdf'\n",
    "    df_file = f'responses_across_learning.csv'\n",
    "\n",
    "with PdfPages(os.path.join(output_dir, pdf_file)) as pdf:\n",
    "    sns.set_theme(context='talk', style='ticks', palette='deep', font='sans-serif', font_scale=1)\n",
    "    palette = sns.color_palette(['#238443', '#d51a1c'])\n",
    "\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(10, 6), sharex=True)\n",
    "    sns.boxplot(data=df, x='day', y='population_response', hue='reward_group',\n",
    "                ax=axes[0,0], legend=False, hue_order=['R+', 'R-'], palette=palette)\n",
    "    axes[0,0].set_title('Amplitude')\n",
    "    axes[0,0].set_ylabel(r'% dF/F')\n",
    "    axes[0,0].set_ylim([0, 6])\n",
    "\n",
    "    sns.barplot(data=df, x='day', y='population_std', hue='reward_group',\n",
    "                ax=axes[0,1], legend=False, hue_order=['R+', 'R-'], palette=palette)\n",
    "    axes[0,1].set_title('Population variability')\n",
    "    axes[0,1].set_ylabel(r'Standard deviation')\n",
    "    axes[0,1].set_ylim([0, 0.2])\n",
    "\n",
    "    sns.barplot(data=df, x='day', y='dimensionality', hue='reward_group',\n",
    "                ax=axes[1,0], legend=False, hue_order=['R+', 'R-'], palette=palette)\n",
    "    axes[1,0].set_title('Dimensionality')\n",
    "    axes[1,0].set_ylabel('# PCs')\n",
    "    axes[1,0].set_ylim([0, 40])\n",
    "\n",
    "    sns.barplot(data=df, x='day', y='n_responsive_thr_0.01', hue='reward_group',\n",
    "                ax=axes[1,1], hue_order=['R+', 'R-'], palette=palette)\n",
    "    axes[1,1].set_title(r'% responsive cells (p<0.01)')\n",
    "    axes[1,1].set_ylabel(r'% responsive')\n",
    "    axes[1,1].set_ylim([0, 50])\n",
    "\n",
    "    sns.despine()\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # pdf.savefig(fig, dpi=300)\n",
    "    # df.to_csv(os.path.join(output_dir, df_file), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2. Correlation matrices and responsive similarity across learning.\n",
    "\n",
    "Start with making a correlation matrix for each mouse and cell type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['GF305', 'GF306', 'GF307', 'GF308', 'GF310', 'GF311', 'GF313', 'GF314', 'GF317', 'GF318', 'GF319', 'GF323', 'GF333', 'GF334', 'GF348', 'GF350', 'MI062', 'MI069', 'MI072', 'MI075', 'MI076', 'AR132', 'AR133', 'AR135', 'AR137', 'AR139', 'AR127', 'AR131', 'AR143', 'AR144']\n"
     ]
    }
   ],
   "source": [
    "# Load data needed to compute before and after learning.\n",
    "\n",
    "sampling_rate = 30\n",
    "win = (1, 1.3)  # from stimulus onset to 300 ms after.\n",
    "win = (int(win[0] * sampling_rate), int(win[1] * sampling_rate))\n",
    "baseline_win = (0, 1)\n",
    "baseline_win = (int(baseline_win[0] * sampling_rate), int(baseline_win[1] * sampling_rate))\n",
    "days = ['-2', '-1', '0', '+1', '+2']\n",
    "\n",
    "_, _, mice, _ = io.select_sessions_from_db(db_path,\n",
    "                                            nwb_dir,\n",
    "                                            two_p_imaging='yes')\n",
    "print(mice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['AR127_20240221_133407', 'AR127_20240222_152629', 'AR127_20240223_131820', 'AR127_20240224_140853', 'AR127_20240225_142858']\n"
     ]
    }
   ],
   "source": [
    "corr_avg_days = {}\n",
    "corr_avg_pre_post = {}\n",
    "metadata = {}\n",
    "pop_vectors_dict = {}\n",
    "lmi = {}\n",
    "\n",
    "mice = ['AR127']\n",
    "\n",
    "for mouse_id in mice:\n",
    "    output_dir = fr'//sv-nas1.rcp.epfl.ch/Petersen-Lab/analysis/Anthony_Renard/analysis_output/mice/{mouse_id}'\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "\n",
    "    session_list, nwb_files, _, db_filtered = io.select_sessions_from_db(db_path,\n",
    "                                                                        nwb_dir,\n",
    "                                                                        two_p_imaging='yes',\n",
    "                                                                        subject_id=mouse_id,\n",
    "                                                                        day=days,)\n",
    "    print(session_list)\n",
    "    \n",
    "    data = []\n",
    "    mdata_list = []\n",
    "    for session_id in session_list:\n",
    "        arr, mdata = imaging_utils.load_session_2p_imaging(mouse_id,\n",
    "                                                            session_id,\n",
    "                                                            processed_dir)\n",
    "        arr = imaging_utils.substract_baseline(arr, 3, baseline_win)\n",
    "        data.append(arr)\n",
    "        mdata_list.append(mdata)\n",
    "    reward_group = io.get_reward_group_from_db(db_path, session_list[0])\n",
    "    metadata[mouse_id] = {}\n",
    "    metadata[mouse_id]['reward_group'] = reward_group\n",
    "    \n",
    "    # Extract UM trials.\n",
    "    for i, arr in enumerate(data):\n",
    "        arr = imaging_utils.extract_trials(arr, mdata_list[i], 'UM', n_trials=None)\n",
    "        data[i] = arr\n",
    "\n",
    "    corr_avg_days[mouse_id] = {}\n",
    "    corr_avg_pre_post[mouse_id] = {}\n",
    "    pop_vectors_dict[mouse_id] = {}\n",
    "    \n",
    "    for cell_type in ['allcells', 'wS2', 'wM1']:\n",
    "        # Select cell type.\n",
    "        if cell_type == 'allcells':\n",
    "            data_subtype = data\n",
    "        else:\n",
    "            data_subtype = []\n",
    "            cell_type_mask = mdata_list[0]['cell_types']==cell_type\n",
    "            data_subtype = [arr[cell_type_mask] for arr in data]\n",
    "\n",
    "        # strong_cells = [3,11,33,48,57,67,80,86,104,153,166,175]\n",
    "        # mask = np.ones(data_subtype[0].shape[0], dtype=bool)\n",
    "        # mask[strong_cells] = False\n",
    "        # data_subtype = [arr[mask] for arr in data_subtype]\n",
    "\n",
    "        # If no cells of the specified type, skip.\n",
    "        if data_subtype[0].shape[0] == 0:\n",
    "            continue\n",
    "\n",
    "        # Compute average response for each trial, each day.\n",
    "        \n",
    "        response_avg = []\n",
    "        for day in data_subtype:\n",
    "            response_avg.append(np.nanmean(day[:, :, win[0]:win[1]], axis=2))\n",
    "\n",
    "        pop_vectors = np.concatenate(response_avg, axis=1)\n",
    "        pop_vectors_dict[mouse_id][cell_type] = pop_vectors\n",
    "\n",
    "        # Compute LMI.\n",
    "        if cell_type == 'allcells':\n",
    "            # pre = np.mean(np.concatenate(response_avg[0:2], axis=1), axis=1)\n",
    "            # print(pre.shape)\n",
    "            # post = np.mean(np.concatenate((response_avg[5], response_avg[7]), axis=1), axis=1)\n",
    "            # lmi[mouse_id] = (post - pre) / (np.abs(post) + np.abs(pre))\n",
    "            lmis = []\n",
    "            for icell in range(pop_vectors.shape[0]):\n",
    "                # mapping trials of D-2, D-1, D+1, D+2.\n",
    "                X = np.r_[response_avg[0][icell], response_avg[1][icell],\n",
    "                          response_avg[3][icell], response_avg[4][icell]]\n",
    "                y = np.r_[np.zeros(response_avg[0][icell].shape[0]),\n",
    "                          np.zeros(response_avg[1][icell].shape[0]),\n",
    "                          np.ones(response_avg[3][icell].shape[0]),\n",
    "                          np.ones(response_avg[4][icell].shape[0])]\n",
    "                fpr, tpr, _ = roc_curve(y, X)\n",
    "                roc_auc = auc(fpr, tpr)\n",
    "                lmis.append((roc_auc - 0.5) * 2)\n",
    "            lmi[mouse_id] = np.array(lmis)\n",
    "        \n",
    "        corr_matrix = np.corrcoef(pop_vectors.T)\n",
    "        # corr_matrix = cosine_similarity(pop_vectors.T)\n",
    "        # corr_matrix = spearmanr(pop_vectors.T, axis=1)[0]\n",
    "\n",
    "        # Compute average correlation inside each days.\n",
    "        corr_avg_days[mouse_id][cell_type] = []\n",
    "        n_trials = [arr.shape[1] for arr in data_subtype]\n",
    "        for start, end in zip(np.cumsum([0] + n_trials[:-1]), np.cumsum(n_trials)):\n",
    "            upper_triangle = np.triu(corr_matrix[start:end, start:end], k=1)\n",
    "            corr_avg_days[mouse_id][cell_type].append(np.mean(upper_triangle))\n",
    "\n",
    "        # Compare correlation between inside pre training days,\n",
    "        # inside post training days and between pre and post training days.\n",
    "        trial_cumsum = np.cumsum([0] + n_trials)\n",
    "        pre_in_start_x, pre_in_end_x = trial_cumsum[1], trial_cumsum[2]\n",
    "        pre_in_start_y, pre_in_end_y = trial_cumsum[0], trial_cumsum[1]\n",
    "        pre_in = np.mean(corr_matrix[pre_in_start_x:pre_in_end_x, pre_in_start_y:pre_in_end_y])\n",
    "\n",
    "        post_in_start_x, post_in_end_x = trial_cumsum[4], trial_cumsum[5]\n",
    "        post_in_start_y, post_in_end_y = trial_cumsum[3], trial_cumsum[4]\n",
    "        post_in = np.mean(corr_matrix[post_in_start_x:post_in_end_x, post_in_start_y:post_in_end_y])\n",
    "\n",
    "        pre_post_start_x, pre_post_end_x = trial_cumsum[3], trial_cumsum[5]\n",
    "        pre_post_start_y, pre_post_end_y = trial_cumsum[0], trial_cumsum[2]\n",
    "        pre_post = np.mean(corr_matrix[pre_post_start_x:pre_post_end_x, pre_post_start_y:pre_post_end_y])\n",
    "\n",
    "        corr_avg_pre_post[mouse_id][cell_type] = [pre_in, post_in, pre_post]\n",
    "\n",
    "\n",
    "        # Plot population vectors.\n",
    "        pdf_file = f'pop_vectors_{mouse_id}_{cell_type}.pdf'\n",
    "        with PdfPages(os.path.join(output_dir, pdf_file)) as pdf:\n",
    "            vmax = np.percentile(pop_vectors, 99)\n",
    "            vmin = np.percentile(pop_vectors, 1)\n",
    "\n",
    "            f = plt.figure()\n",
    "            im = plt.imshow(pop_vectors, cmap='viridis', vmin=vmin, vmax=vmax)\n",
    "            cbar = f.colorbar(im, ticks=[vmin, 0, vmax])\n",
    "            cbar.ax.set_yticklabels([f'{vmin:.2f}', '0', f'> {vmax:.2f}'])\n",
    "            cbar.ax.tick_params(size=0)\n",
    "            pdf.savefig(dpi=300)\n",
    "            plt.close()\n",
    "\n",
    "        # Plot correlation matrix.\n",
    "        pdf_file = f'correlation_matrices_trial_{mouse_id}_{cell_type}.pdf'            \n",
    "        with PdfPages(os.path.join(output_dir, pdf_file)) as pdf:\n",
    "            \n",
    "            # Set color map limit to the max without the diagonal.\n",
    "            vmax = np.max(corr_matrix[~np.eye(corr_matrix.shape[0], dtype=bool)])\n",
    "            vmin = np.min(corr_matrix)\n",
    "            f = plt.figure()\n",
    "            im = plt.imshow(corr_matrix, vmin = vmin, vmax=vmax, cmap='viridis')\n",
    "            n_trials = [arr.shape[1] for arr in data_subtype]\n",
    "            for i in np.cumsum(n_trials)[:-1]:\n",
    "                plt.axvline(x=i-1, color='#252525', linestyle='-', lw=0.5)\n",
    "                plt.axhline(y=i-1, color='#252525', linestyle='-', lw=0.5)\n",
    "            if cell_type:\n",
    "                plt.title(f'{mouse_id} {reward_group} {cell_type}')\n",
    "            else:\n",
    "                plt.title(f'{mouse_id} {reward_group} all cells')\n",
    "            cbar_ax = f.add_axes([0.85, 0.15, 0.05, 0.7])\n",
    "            cbar = f.colorbar(im, cax=cbar_ax, ticks=[vmin, 0, vmax])\n",
    "            cbar.ax.set_yticklabels([f'{vmin:.2f}', '0', f'> {vmax:.2f}'])\n",
    "            cbar.ax.tick_params(size=0)\n",
    "            pdf.savefig(dpi=300)\n",
    "            plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot average correlation inside pre-training days, inside post-training days and between pre- and post- training.\n",
    "\n",
    "This is to see these two periods are two modes of activity that are more disimilar in the rewarded group.\n",
    "\n",
    "It seems that the only difference between R+ and R- is the correlation among post-learning days which is higher. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "mouse_ids = corr_avg_days.keys()\n",
    "\n",
    "df_corr_days = []\n",
    "for mouse_id in mouse_ids:\n",
    "    for cell_type in corr_avg_days[mouse_id].keys():\n",
    "        for iday in range(len(days)):\n",
    "            corr = corr_avg_days[mouse_id][cell_type][iday]\n",
    "            temp = pd.DataFrame([[corr, days[iday], cell_type, mouse_id, metadata[mouse_id]['reward_group']]],\n",
    "                                columns=['correlation','day', 'cell_type', 'mouse_id', 'reward_group'])\n",
    "            df_corr_days.append(temp)\n",
    "df_corr_days = pd.concat(df_corr_days)\n",
    "\n",
    "\n",
    "df_corr_pre_post = []\n",
    "for mouse_id in mouse_ids:\n",
    "    for cell_type in corr_avg_days[mouse_id].keys():\n",
    "        for i, comp in enumerate(['pre_in', 'post_in', 'pre_post']):\n",
    "            corr = corr_avg_pre_post[mouse_id][cell_type][i]\n",
    "            temp = pd.DataFrame([[corr, comp, cell_type, mouse_id, metadata[mouse_id]['reward_group']]],\n",
    "                                columns=['correlation', 'comparison', 'cell_type', 'mouse_id', 'reward_group'])\n",
    "            df_corr_pre_post.append(temp)\n",
    "df_corr_pre_post = pd.concat(df_corr_pre_post)\n",
    "\n",
    "\n",
    "palette = sns.color_palette(['#238443', '#d51a1c'])\n",
    "\n",
    "plt.figure()\n",
    "sns.barplot(data=df_corr_days.loc[df_corr_days.cell_type=='allcells'], x='day', y='correlation', hue='reward_group', palette=palette)\n",
    "\n",
    "plt.figure()\n",
    "sns.barplot(data=df_corr_pre_post.loc[df_corr_pre_post.cell_type=='allcells'], x='comparison', y='correlation', hue='reward_group')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the population vectors and lmi.\n",
    "\n",
    "This is to show that lmi select cells that go on and off as expected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.27537563 1.1496639\n"
     ]
    }
   ],
   "source": [
    "f, axes = plt.subplots(1, 2, sharey=True)\n",
    "im = axes[0].imshow(np.repeat(lmi[mouse_id][:, np.newaxis], 10, axis=1), cmap='viridis', vmin=-1, vmax=1)\n",
    "plt.colorbar(im)\n",
    "vmax = np.percentile(pop_vectors_dict[mouse_id]['allcells'], 99)\n",
    "vmin = np.percentile(pop_vectors_dict[mouse_id]['allcells'], 1)\n",
    "im = axes[1].imshow(pop_vectors_dict[mouse_id]['allcells'], cmap='viridis', vmin=vmin, vmax=vmax)\n",
    "plt.colorbar(im)\n",
    "print(vmin, vmax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot global matrix for the whole population."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data needed to compute before and after learning.\n",
    "\n",
    "sampling_rate = 30\n",
    "win = (1, 1.3)  # from stimulus onset to 300 ms after.\n",
    "win = (int(win[0] * sampling_rate), int(win[1] * sampling_rate))\n",
    "baseline_win = (0, 1)\n",
    "baseline_win = (int(baseline_win[0] * sampling_rate), int(baseline_win[1] * sampling_rate))\n",
    "days = ['-2', '-1', '0', '+1', '+2']\n",
    "\n",
    "# mice = ['GF323']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['GF305', 'GF306', 'GF307', 'GF308', 'GF310', 'GF311', 'GF313', 'GF314', 'GF317', 'GF318', 'GF323', 'GF333', 'GF334', 'AR133', 'AR135', 'AR127', 'AR143', 'AR144']\n",
      "GF305\n",
      "['GF305_27112020_083119', 'GF305_28112020_103938', 'GF305_29112020_103331', 'GF305_30112020_110255', 'GF305_02122020_132229']\n",
      "GF306\n",
      "['GF306_27112020_104436', 'GF306_28112020_125555', 'GF306_29112020_131929', 'GF306_30112020_133249', 'GF306_02122020_161611']\n",
      "GF307\n",
      "GF308\n",
      "['GF308_17112020_105052', 'GF308_18112020_093627', 'GF308_19112020_103527', 'GF308_20112020_122826', 'GF308_21112020_135515']\n",
      "GF310\n",
      "GF311\n",
      "['GF311_17112020_155501', 'GF311_18112020_151838', 'GF311_19112020_160412', 'GF311_20112020_171609', 'GF311_21112020_180049']\n",
      "GF313\n",
      "['GF313_27112020_141857', 'GF313_28112020_154236', 'GF313_29112020_154625', 'GF313_30112020_154904', 'GF313_03122020_082147']\n",
      "GF314\n",
      "['GF314_27112020_160459', 'GF314_28112020_171800', 'GF314_29112020_174831', 'GF314_30112020_171906', 'GF314_03122020_102249']\n",
      "GF317\n",
      "['GF317_15122020_081931', 'GF317_16122020_082007', 'GF317_17122020_080715', 'GF317_18122020_104834', 'GF317_20122020_120604']\n",
      "GF318\n",
      "['GF318_15122020_095616', 'GF318_16122020_095516', 'GF318_17122020_144100', 'GF318_18122020_132105', 'GF318_19122020_155806']\n",
      "GF323\n",
      "['GF323_07012021_092005', 'GF323_08012021_083725', 'GF323_09012021_111716', 'GF323_11012021_084126', 'GF323_12012021_090219']\n",
      "GF333\n",
      "GF334\n",
      "['GF334_21012021_160130', 'GF334_22012021_153815', 'GF334_24012021_173019', 'GF334_25012021_163843', 'GF334_26012021_171010']\n",
      "AR133\n",
      "['AR133_20240424_130306', 'AR133_20240425_115233', 'AR133_20240426_113430', 'AR133_20240427_142253', 'AR133_20240428_134911']\n",
      "AR135\n",
      "['AR135_20240424_160805', 'AR135_20240425_151948', 'AR135_20240426_133260', 'AR135_20240427_154417', 'AR135_20240428_150944']\n",
      "AR127\n",
      "['AR127_20240221_133407', 'AR127_20240222_152629', 'AR127_20240223_131820', 'AR127_20240224_140853', 'AR127_20240225_142858']\n",
      "AR143\n",
      "['AR143_20240518_174556', 'AR143_20240519_141725', 'AR143_20240520_130137', 'AR143_20240521_125833', 'AR143_20240522_172846']\n",
      "AR144\n",
      "['AR144_20240518_193553', 'AR144_20240519_151737', 'AR144_20240520_141104', 'AR144_20240521_142259', 'AR144_20240522_190834']\n",
      "[50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 49, 49, 50, 50]\n",
      "[50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 49, 50, 49, 50, 50]\n",
      "[50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50]\n",
      "[50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 49, 50, 50]\n",
      "[50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 49, 50, 49, 50, 47]\n",
      "['GF305', 'GF306', 'GF307', 'GF308', 'GF310', 'GF311', 'GF313', 'GF314', 'GF317', 'GF318', 'GF323', 'GF333', 'GF334', 'AR133', 'AR135', 'AR127', 'AR143', 'AR144']\n",
      "GF305\n",
      "['GF305_27112020_083119', 'GF305_28112020_103938', 'GF305_29112020_103331', 'GF305_30112020_110255', 'GF305_02122020_132229']\n",
      "GF306\n",
      "['GF306_27112020_104436', 'GF306_28112020_125555', 'GF306_29112020_131929', 'GF306_30112020_133249', 'GF306_02122020_161611']\n",
      "GF307\n",
      "GF308\n",
      "['GF308_17112020_105052', 'GF308_18112020_093627', 'GF308_19112020_103527', 'GF308_20112020_122826', 'GF308_21112020_135515']\n",
      "GF310\n",
      "GF311\n",
      "['GF311_17112020_155501', 'GF311_18112020_151838', 'GF311_19112020_160412', 'GF311_20112020_171609', 'GF311_21112020_180049']\n",
      "GF313\n",
      "['GF313_27112020_141857', 'GF313_28112020_154236', 'GF313_29112020_154625', 'GF313_30112020_154904', 'GF313_03122020_082147']\n",
      "GF314\n",
      "['GF314_27112020_160459', 'GF314_28112020_171800', 'GF314_29112020_174831', 'GF314_30112020_171906', 'GF314_03122020_102249']\n",
      "GF317\n",
      "['GF317_15122020_081931', 'GF317_16122020_082007', 'GF317_17122020_080715', 'GF317_18122020_104834', 'GF317_20122020_120604']\n",
      "GF318\n",
      "['GF318_15122020_095616', 'GF318_16122020_095516', 'GF318_17122020_144100', 'GF318_18122020_132105', 'GF318_19122020_155806']\n",
      "GF323\n",
      "['GF323_07012021_092005', 'GF323_08012021_083725', 'GF323_09012021_111716', 'GF323_11012021_084126', 'GF323_12012021_090219']\n",
      "GF333\n",
      "GF334\n",
      "['GF334_21012021_160130', 'GF334_22012021_153815', 'GF334_24012021_173019', 'GF334_25012021_163843', 'GF334_26012021_171010']\n",
      "AR133\n",
      "['AR133_20240424_130306', 'AR133_20240425_115233', 'AR133_20240426_113430', 'AR133_20240427_142253', 'AR133_20240428_134911']\n",
      "AR135\n",
      "['AR135_20240424_160805', 'AR135_20240425_151948', 'AR135_20240426_133260', 'AR135_20240427_154417', 'AR135_20240428_150944']\n",
      "AR127\n",
      "['AR127_20240221_133407', 'AR127_20240222_152629', 'AR127_20240223_131820', 'AR127_20240224_140853', 'AR127_20240225_142858']\n",
      "AR143\n",
      "['AR143_20240518_174556', 'AR143_20240519_141725', 'AR143_20240520_130137', 'AR143_20240521_125833', 'AR143_20240522_172846']\n",
      "AR144\n",
      "['AR144_20240518_193553', 'AR144_20240519_151737', 'AR144_20240520_141104', 'AR144_20240521_142259', 'AR144_20240522_190834']\n",
      "[50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 49, 49, 50, 50]\n",
      "[50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 49, 50, 49, 50, 50]\n",
      "[50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50]\n",
      "[50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 49, 50, 50]\n",
      "[50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 49, 50, 49, 50, 47]\n",
      "['GF305', 'GF306', 'GF307', 'GF308', 'GF310', 'GF311', 'GF313', 'GF314', 'GF317', 'GF318', 'GF323', 'GF333', 'GF334', 'AR133', 'AR135', 'AR127', 'AR143', 'AR144']\n",
      "GF305\n",
      "['GF305_27112020_083119', 'GF305_28112020_103938', 'GF305_29112020_103331', 'GF305_30112020_110255', 'GF305_02122020_132229']\n",
      "GF306\n",
      "['GF306_27112020_104436', 'GF306_28112020_125555', 'GF306_29112020_131929', 'GF306_30112020_133249', 'GF306_02122020_161611']\n",
      "GF307\n",
      "GF308\n",
      "['GF308_17112020_105052', 'GF308_18112020_093627', 'GF308_19112020_103527', 'GF308_20112020_122826', 'GF308_21112020_135515']\n",
      "GF310\n",
      "GF311\n",
      "['GF311_17112020_155501', 'GF311_18112020_151838', 'GF311_19112020_160412', 'GF311_20112020_171609', 'GF311_21112020_180049']\n",
      "GF313\n",
      "['GF313_27112020_141857', 'GF313_28112020_154236', 'GF313_29112020_154625', 'GF313_30112020_154904', 'GF313_03122020_082147']\n",
      "GF314\n",
      "['GF314_27112020_160459', 'GF314_28112020_171800', 'GF314_29112020_174831', 'GF314_30112020_171906', 'GF314_03122020_102249']\n",
      "GF317\n",
      "['GF317_15122020_081931', 'GF317_16122020_082007', 'GF317_17122020_080715', 'GF317_18122020_104834', 'GF317_20122020_120604']\n",
      "GF318\n",
      "['GF318_15122020_095616', 'GF318_16122020_095516', 'GF318_17122020_144100', 'GF318_18122020_132105', 'GF318_19122020_155806']\n",
      "GF323\n",
      "['GF323_07012021_092005', 'GF323_08012021_083725', 'GF323_09012021_111716', 'GF323_11012021_084126', 'GF323_12012021_090219']\n",
      "GF333\n",
      "GF334\n",
      "['GF334_21012021_160130', 'GF334_22012021_153815', 'GF334_24012021_173019', 'GF334_25012021_163843', 'GF334_26012021_171010']\n",
      "AR133\n",
      "['AR133_20240424_130306', 'AR133_20240425_115233', 'AR133_20240426_113430', 'AR133_20240427_142253', 'AR133_20240428_134911']\n",
      "AR135\n",
      "['AR135_20240424_160805', 'AR135_20240425_151948', 'AR135_20240426_133260', 'AR135_20240427_154417', 'AR135_20240428_150944']\n",
      "AR127\n",
      "['AR127_20240221_133407', 'AR127_20240222_152629', 'AR127_20240223_131820', 'AR127_20240224_140853', 'AR127_20240225_142858']\n",
      "AR143\n",
      "['AR143_20240518_174556', 'AR143_20240519_141725', 'AR143_20240520_130137', 'AR143_20240521_125833', 'AR143_20240522_172846']\n",
      "AR144\n",
      "['AR144_20240518_193553', 'AR144_20240519_151737', 'AR144_20240520_141104', 'AR144_20240521_142259', 'AR144_20240522_190834']\n",
      "[50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 49, 49, 50, 50]\n",
      "[50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 49, 50, 49, 50, 50]\n",
      "[50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50]\n",
      "[50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 49, 50, 50]\n",
      "[50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 49, 50, 49, 50, 47]\n",
      "['GF319', 'GF348', 'GF350', 'MI062', 'MI069', 'MI072', 'MI075', 'MI076', 'AR132', 'AR137', 'AR139', 'AR131']\n",
      "GF319\n",
      "['GF319_24122020_120204', 'GF319_25122020_142951', 'GF319_26122020_144746', 'GF319_27122020_135842', 'GF319_28122020_132438']\n",
      "GF348\n",
      "['GF348_29052021_100151', 'GF348_30052021_110107', 'GF348_31052021_102411', 'GF348_01062021_095758', 'GF348_02062021_084344']\n",
      "GF350\n",
      "['GF350_29052021_124022', 'GF350_30052021_123155', 'GF350_31052021_135001', 'GF350_01062021_122420', 'GF350_02062021_142138']\n",
      "MI062\n",
      "['MI062_30092021_091006', 'MI062_01102021_091233', 'MI062_02102021_105027', 'MI062_03102021_103851', 'MI062_04102021_092339']\n",
      "MI069\n",
      "['MI069_19122021_100830', 'MI069_20122021_095058', 'MI069_21122021_090648', 'MI069_22122021_090212', 'MI069_23122021_085758']\n",
      "MI072\n",
      "['MI072_19122021_140553', 'MI072_20122021_125805', 'MI072_21122021_132704', 'MI072_22122021_132651', 'MI072_23122021_132111']\n",
      "MI075\n",
      "MI076\n",
      "['MI076_19122021_120004', 'MI076_20122021_113038', 'MI076_21122021_112146', 'MI076_22122021_114039', 'MI076_23122021_113818']\n",
      "AR132\n",
      "['AR132_20240424_112338', 'AR132_20240425_102625', 'AR132_20240426_093953', 'AR132_20240427_122605', 'AR132_20240428_122206']\n",
      "AR137\n",
      "['AR137_20240424_172627', 'AR137_20240425_170755', 'AR137_20240426_152510', 'AR137_20240427_171535', 'AR137_20240428_163224']\n",
      "AR139\n",
      "['AR139_20240424_185913', 'AR139_20240425_181627', 'AR139_20240426_165725', 'AR139_20240427_183701', 'AR139_20240428_180459']\n",
      "AR131\n",
      "['AR131_20240301_145952', 'AR131_20240302_123034', 'AR131_20240303_171032', 'AR131_20240304_133332', 'AR131_20240305_140141']\n",
      "[50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50]\n",
      "[50, 50, 50, 50, 50, 50, 50, 50, 49, 50, 50]\n",
      "[50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50]\n",
      "[50, 50, 50, 50, 50, 50, 50, 51, 50, 50, 49]\n",
      "[50, 50, 50, 50, 50, 50, 50, 50, 50, 47, 50]\n",
      "['GF319', 'GF348', 'GF350', 'MI062', 'MI069', 'MI072', 'MI075', 'MI076', 'AR132', 'AR137', 'AR139', 'AR131']\n",
      "GF319\n",
      "['GF319_24122020_120204', 'GF319_25122020_142951', 'GF319_26122020_144746', 'GF319_27122020_135842', 'GF319_28122020_132438']\n",
      "GF348\n",
      "['GF348_29052021_100151', 'GF348_30052021_110107', 'GF348_31052021_102411', 'GF348_01062021_095758', 'GF348_02062021_084344']\n",
      "GF350\n",
      "['GF350_29052021_124022', 'GF350_30052021_123155', 'GF350_31052021_135001', 'GF350_01062021_122420', 'GF350_02062021_142138']\n",
      "MI062\n",
      "['MI062_30092021_091006', 'MI062_01102021_091233', 'MI062_02102021_105027', 'MI062_03102021_103851', 'MI062_04102021_092339']\n",
      "MI069\n",
      "['MI069_19122021_100830', 'MI069_20122021_095058', 'MI069_21122021_090648', 'MI069_22122021_090212', 'MI069_23122021_085758']\n",
      "MI072\n",
      "['MI072_19122021_140553', 'MI072_20122021_125805', 'MI072_21122021_132704', 'MI072_22122021_132651', 'MI072_23122021_132111']\n",
      "MI075\n",
      "MI076\n",
      "['MI076_19122021_120004', 'MI076_20122021_113038', 'MI076_21122021_112146', 'MI076_22122021_114039', 'MI076_23122021_113818']\n",
      "AR132\n",
      "['AR132_20240424_112338', 'AR132_20240425_102625', 'AR132_20240426_093953', 'AR132_20240427_122605', 'AR132_20240428_122206']\n",
      "AR137\n",
      "['AR137_20240424_172627', 'AR137_20240425_170755', 'AR137_20240426_152510', 'AR137_20240427_171535', 'AR137_20240428_163224']\n",
      "AR139\n",
      "['AR139_20240424_185913', 'AR139_20240425_181627', 'AR139_20240426_165725', 'AR139_20240427_183701', 'AR139_20240428_180459']\n",
      "AR131\n",
      "['AR131_20240301_145952', 'AR131_20240302_123034', 'AR131_20240303_171032', 'AR131_20240304_133332', 'AR131_20240305_140141']\n",
      "[50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50]\n",
      "[50, 50, 50, 50, 50, 50, 50, 50, 49, 50, 50]\n",
      "[50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50]\n",
      "[50, 50, 50, 50, 50, 50, 50, 51, 50, 50, 49]\n",
      "[50, 50, 50, 50, 50, 50, 50, 50, 50, 47, 50]\n",
      "['GF319', 'GF348', 'GF350', 'MI062', 'MI069', 'MI072', 'MI075', 'MI076', 'AR132', 'AR137', 'AR139', 'AR131']\n",
      "GF319\n",
      "['GF319_24122020_120204', 'GF319_25122020_142951', 'GF319_26122020_144746', 'GF319_27122020_135842', 'GF319_28122020_132438']\n",
      "GF348\n",
      "['GF348_29052021_100151', 'GF348_30052021_110107', 'GF348_31052021_102411', 'GF348_01062021_095758', 'GF348_02062021_084344']\n",
      "GF350\n",
      "['GF350_29052021_124022', 'GF350_30052021_123155', 'GF350_31052021_135001', 'GF350_01062021_122420', 'GF350_02062021_142138']\n",
      "MI062\n",
      "['MI062_30092021_091006', 'MI062_01102021_091233', 'MI062_02102021_105027', 'MI062_03102021_103851', 'MI062_04102021_092339']\n",
      "MI069\n",
      "['MI069_19122021_100830', 'MI069_20122021_095058', 'MI069_21122021_090648', 'MI069_22122021_090212', 'MI069_23122021_085758']\n",
      "MI072\n",
      "['MI072_19122021_140553', 'MI072_20122021_125805', 'MI072_21122021_132704', 'MI072_22122021_132651', 'MI072_23122021_132111']\n",
      "MI075\n",
      "MI076\n",
      "['MI076_19122021_120004', 'MI076_20122021_113038', 'MI076_21122021_112146', 'MI076_22122021_114039', 'MI076_23122021_113818']\n",
      "AR132\n",
      "['AR132_20240424_112338', 'AR132_20240425_102625', 'AR132_20240426_093953', 'AR132_20240427_122605', 'AR132_20240428_122206']\n",
      "AR137\n",
      "['AR137_20240424_172627', 'AR137_20240425_170755', 'AR137_20240426_152510', 'AR137_20240427_171535', 'AR137_20240428_163224']\n",
      "AR139\n",
      "['AR139_20240424_185913', 'AR139_20240425_181627', 'AR139_20240426_165725', 'AR139_20240427_183701', 'AR139_20240428_180459']\n",
      "AR131\n",
      "['AR131_20240301_145952', 'AR131_20240302_123034', 'AR131_20240303_171032', 'AR131_20240304_133332', 'AR131_20240305_140141']\n",
      "[50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50]\n",
      "[50, 50, 50, 50, 50, 50, 50, 50, 49, 50, 50]\n",
      "[50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50]\n",
      "[50, 50, 50, 50, 50, 50, 50, 51, 50, 50, 49]\n",
      "[50, 50, 50, 50, 50, 50, 50, 50, 50, 47, 50]\n"
     ]
    }
   ],
   "source": [
    "for reward_group in ['R+', 'R-']:\n",
    "    for cell_type in ['allcells', 'wS2', 'wM1']:\n",
    "        output_dir = r'//sv-nas1.rcp.epfl.ch/Petersen-Lab/analysis/Anthony_Renard/analysis_output/sensory_plasticity/correlation_matrices'\n",
    "        pdf_file = f'global_correlation_matrices_nobaselinesubstraction_{reward_group}_{cell_type}.pdf'\n",
    "\n",
    "        _, _, mice, _ = io.select_sessions_from_db(db_path,\n",
    "                                            nwb_dir,\n",
    "                                            two_p_imaging='yes',\n",
    "                                            reward_group=reward_group)\n",
    "        print(mice)\n",
    "\n",
    "        average_response = {}\n",
    "        for mouse_id in mice:\n",
    "            print(mouse_id)\n",
    "            # Disregard these mice as the number of trials is too low.\n",
    "            if mouse_id in ['GF307', 'GF310', 'GF333', 'MI075']:\n",
    "                continue\n",
    "            session_list, nwb_files, _, db_filtered = io.select_sessions_from_db(db_path,\n",
    "                                                                                nwb_dir,\n",
    "                                                                                two_p_imaging='yes',\n",
    "                                                                                subject_id=mouse_id,\n",
    "                                                                                day=days,)\n",
    "            print(session_list)\n",
    "            data = []\n",
    "            mdata_list = []\n",
    "            for session_id in session_list:\n",
    "                arr, mdata = imaging_utils.load_session_2p_imaging(mouse_id,\n",
    "                                                                    session_id,\n",
    "                                                                    processed_dir)\n",
    "                # arr = imaging_utils.substract_baseline(arr, 3, baseline_win)\n",
    "                data.append(arr)\n",
    "                mdata_list.append(mdata)\n",
    "            \n",
    "            # Extract UM trials.\n",
    "            for i, arr in enumerate(data):\n",
    "                arr = imaging_utils.extract_trials(arr, mdata_list[i], 'UM', n_trials=None)\n",
    "                data[i] = arr\n",
    "\n",
    "            # Select cell type.\n",
    "            if cell_type != 'allcells':\n",
    "                cell_type_mask = mdata_list[0]['cell_types']==cell_type\n",
    "                data = [arr[cell_type_mask] for arr in data]\n",
    "\n",
    "            # Compute average response for each trial, each day.\n",
    "            average_response[mouse_id] = []\n",
    "            for day in data:\n",
    "                average_response[mouse_id].append(np.nanmean(day[:, :, win[0]:win[1]], axis=2))\n",
    "\n",
    "        # Even the number of trials per days across mice.\n",
    "        min_trials = []\n",
    "        for iday in range(len(days)):\n",
    "            m = [data[iday].shape[1] for _, data in average_response.items()]\n",
    "            print(m)\n",
    "            min_trials.append(np.min(m))\n",
    "\n",
    "        for mouse, data in average_response.items():\n",
    "            for iday in range(len(days)):\n",
    "                average_response[mouse][iday] = data[iday][:, :min_trials[iday]]\n",
    "            \n",
    "        corr_matrix = np.concatenate([np.concatenate(data, axis=1) for _, data in average_response.items()], axis=0)\n",
    "        corr_matrix = np.corrcoef(corr_matrix.T)\n",
    "        # corr_matrix = spearmanr(pop_vectors.T, axis=1)[0]\n",
    "        \n",
    "        # Set color map limit to the max without the diagonal.\n",
    "        vmax = np.max(corr_matrix[~np.eye(corr_matrix.shape[0], dtype=bool)])\n",
    "        vmin = np.min(corr_matrix)\n",
    "\n",
    "        with PdfPages(os.path.join(output_dir, pdf_file)) as pdf:\n",
    "            f = plt.figure()\n",
    "            im = plt.imshow(corr_matrix, vmin = vmin, vmax=vmax, cmap='viridis')\n",
    "            n_trials = [arr.shape[1] for arr in data]\n",
    "            for i in np.cumsum(n_trials)[:-1]:\n",
    "                plt.axvline(x=i-1, color='#252525', linestyle='-', lw=0.5)\n",
    "                plt.axhline(y=i-1, color='#252525', linestyle='-', lw=0.5)\n",
    "            plt.title(f'{reward_group} {cell_type}')\n",
    "            plt.title(reward_group)\n",
    "            cbar_ax = f.add_axes([0.85, 0.15, 0.05, 0.7])\n",
    "            cbar = f.colorbar(im, cax=cbar_ax, ticks=[vmin, 0, vmax])\n",
    "            cbar.ax.set_yticklabels([f'{vmin:.2f}', '0', f'> {vmax:.2f}'])\n",
    "            cbar.ax.tick_params(size=0)\n",
    "            pdf.savefig(dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.colorbar.Colorbar at 0x207f56f5610>"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "sim = np.concatenate(response_avg, axis=1)\n",
    "sim = cosine_similarity(sim.T)\n",
    "\n",
    "plt.figure()\n",
    "# vmin=-1\n",
    "# vmax=1\n",
    "# plt.imshow(corr_matrix, vmin=vmin, vmax=vmax)\n",
    "plt.imshow(sim)\n",
    "n_trials = [arr.shape[1] for arr in data]\n",
    "for i in np.cumsum(n_trials)[:-1]:\n",
    "    plt.axvline(x=i, color='#252525', linestyle='-',)\n",
    "    plt.axhline(y=i, color='#252525', linestyle='-',)\n",
    "plt.title(mouse_id)\n",
    "\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Correlation during learning.\n",
    "\n",
    "When is the change of correlation triggered during D0 whisker learning?\n",
    "\n",
    "- First, plot correlation matrix with WH trials stacked with UM.\n",
    "- then point plot the correlation of each trial with the average maaping response of D+2\n",
    "- select modulated cells with LMI and plot population vectors for WH and UM. Is there a graded response? a discret change? or do they respond strong since the very first trial?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['GF305', 'GF306', 'GF307', 'GF308', 'GF310', 'GF311', 'GF313', 'GF314', 'GF317', 'GF318', 'GF319', 'GF323', 'GF333', 'GF334', 'GF348', 'GF350', 'MI062', 'MI069', 'MI072', 'MI075', 'MI076', 'AR132', 'AR133', 'AR135', 'AR137', 'AR139', 'AR127', 'AR131', 'AR143', 'AR144']\n"
     ]
    }
   ],
   "source": [
    "# Load data needed to compute before and after learning.\n",
    "\n",
    "sampling_rate = 30\n",
    "win = (1, 1.150)  # from stimulus onset to 300 ms after.\n",
    "win = (int(win[0] * sampling_rate), int(win[1] * sampling_rate))\n",
    "baseline_win = (0, 1)\n",
    "baseline_win = (int(baseline_win[0] * sampling_rate), int(baseline_win[1] * sampling_rate))\n",
    "reward_group = 'R-'\n",
    "plot_save_figs = False\n",
    "days = ['-2', '-1', '0', '+1', '+2']\n",
    "wh_trial_type = 'WH'\n",
    "\n",
    "_, _, mice, _ = io.select_sessions_from_db(db_path,\n",
    "                                            nwb_dir,\n",
    "                                            two_p_imaging='yes')\n",
    "print(mice)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['GF305_27112020_083119', 'GF305_28112020_103938', 'GF305_29112020_103331', 'GF305_30112020_110255', 'GF305_02122020_132229']\n",
      "[45, 45, 30, 45, 30, 45, 30, 45]\n",
      "['GF306_27112020_104436', 'GF306_28112020_125555', 'GF306_29112020_131929', 'GF306_30112020_133249', 'GF306_02122020_161611']\n",
      "[45, 45, 30, 45, 30, 45, 30, 45]\n",
      "['GF308_17112020_105052', 'GF308_18112020_093627', 'GF308_19112020_103527', 'GF308_20112020_122826', 'GF308_21112020_135515']\n",
      "[45, 45, 30, 45, 30, 45, 30, 45]\n",
      "['GF311_17112020_155501', 'GF311_18112020_151838', 'GF311_19112020_160412', 'GF311_20112020_171609', 'GF311_21112020_180049']\n",
      "[45, 45, 30, 45, 30, 45, 30, 45]\n",
      "['GF313_27112020_141857', 'GF313_28112020_154236', 'GF313_29112020_154625', 'GF313_30112020_154904', 'GF313_03122020_082147']\n",
      "[45, 45, 30, 45, 30, 45, 30, 45]\n",
      "['GF314_27112020_160459', 'GF314_28112020_171800', 'GF314_29112020_174831', 'GF314_30112020_171906', 'GF314_03122020_102249']\n",
      "[45, 45, 30, 45, 30, 45, 30, 45]\n",
      "['GF317_15122020_081931', 'GF317_16122020_082007', 'GF317_17122020_080715', 'GF317_18122020_104834', 'GF317_20122020_120604']\n",
      "[45, 45, 30, 45, 30, 45, 30, 45]\n",
      "['GF318_15122020_095616', 'GF318_16122020_095516', 'GF318_17122020_144100', 'GF318_18122020_132105', 'GF318_19122020_155806']\n",
      "[45, 45, 30, 45, 30, 45, 30, 45]\n",
      "['GF319_24122020_120204', 'GF319_25122020_142951', 'GF319_26122020_144746', 'GF319_27122020_135842', 'GF319_28122020_132438']\n",
      "[45, 45, 10, 45, 10, 45, 10, 45]\n",
      "['GF323_07012021_092005', 'GF323_08012021_083725', 'GF323_09012021_111716', 'GF323_11012021_084126', 'GF323_12012021_090219']\n",
      "[45, 45, 30, 45, 30, 45, 30, 45]\n",
      "['GF334_21012021_160130', 'GF334_22012021_153815', 'GF334_24012021_173019', 'GF334_25012021_163843', 'GF334_26012021_171010']\n",
      "[45, 45, 30, 45, 30, 45, 30, 45]\n",
      "['GF348_29052021_100151', 'GF348_30052021_110107', 'GF348_31052021_102411', 'GF348_01062021_095758', 'GF348_02062021_084344']\n",
      "[45, 45, 10, 45, 10, 45, 10, 45]\n",
      "['GF350_29052021_124022', 'GF350_30052021_123155', 'GF350_31052021_135001', 'GF350_01062021_122420', 'GF350_02062021_142138']\n",
      "[45, 45, 10, 45, 10, 45, 10, 45]\n",
      "['MI062_30092021_091006', 'MI062_01102021_091233', 'MI062_02102021_105027', 'MI062_03102021_103851', 'MI062_04102021_092339']\n",
      "[45, 45, 10, 45, 10, 45, 10, 45]\n",
      "['MI069_19122021_100830', 'MI069_20122021_095058', 'MI069_21122021_090648', 'MI069_22122021_090212', 'MI069_23122021_085758']\n",
      "[45, 45, 10, 45, 10, 45, 10, 45]\n",
      "['MI072_19122021_140553', 'MI072_20122021_125805', 'MI072_21122021_132704', 'MI072_22122021_132651', 'MI072_23122021_132111']\n",
      "[45, 45, 10, 45, 10, 45, 10, 45]\n",
      "['MI076_19122021_120004', 'MI076_20122021_113038', 'MI076_21122021_112146', 'MI076_22122021_114039', 'MI076_23122021_113818']\n",
      "[45, 45, 10, 45, 10, 45, 10, 45]\n",
      "['AR132_20240424_112338', 'AR132_20240425_102625', 'AR132_20240426_093953', 'AR132_20240427_122605', 'AR132_20240428_122206']\n",
      "['AR133_20240424_130306', 'AR133_20240425_115233', 'AR133_20240426_113430', 'AR133_20240427_142253', 'AR133_20240428_134911']\n",
      "[45, 45, 30, 45, 30, 45, 30, 45]\n",
      "['AR135_20240424_160805', 'AR135_20240425_151948', 'AR135_20240426_133260', 'AR135_20240427_154417', 'AR135_20240428_150944']\n",
      "[45, 45, 30, 45, 30, 45, 30, 45]\n",
      "['AR137_20240424_172627', 'AR137_20240425_170755', 'AR137_20240426_152510', 'AR137_20240427_171535', 'AR137_20240428_163224']\n",
      "[45, 45, 10, 45, 10, 45, 10, 45]\n",
      "['AR139_20240424_185913', 'AR139_20240425_181627', 'AR139_20240426_165725', 'AR139_20240427_183701', 'AR139_20240428_180459']\n",
      "[45, 45, 10, 45, 10, 45, 10, 45]\n",
      "['AR127_20240221_133407', 'AR127_20240222_152629', 'AR127_20240223_131820', 'AR127_20240224_140853', 'AR127_20240225_142858']\n",
      "[45, 45, 30, 45, 30, 45, 30, 45]\n",
      "['AR131_20240301_145952', 'AR131_20240302_123034', 'AR131_20240303_171032', 'AR131_20240304_133332', 'AR131_20240305_140141']\n",
      "[45, 45, 10, 45, 10, 45, 10, 45]\n",
      "['AR143_20240518_174556', 'AR143_20240519_141725', 'AR143_20240520_130137', 'AR143_20240521_125833', 'AR143_20240522_172846']\n",
      "[45, 45, 30, 45, 30, 45, 30, 45]\n",
      "['AR144_20240518_193553', 'AR144_20240519_151737', 'AR144_20240520_141104', 'AR144_20240521_142259', 'AR144_20240522_190834']\n",
      "[45, 45, 30, 45, 30, 45, 30, 45]\n"
     ]
    }
   ],
   "source": [
    "corr_avg_days = {}\n",
    "corr_avg_pre_post = {}\n",
    "metadata = {}\n",
    "pop_vectors_dict = {}\n",
    "n_trials = {}\n",
    "lmi = {}\n",
    "\n",
    "# mice = ['GF334']\n",
    "\n",
    "# Disregard these mice as the number of trials is too low.\n",
    "mice =  [mouse for mouse in mice if mouse not in ['GF307', 'GF310', 'GF333', 'MI075']]\n",
    "\n",
    "for mouse_id in mice:\n",
    "    output_dir = fr'//sv-nas1.rcp.epfl.ch/Petersen-Lab/analysis/Anthony_Renard/analysis_output/mice/{mouse_id}'\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "\n",
    "    session_list, nwb_files, _, db_filtered = io.select_sessions_from_db(db_path,\n",
    "                                                                        nwb_dir,\n",
    "                                                                        two_p_imaging='yes',\n",
    "                                                                        subject_id=mouse_id,\n",
    "                                                                        day=days,)\n",
    "    print(session_list)\n",
    "    \n",
    "    data = []\n",
    "    mdata_list = []\n",
    "    for session_id in session_list:\n",
    "        arr, mdata = imaging_utils.load_session_2p_imaging(mouse_id,\n",
    "                                                            session_id,\n",
    "                                                            processed_dir)\n",
    "        arr = imaging_utils.substract_baseline(arr, 3, baseline_win)\n",
    "        data.append(arr)\n",
    "        mdata_list.append(mdata)\n",
    "    reward_group = io.get_reward_group_from_db(db_path, session_list[0])\n",
    "    metadata[mouse_id] = {}\n",
    "    metadata[mouse_id]['reward_group'] = reward_group\n",
    "    \n",
    "    # Extract UM and WH trials.\n",
    "    if reward_group == 'R+':\n",
    "        n_um = 45\n",
    "        n_wh = 30\n",
    "    else:\n",
    "        n_um = 45\n",
    "        n_wh = 10\n",
    "    \n",
    "    if wh_trial_type == 'WH':\n",
    "        # Some days are no WH trials for the mouse.\n",
    "        if mouse_id == 'AR132':\n",
    "            continue\n",
    "\n",
    "    activity = []\n",
    "    arr = imaging_utils.extract_trials(data[0], mdata_list[0], 'UM', n_trials=n_um)\n",
    "    activity.append(arr)\n",
    "    arr = imaging_utils.extract_trials(data[1], mdata_list[1], 'UM', n_trials=n_um)\n",
    "    activity.append(arr)\n",
    "    arr = imaging_utils.extract_trials(data[2], mdata_list[2], wh_trial_type, n_trials=n_wh)\n",
    "    activity.append(arr)\n",
    "    arr = imaging_utils.extract_trials(data[2], mdata_list[2], 'UM', n_trials=n_um)\n",
    "    activity.append(arr)\n",
    "    arr = imaging_utils.extract_trials(data[3], mdata_list[3], wh_trial_type, n_trials=n_wh)\n",
    "    activity.append(arr)\n",
    "    arr = imaging_utils.extract_trials(data[3], mdata_list[3], 'UM', n_trials=n_um)\n",
    "    activity.append(arr)\n",
    "    arr = imaging_utils.extract_trials(data[4], mdata_list[4], wh_trial_type, n_trials=n_wh)\n",
    "    activity.append(arr)\n",
    "    arr = imaging_utils.extract_trials(data[4], mdata_list[4], 'UM', n_trials=n_um)\n",
    "    activity.append(arr)\n",
    "\n",
    "    # # Print n trials.\n",
    "    # print([arr.shape[1] for arr in activity])\n",
    "\n",
    "    corr_avg_days[mouse_id] = {}\n",
    "    corr_avg_pre_post[mouse_id] = {}\n",
    "    pop_vectors_dict[mouse_id] = {}\n",
    "    n_trials[mouse_id] = {}\n",
    "\n",
    "    for cell_type in ['allcells']:\n",
    "        # Select cell type.\n",
    "        if cell_type == 'allcells':\n",
    "            activity_subtype = activity\n",
    "        else:\n",
    "            activity_subtype = []\n",
    "            cell_type_mask = mdata_list[0]['cell_types']==cell_type\n",
    "            activity_subtype = [arr[cell_type_mask] for arr in activity]\n",
    "        \n",
    "        # strong_cells = [3,11,33,48,57,67,80,86,104,153,166,175]\n",
    "        # mask = np.ones(data_subtype[0].shape[0], dtype=bool)\n",
    "        # mask[strong_cells] = False\n",
    "        # data_subtype = [arr[mask] for arr in data_subtype]\n",
    "\n",
    "        # If no cells of the specified type, skip.\n",
    "        if activity_subtype[0].shape[0] == 0:\n",
    "            continue\n",
    "\n",
    "        # Compute average response for each trial, each day.\n",
    "        response_avg = []\n",
    "        for d in activity_subtype:\n",
    "            response_avg.append(np.nanmean(d[:, :, win[0]:win[1]], axis=2))\n",
    "\n",
    "        pop_vectors = np.concatenate(response_avg, axis=1)\n",
    "        pop_vectors_dict[mouse_id][cell_type] = pop_vectors\n",
    "        \n",
    "        # Compute LMI.\n",
    "        if cell_type == 'allcells':\n",
    "            # pre = np.mean(np.concatenate(response_avg[0:2], axis=1), axis=1)\n",
    "            # print(pre.shape)\n",
    "            # post = np.mean(np.concatenate((response_avg[5], response_avg[7]), axis=1), axis=1)\n",
    "            # lmi[mouse_id] = (post - pre) / (np.abs(post) + np.abs(pre))\n",
    "            lmis = []\n",
    "            for icell in range(pop_vectors.shape[0]):\n",
    "                # mapping trials of D-2, D-1, D+1, D+2.\n",
    "                X = np.r_[response_avg[0][icell], response_avg[1][icell],\n",
    "                          response_avg[5][icell], response_avg[7][icell]]\n",
    "                y = np.r_[np.zeros(response_avg[0][icell].shape[0]),\n",
    "                          np.zeros(response_avg[1][icell].shape[0]),\n",
    "                          np.ones(response_avg[5][icell].shape[0]),\n",
    "                          np.ones(response_avg[7][icell].shape[0])]\n",
    "                fpr, tpr, _ = roc_curve(y, X)\n",
    "                roc_auc = auc(fpr, tpr)\n",
    "                lmis.append((roc_auc - 0.5) * 2)\n",
    "            lmi[mouse_id] = np.array(lmis)\n",
    "\n",
    "        corr_matrix = np.corrcoef(pop_vectors.T)\n",
    "        # corr_matrix = cosine_similarity(pop_vectors.T)\n",
    "        # corr_matrix = spearmanr(pop_vectors.T, axis=1)[0]\n",
    "\n",
    "        # Compute average correlation inside each days.\n",
    "        corr_avg_days[mouse_id][cell_type] = []\n",
    "        n_trials[mouse_id] = [arr.shape[1] for arr in activity_subtype]\n",
    "        for start, end in zip(np.cumsum([0] + n_trials[mouse_id][:-1]), np.cumsum(n_trials[mouse_id])):\n",
    "            upper_triangle = np.triu(corr_matrix[start:end, start:end], k=1)\n",
    "            corr_avg_days[mouse_id][cell_type].append(np.mean(upper_triangle))\n",
    "\n",
    "        # Compare correlation between inside pre training days,\n",
    "        # inside post training days and between pre and post training days.\n",
    "        trial_cumsum = np.cumsum([0] + n_trials[mouse_id])\n",
    "        pre_in_start_x, pre_in_end_x = trial_cumsum[1], trial_cumsum[2]\n",
    "        pre_in_start_y, pre_in_end_y = trial_cumsum[0], trial_cumsum[1]\n",
    "        pre_in = np.mean(corr_matrix[pre_in_start_x:pre_in_end_x, pre_in_start_y:pre_in_end_y])\n",
    "\n",
    "        post_in_start_x, post_in_end_x = trial_cumsum[4], trial_cumsum[5]\n",
    "        post_in_start_y, post_in_end_y = trial_cumsum[3], trial_cumsum[4]\n",
    "        post_in = np.mean(corr_matrix[post_in_start_x:post_in_end_x, post_in_start_y:post_in_end_y])\n",
    "\n",
    "        pre_post_start_x, pre_post_end_x = trial_cumsum[3], trial_cumsum[5]\n",
    "        pre_post_start_y, pre_post_end_y = trial_cumsum[0], trial_cumsum[2]\n",
    "        pre_post = np.mean(corr_matrix[pre_post_start_x:pre_post_end_x, pre_post_start_y:pre_post_end_y])\n",
    "\n",
    "        corr_avg_pre_post[mouse_id][cell_type] = [pre_in, post_in, pre_post]\n",
    "\n",
    "        if plot_save_figs:\n",
    "            # Plot population vectors.\n",
    "            pdf_file = f'pop_vectors_wh_um_{mouse_id}_{cell_type}.pdf'\n",
    "            with PdfPages(os.path.join(output_dir, pdf_file)) as pdf:\n",
    "                vmax = np.percentile(pop_vectors, 99)\n",
    "                vmin = np.percentile(pop_vectors, 1)\n",
    "\n",
    "                f = plt.figure()\n",
    "                im = plt.imshow(pop_vectors, cmap='viridis', vmin=vmin, vmax=vmax)\n",
    "                cbar = f.colorbar(im, ticks=[vmin, 0, vmax])\n",
    "                cbar.ax.set_yticklabels([f'{vmin:.2f}', '0', f'> {vmax:.2f}'])\n",
    "                cbar.ax.tick_params(size=0)\n",
    "                pdf.savefig(dpi=300)\n",
    "                plt.close()\n",
    "\n",
    "            # Plot correlation matrix.\n",
    "            pdf_file = f'correlation_matrices_trial_wh_um_{mouse_id}_{cell_type}.pdf'            \n",
    "            with PdfPages(os.path.join(output_dir, pdf_file)) as pdf:\n",
    "                \n",
    "                # Set color map limit to the max without the diagonal.\n",
    "                vmax = np.max(corr_matrix[~np.eye(corr_matrix.shape[0], dtype=bool)])\n",
    "                vmin = np.min(corr_matrix)\n",
    "                f = plt.figure()\n",
    "                im = plt.imshow(corr_matrix, vmin = vmin, vmax=vmax, cmap='viridis')\n",
    "                n_trials[mouse_id] = [arr.shape[1] for arr in activity]\n",
    "                for i in np.cumsum(n_trials[mouse_id])[:-1]:\n",
    "                    plt.axvline(x=i-1, color='#252525', linestyle='-', lw=0.5)\n",
    "                    plt.axhline(y=i-1, color='#252525', linestyle='-', lw=0.5)\n",
    "                if cell_type:\n",
    "                    plt.title(f'{mouse_id} {reward_group} {cell_type}')\n",
    "                else:\n",
    "                    plt.title(f'{mouse_id} {reward_group} all cells')\n",
    "                cbar_ax = f.add_axes([0.85, 0.15, 0.05, 0.7])\n",
    "                cbar = f.colorbar(im, cax=cbar_ax, ticks=[vmin, 0, vmax])\n",
    "                cbar.ax.set_yticklabels([f'{vmin:.2f}', '0', f'> {vmax:.2f}'])\n",
    "                cbar.ax.tick_params(size=0)\n",
    "                pdf.savefig(dpi=300)\n",
    "                plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Population vector plot on the stim for the modulated cells. For WH and UM.\n",
    "\n",
    "I'm afraid the modulated cells repond high already at the first WH."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "rewarded_mice = [mouse_id for mouse_id in pop_vectors_dict.keys() if metadata[mouse_id]['reward_group']=='R+']\n",
    "unrewarded_mice = [mouse_id for mouse_id in pop_vectors_dict.keys() if metadata[mouse_id]['reward_group']=='R-']\n",
    "\n",
    "# Compute the LMI thresholds for the top 5% most modulated cells and bottom 5% least modulated cells\n",
    "lmi_threshold_top = np.percentile(lmi[rewarded_mice[0]], 95)\n",
    "lmi_threshold_bottom = np.percentile(lmi[rewarded_mice[0]], 5)\n",
    "\n",
    "# Select the top 5% most modulated cells and bottom 5% least modulated cells for each rewarded mouse\n",
    "rewarded_pop_vectors_top = np.concatenate(\n",
    "    [pop_vectors_dict[mouse_id]['allcells'][lmi[mouse_id] > lmi_threshold_top] for mouse_id in rewarded_mice], axis=0\n",
    ")\n",
    "rewarded_pop_vectors_bottom = np.concatenate(\n",
    "    [pop_vectors_dict[mouse_id]['allcells'][lmi[mouse_id] < lmi_threshold_bottom] for mouse_id in rewarded_mice], axis=0\n",
    ")\n",
    "\n",
    "# Select the top 5% most modulated cells and bottom 5% least modulated cells for each unrewarded mouse\n",
    "unrewarded_pop_vectors_top = np.concatenate(\n",
    "    [pop_vectors_dict[mouse_id]['allcells'][lmi[mouse_id] > lmi_threshold_top_unrewarded] for mouse_id in unrewarded_mice], axis=0\n",
    ")\n",
    "unrewarded_pop_vectors_bottom = np.concatenate(\n",
    "    [pop_vectors_dict[mouse_id]['allcells'][lmi[mouse_id] < lmi_threshold_bottom_unrewarded] for mouse_id in unrewarded_mice], axis=0\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Bottom 5% negatively modulated cells for each mouse -- R-')"
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if wh_trial_type == 'WH':\n",
    "    block_edges_rew = np.cumsum([45, 45, 30, 45, 30, 45, 30, 45])[:-1]\n",
    "    block_edges_unrew = np.cumsum([45, 45, 10, 45, 10, 45, 10, 45])[:-1]\n",
    "elif wh_trial_type == 'WM':\n",
    "    block_edges_rew = np.cumsum([45, 45, 30, 45, 30, 45, 30, 45])[:-1]\n",
    "    block_edges_unrew = np.cumsum([45, 45, 10, 45, 10, 45, 10, 45])[:-1]\n",
    "\n",
    "vmax = np.percentile(rewarded_pop_vectors_top, 99)\n",
    "vmin = np.percentile(rewarded_pop_vectors_top, 1)\n",
    "\n",
    "plt.figure()\n",
    "plt.imshow(rewarded_pop_vectors_top, cmap='viridis', vmin=vmin, vmax=vmax)\n",
    "for i in block_edges_rew-0.5:\n",
    "    plt.axvline(x=i, color='white', linestyle='--', linewidth=1)\n",
    "plt.xticks(block_edges_rew-0.5, block_edges_rew)\n",
    "plt.colorbar()\n",
    "plt.show()\n",
    "plt.title('Top 5% positively modulated cells for each mouse -- R+')\n",
    "\n",
    "# Plot for the bottom 5% negatively modulated cells -- R+\n",
    "vmax = np.percentile(rewarded_pop_vectors_bottom, 99)\n",
    "vmin = np.percentile(rewarded_pop_vectors_bottom, 1)\n",
    "plt.figure()\n",
    "plt.imshow(rewarded_pop_vectors_bottom, cmap='viridis', vmin=vmin, vmax=vmax)\n",
    "for i in block_edges_rew-0.5:\n",
    "    plt.axvline(x=i, color='white', linestyle='--', linewidth=1)\n",
    "plt.xticks(block_edges_rew-0.5, block_edges_rew)\n",
    "plt.colorbar()\n",
    "plt.show()\n",
    "plt.title('Bottom 5% negatively modulated cells for each mouse -- R+')\n",
    "\n",
    "# Compute the LMI thresholds for the top 5% most modulated cells and bottom 5% least modulated cells for unrewarded mice\n",
    "lmi_threshold_top_unrewarded = np.percentile(lmi[unrewarded_mice[0]], 95)\n",
    "lmi_threshold_bottom_unrewarded = np.percentile(lmi[unrewarded_mice[0]], 5)\n",
    "\n",
    "\n",
    "# Plot for the top 5% positively modulated cells -- R-\n",
    "vmax = np.percentile(unrewarded_pop_vectors_top, 99)\n",
    "vmin = np.percentile(unrewarded_pop_vectors_top, 1)\n",
    "plt.figure()\n",
    "plt.imshow(unrewarded_pop_vectors_top, cmap='viridis', vmin=vmin, vmax=vmax)\n",
    "for i in block_edges_unrew-0.5:\n",
    "    plt.axvline(x=i, color='white', linestyle='--', linewidth=1)\n",
    "plt.xticks(block_edges_unrew-0.5, block_edges_unrew)\n",
    "plt.colorbar()\n",
    "plt.show()\n",
    "plt.title('Top 5% positively modulated cells -- R-')\n",
    "\n",
    "# Plot for the bottom 5% negatively modulated cells -- R-\n",
    "vmax = np.percentile(unrewarded_pop_vectors_bottom, 99)\n",
    "vmin = np.percentile(unrewarded_pop_vectors_bottom, 1)\n",
    "plt.figure()\n",
    "plt.imshow(unrewarded_pop_vectors_bottom, cmap='viridis', vmin=vmin, vmax=vmax)\n",
    "for i in block_edges_unrew-0.5:\n",
    "    plt.axvline(x=i, color='white', linestyle='--', linewidth=1)\n",
    "plt.xticks(block_edges_unrew-0.5, block_edges_unrew)\n",
    "plt.colorbar()\n",
    "plt.show()\n",
    "plt.title('Bottom 5% negatively modulated cells for each mouse -- R-')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scatter plot of the correlation of each D0 WH with post learning UM.\n",
    "\n",
    "First have a look with the global population."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 45  90 120 165 195 240 270 315]\n"
     ]
    }
   ],
   "source": [
    "block_edges_rew = np.cumsum([45, 45, 30, 45, 30, 45, 30, 45])\n",
    "print(block_edges_rew)\n",
    "pre = rewarded_pop_vectors_top[:, :block_edges_rew[1]]\n",
    "post = np.concatenate((rewarded_pop_vectors_top[:,block_edges_rew[4]:block_edges_rew[5]],\n",
    "                       rewarded_pop_vectors_top[:,block_edges_rew[6]:block_edges_rew[7]]), axis=1)\n",
    "d0_learning = rewarded_pop_vectors_top[:,block_edges_rew[2]:block_edges_rew[3]]\n",
    "\n",
    "correlations = []\n",
    "correlations.append(np.mean(np.corrcoef(pre.T, post.T)[0:post.shape[1], pre.shape[1]:]))\n",
    "for i in range(d0_learning.shape[1]):\n",
    "    correlations.append(np.mean(np.corrcoef(d0_learning[:, i], post.T)[0:post.shape[1], 0]))\n",
    "correlation = np.array(correlations)\n",
    "\n",
    "plt.figure()\n",
    "plt.scatter(range(correlation.shape[0]), correlation)\n",
    "plt.xlabel('Correlation with Pre')\n",
    "plt.ylabel('Correlation with Post')\n",
    "plt.title('Correlation of Pre and Each Vector in D0 Learning with Post')\n",
    "plt.ylim([-1, 1])\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(175, 90)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 0.02034362,  0.26056918,  0.04235924, ...,  0.18045816,\n",
       "         0.1439456 ,  0.1596096 ],\n",
       "       [ 0.03551034,  0.13685159,  0.22050762, ...,  0.1917738 ,\n",
       "         0.22206861,  0.2400069 ],\n",
       "       [-0.02437256,  0.10172189,  0.03464237, ...,  0.35288548,\n",
       "         0.09057352,  0.18831184],\n",
       "       ...,\n",
       "       [ 0.12885872,  0.19384733, -0.0238691 , ...,  0.10951992,\n",
       "         0.18027061,  0.07334732],\n",
       "       [ 0.03851379,  0.16146571,  0.00986161, ...,  0.31289878,\n",
       "         0.27375669,  0.14097796],\n",
       "       [ 0.13142371,  0.31517988,  0.04071624, ...,  0.17331523,\n",
       "         0.10635769,  0.1278629 ]])"
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aprenard\\AppData\\Local\\Temp\\ipykernel_16996\\638471481.py:7: UserWarning:\n",
      "\n",
      "Adding colorbar to a different Figure <Figure size 640x480 with 2 Axes> than <Figure size 640x480 with 8 Axes> which fig.colorbar is called on.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([<matplotlib.axis.XTick at 0x22091d70cb0>,\n",
       "  <matplotlib.axis.XTick at 0x22091d71b20>,\n",
       "  <matplotlib.axis.XTick at 0x2208e2fa5d0>,\n",
       "  <matplotlib.axis.XTick at 0x2208e306330>,\n",
       "  <matplotlib.axis.XTick at 0x2208e305550>,\n",
       "  <matplotlib.axis.XTick at 0x2208e360d40>,\n",
       "  <matplotlib.axis.XTick at 0x2208e3625a0>],\n",
       " [Text(44.5, 0, '45'),\n",
       "  Text(89.5, 0, '90'),\n",
       "  Text(119.5, 0, '120'),\n",
       "  Text(164.5, 0, '165'),\n",
       "  Text(194.5, 0, '195'),\n",
       "  Text(239.5, 0, '240'),\n",
       "  Text(269.5, 0, '270')])"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr_matrix = np.corrcoef(rewarded_pop_vectors_top.T)\n",
    "vmax = np.max(corr_matrix[~np.eye(corr_matrix.shape[0], dtype=bool)])\n",
    "vmin = np.min(corr_matrix)\n",
    "\n",
    "plt.figure()\n",
    "im = plt.imshow(corr_matrix, cmap='viridis', vmin=vmin, vmax=vmax)\n",
    "cbar = f.colorbar(im, ticks=[vmin, 0, vmax])\n",
    "cbar.ax.set_yticklabels([f'{vmin:.2f}', '0', f'> {vmax:.2f}'])\n",
    "cbar.ax.tick_params(size=0)\n",
    "\n",
    "for i in block_edges_rew-0.5:\n",
    "    plt.axvline(x=i, color='white', linestyle='--', linewidth=1)\n",
    "    plt.axhline(y=i, color='white', linestyle='--', linewidth=1)\n",
    "plt.xticks(block_edges_rew-0.5, block_edges_rew)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.colorbar.Colorbar at 0x2209ce2d670>"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr_matrix = np.corrcoef(rewarded_pop_vectors_top.T)\n",
    "plt.figure()\n",
    "im = plt.imshow(corr_matrix, cmap='viridis')\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "-1.0\n",
      "31\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x22061a5c860>"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print population vectors for specific LMI cells.\n",
    "mouse_id = 'AR127'\n",
    "alpha = 5\n",
    "top = np.percentile(lmi[mouse_id], 100 - alpha)\n",
    "bottom = np.percentile(lmi[mouse_id], alpha)\n",
    "lmi_mask = (lmi[mouse_id] >= top) \n",
    "print(top)\n",
    "print(bottom)\n",
    "print(np.sum(lmi_mask))\n",
    "\n",
    "plt.imshow(pop_vectors_dict[mouse_id]['allcells'][lmi_mask], cmap='viridis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(260,)\n",
      "(260,)\n",
      "(260,)\n",
      "(260,)\n",
      "(260,)\n",
      "(260,)\n",
      "(260,)\n",
      "(260,)\n",
      "(260,)\n",
      "(260,)\n",
      "(260,)\n",
      "(260,)\n"
     ]
    }
   ],
   "source": [
    "mouse_ids = corr_avg_days.keys()\n",
    "correlations = {}\n",
    "\n",
    "for mouse_id in mouse_ids:\n",
    "    trial_boundaries = np.cumsum([0] + n_trials[mouse_id])\n",
    "    post_training = np.mean(pop_vectors_dict[mouse_id]['allcells'][:, trial_boundaries[-2]:], axis=1)\n",
    "    correlations[mouse_id] = np.corrcoef(pop_vectors_dict[mouse_id]['allcells'], post_training, rowvar=False)[-1, :-1]\n",
    "    print(correlations[mouse_id].shape)\n",
    "    # repeated_post_training = np.tile(post_training, (10, 1))\n",
    "    # plt.figure()\n",
    "    # plt.imshow(repeated_post_training.T, cmap='viridis',vmin=-0.27, vmax=1.3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = []\n",
    "block_labels = [f'block_{i}' for i in range(1, 8)]\n",
    "\n",
    "df = []\n",
    "for mouse_id in mouse_ids:\n",
    "    for cell_type in corr_avg_days[mouse_id].keys():\n",
    "        if pop_vectors_dict[mouse_id][cell_type].shape[0] < 5:\n",
    "            continue\n",
    "        trial_boundaries = np.cumsum([0] + n_trials[mouse_id])\n",
    "        post_training = np.mean(pop_vectors_dict[mouse_id][cell_type][:, trial_boundaries[-2]:], axis=1, keepdims=True)\n",
    "        corr = np.corrcoef(pop_vectors_dict[mouse_id][cell_type], post_training, rowvar=False)[-1, :-1]\n",
    "        \n",
    "        # blocks = [i for i in range(0, 8) for _ in range(trial_boundaries[i],trial_boundaries[i+1])]\n",
    "        # trial_id_in_blocks = np.concat([np.arange(0, n_trials[mouse_id][i]) for i in range(8)])\n",
    "        # block_trial_id = [(block, trial) for block, trial in zip(blocks, trial_id_in_blocks)]\n",
    "        trial_ids = np.arange(corr.shape[0])\n",
    "\n",
    "        # multi_index = pd.MultiIndex.from_tuples([('block', 'trial_id')], names=['level_1', 'level_2'])\n",
    "        df.append(pd.DataFrame([[c, i, cell_type, mouse_id, metadata[mouse_id]['reward_group']] for c, i in zip(corr, trial_ids)],\n",
    "                            columns=['correlation', 'trial', 'cell_type', 'mouse_id', 'reward_group']))\n",
    "df = pd.concat(df, ignore_index=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.axis.XTick at 0x1fd779938c0>,\n",
       " <matplotlib.axis.XTick at 0x1fd5a1a7e60>,\n",
       " <matplotlib.axis.XTick at 0x1fd47bbafc0>,\n",
       " <matplotlib.axis.XTick at 0x1fd5d194110>,\n",
       " <matplotlib.axis.XTick at 0x1fd5d177320>,\n",
       " <matplotlib.axis.XTick at 0x1fd5d177e60>,\n",
       " <matplotlib.axis.XTick at 0x1fd5d1646b0>,\n",
       " <matplotlib.axis.XTick at 0x1fd5d165190>,\n",
       " <matplotlib.axis.XTick at 0x1fd5d194470>,\n",
       " <matplotlib.axis.XTick at 0x1fd5d165490>,\n",
       " <matplotlib.axis.XTick at 0x1fd5d166240>,\n",
       " <matplotlib.axis.XTick at 0x1fd5d166ae0>,\n",
       " <matplotlib.axis.XTick at 0x1fd5d167590>,\n",
       " <matplotlib.axis.XTick at 0x1fd5d167230>]"
      ]
     },
     "execution_count": 271,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sns.pointplot(data=df.loc[df.cell_type=='allcells'], x='trial', y='correlation', linestyles='none', errorbar=None)\n",
    "plt.ylim([-1,1])\n",
    "ax = plt.gca()\n",
    "ax.set_xticks(range(0,280,20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 260)"
      ]
     },
     "execution_count": 268,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pop_vectors_dict[mouse_id][cell_type].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 1)"
      ]
     },
     "execution_count": 269,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "post_training.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_blocks = 8\n",
    "mapping_block = [0, 1, 3, 5, 7]\n",
    "learning_block = [2, 4, 6]\n",
    "\n",
    "sns.set_theme(context='paper', style='ticks', palette='deep')\n",
    "palette = sns.color_palette()\n",
    "f, axes = plt.subplots(2, 1, figsize=(15, 6))\n",
    "\n",
    "for i in range(n_blocks):\n",
    "    if i in learning_block:\n",
    "        # color = '#238443'\n",
    "        color = 'red'\n",
    "\n",
    "    else:\n",
    "        color = '#eea429ff'\n",
    "    axes[0].scatter(range(trial_boundaries[i], trial_boundaries[i+1]),\n",
    "                    correlations[trial_boundaries[i]:trial_boundaries[i+1]],\n",
    "                    color=color)\n",
    "axes[0].set_ylim(-1, 1)\n",
    "# if apply_pca:\n",
    "#     plt.title('Correlation\\n' \\\n",
    "#               f'mice {mouse_list} ' \\\n",
    "#               f'variance retained: {variance_to_retain}')\n",
    "# else:   \n",
    "plt.title('Correlation\\n' \\\n",
    "            f'mice {mouse_id} ' \\\n",
    "            'full data (no dim reduction)')\n",
    "\n",
    "behav_table = nwb_read.get_trial_table(nwb_files[2])\n",
    "behav_table = compute_performance(behav_table, session_list[2], db_path)\n",
    "\n",
    "palette = sns.color_palette()\n",
    "plot_single_session(behav_table, session_list[2], axes[1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 Functional maps across learning days\n",
    "\n",
    "- amplitude of response\n",
    "- significance levels (p-value maps)\n",
    "- LMI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['GF305', 'GF306', 'GF307', 'GF308', 'GF310', 'GF311', 'GF313', 'GF314', 'GF317', 'GF318', 'GF323', 'GF333', 'GF334', 'AR133', 'AR135', 'AR127', 'AR143', 'AR144']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\aprenard\\Anaconda3\\envs\\fast-learning\\Lib\\site-packages\\openpyxl\\worksheet\\_read_only.py:81: UserWarning: Conditional Formatting extension is not supported and will be removed\n",
      "  for idx, row in parser.parse():\n"
     ]
    }
   ],
   "source": [
    "# Load data needed to compute before and after learning.\n",
    "\n",
    "sampling_rate = 30\n",
    "win = (1, 1.5)  # from stimulus onset to 300 ms after.\n",
    "win = (int(win[0] * sampling_rate), int(win[1] * sampling_rate))\n",
    "baseline_win = (0, 1)\n",
    "baseline_win = (int(baseline_win[0] * sampling_rate), int(baseline_win[1] * sampling_rate))\n",
    "reward_group = 'R+'\n",
    "\n",
    "_, _, mice, _ = io.select_sessions_from_db(db_path,\n",
    "                                            nwb_dir,\n",
    "                                            two_p_imaging='yes',\n",
    "                                            reward_group=reward_group)\n",
    "print(mice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = r'//sv-nas1.rcp.epfl.ch/Petersen-Lab/analysis/Anthony_Renard/analysis_output/functional_maps'\n",
    "pdf_file = f'functional_maps_{reward_group}.pdf'\n",
    "with PdfPages(os.path.join(output_dir, pdf_file)) as pdf:\n",
    "    for mouse_id in mice:\n",
    "        print(mouse_id)\n",
    "        session_list, nwb_files, _, db_filtered = io.select_sessions_from_db(db_path,\n",
    "                                                                            nwb_dir,\n",
    "                                                                            two_p_imaging='yes',\n",
    "                                                                            day=days,\n",
    "                                                                            subject_id=mouse_id)\n",
    "        print(session_list)\n",
    "        data = []\n",
    "        for session_id in session_list:\n",
    "            arr, metadata = imaging_utils.load_session_2p_imaging(mouse_id,\n",
    "                                                                session_id,\n",
    "                                                                processed_dir)\n",
    "            arr = imaging_utils.substract_baseline(arr, 3, baseline_win)\n",
    "            data.append(arr)\n",
    "\n",
    "        # Select UM trials.\n",
    "        data = [arr[:, -1] for arr in data]\n",
    "        # Remove trials with NaNs.\n",
    "        data = [arr[:, ~np.isnan(arr).all(axis=(0,2))] for arr in data]\n",
    "\n",
    "        # Load image masks.\n",
    "        roi_masks = nwb_read.get_image_mask(nwb_files[0])\n",
    "        roi_masks = np.stack(roi_masks, axis=0)\n",
    "        \n",
    "        # Compute significance map.\n",
    "        # -------------------------\n",
    "        \n",
    "        # Compute average response and baseline for each trial, each day.\n",
    "        baseline_avg = []\n",
    "        response_avg = []\n",
    "        for day in data:\n",
    "            baseline_avg.append(np.nanmean(day[:, :, baseline_win[0]:baseline_win[1]], axis=2))\n",
    "            response_avg.append(np.nanmean(day[:, :, win[0]:win[1]], axis=2))\n",
    "\n",
    "        # Compare response amplitude to baseline.\n",
    "        n_cells = data[0].shape[0]\n",
    "        p_values = [np.zeros(n_cells) for _ in range(len(data))]\n",
    "        for iday, day in enumerate(data):\n",
    "            for icell in range(n_cells):\n",
    "                _, p_values[iday][icell] = wilcoxon(baseline_avg[iday][icell], response_avg[iday][icell])\n",
    "        p_values = np.stack(p_values, axis=0)\n",
    "\n",
    "        # Categories p-values.\n",
    "        p_values_masks = np.copy(p_values)\n",
    "        p_values_masks[p_values>0.05] = 1\n",
    "        p_values_masks[p_values<=0.05] = 2\n",
    "        p_values_masks[p_values<=0.01] = 3\n",
    "        p_values_masks[p_values<=0.001] = 4\n",
    "        \n",
    "        map_significance = []\n",
    "        for iday in range(5):\n",
    "            maps = roi_masks * p_values_masks[iday, :, None, None]\n",
    "            map_significance.append(np.max(maps, axis=0))\n",
    "            \n",
    "        \n",
    "        # Compute amplitude map.\n",
    "        # ----------------------\n",
    "        \n",
    "        # Compute average response amplitude for each cell.\n",
    "        response_amplitude = []\n",
    "        for day in response_avg:\n",
    "            response_amplitude.append(np.nanmean(day, axis=1))\n",
    "        response_amplitude = np.stack(response_amplitude, axis=0)\n",
    "        \n",
    "        map_amplitude = []\n",
    "        for iday in range(5):\n",
    "            maps = roi_masks * response_amplitude[iday, :, None, None]\n",
    "            map_amplitude.append(np.max(maps, axis=0))\n",
    "    \n",
    "\n",
    "        # Plot maps.\n",
    "        # ----------\n",
    "        \n",
    "        f, axes = plt.subplots(2,5, figsize=(20, 8), sharex=True, sharey=True)\n",
    "        \n",
    "        # Plot amplitude maps.\n",
    "        cmap = sns.color_palette(\"viridis\", as_cmap=True)\n",
    "        # vmin = np.nanmin(response_amplitude)\n",
    "        vmin = 0\n",
    "        vmax = np.percentile(response_amplitude, 98)\n",
    "        \n",
    "        for iday in range(5):\n",
    "            a = axes[0,iday].imshow(map_amplitude[iday],\n",
    "                                interpolation='nearest',\n",
    "                                cmap=cmap,\n",
    "                                vmin=vmin, vmax=vmax)\n",
    "        cbar_ax = f.add_axes([.91,.124,.04,.754])\n",
    "        f.colorbar(a, cax=cbar_ax, location='right')\n",
    "        \n",
    "        \n",
    "        cmap = ['white', '#d9d9d9', '#fdbb84', '#ef6548', '#990000']\n",
    "        cmap = colors.ListedColormap(cmap)\n",
    "        bounds = range(cmap.N+1)\n",
    "        norm = colors.BoundaryNorm(bounds, cmap.N)\n",
    "        # Plot responsivity maps.\n",
    "        for iday in range(5):\n",
    "            axes[1, iday].imshow(map_significance[iday], cmap=cmap, norm=norm, interpolation='nearest')\n",
    "            # axes[iday].imshow(map_significance[iday])\n",
    "            \n",
    "        plt.suptitle(mouse_id)\n",
    "        pdf.savefig()\n",
    "        plt.close()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning modulation index (LMI)\n",
    "\n",
    "Computing LMI maps.\n",
    "\n",
    "What else other than maps do we want to look at? \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check what is quantified in Drieu et al. to conclude no sensory plasticity.\n",
    "- Number of neurons responsive across days.\n",
    "- Variability of the response across days. But how to compute that? Correlation of the pop vector across trials could work well or cell by cell?\n",
    "- Recompute the variability of the response. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'AR132'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[114], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mmetadata\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mAR132\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mreward_group\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "\u001b[1;31mKeyError\u001b[0m: 'AR132'"
     ]
    }
   ],
   "source": [
    "metadata['AR132']['reward_group']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fast-learning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
