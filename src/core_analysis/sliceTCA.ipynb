{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Slice TCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import seaborn as sns\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "import scipy.ndimage as spnd\n",
    "import torch\n",
    "import slicetca\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "sys.path.append(r'H:\\anthony\\repos\\NWB_analysis')\n",
    "from nwb_wrappers import nwb_reader_functions as nwb_read\n",
    "import src.utils.utils_imaging as imaging_utils \n",
    "import src.utils.utils_io as io\n",
    "from src.behavior import compute_performance, plot_single_session\n",
    "\n",
    "# Set plot parameters.\n",
    "plt.rcParams['pdf.fonttype'] = 42\n",
    "plt.rcParams['ps.fonttype'] = 42\n",
    "plt.rcParams['svg.fonttype'] = 'none'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to the directory containing the processed data.\n",
    "processed_dir = r\"//sv-nas1.rcp.epfl.ch/Petersen-Lab/analysis/Anthony_Renard/data_processed/mice\"\n",
    "nwb_dir = r\"//sv-nas1.rcp.epfl.ch/Petersen-Lab/analysis/Anthony_Renard/NWB\"\n",
    "\n",
    "# Session metadata file.\n",
    "db_path = r\"//sv-nas1.rcp.epfl.ch/Petersen-Lab/analysis/Anthony_Renard/mice_info/session_metadata.xlsx\"\n",
    "\n",
    "# Rewarded and non-rewarded NWB files.\n",
    "group_yaml_rew = r\"//sv-nas1.rcp.epfl.ch/Petersen-Lab/analysis/Anthony_Renard/mice_info/groups/imaging_rewarded.yaml\"\n",
    "group_yaml_non_rew = r\"//sv-nas1.rcp.epfl.ch/Petersen-Lab/analysis/Anthony_Renard/mice_info/groups/imaging_non_rewarded.yaml\"\n",
    "nwb_list_rew = io.read_group_yaml(group_yaml_rew)\n",
    "nwb_list_non_rew = io.read_group_yaml(group_yaml_non_rew)\n",
    "nwb_list = nwb_list_rew + nwb_list_non_rew"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here (133, 40, 181)\n",
      "here (133, 40, 181)\n",
      "here (133, 40, 181)\n",
      "here (133, 40, 181)\n",
      "here (133, 40, 181)\n",
      "here (215, 40, 181)\n",
      "here (215, 40, 181)\n",
      "here (215, 40, 181)\n",
      "here (215, 40, 181)\n",
      "here (215, 40, 181)\n",
      "here (147, 40, 181)\n",
      "here (147, 40, 181)\n",
      "here (147, 40, 181)\n",
      "here (147, 40, 181)\n",
      "here (147, 40, 181)\n",
      "here (105, 40, 181)\n",
      "here (105, 40, 181)\n",
      "here (105, 40, 181)\n",
      "here (105, 40, 181)\n",
      "here (105, 40, 181)\n",
      "here (164, 40, 181)\n",
      "here (164, 40, 181)\n",
      "here (164, 40, 181)\n",
      "here (164, 40, 181)\n",
      "here (164, 40, 181)\n",
      "here (197, 40, 181)\n",
      "here (197, 40, 181)\n",
      "here (197, 40, 181)\n",
      "here (197, 40, 181)\n",
      "here (197, 40, 181)\n",
      "here (146, 40, 181)\n",
      "here (146, 40, 181)\n",
      "here (146, 40, 181)\n",
      "here (146, 40, 181)\n",
      "here (146, 40, 181)\n",
      "here (140, 40, 181)\n",
      "here (140, 40, 181)\n",
      "here (140, 40, 181)\n",
      "here (140, 40, 181)\n",
      "here (140, 40, 181)\n",
      "here (305, 40, 181)\n",
      "here (305, 40, 181)\n",
      "here (305, 40, 181)\n",
      "here (305, 40, 181)\n",
      "here (305, 40, 181)\n",
      "here (130, 40, 181)\n",
      "here (130, 40, 181)\n",
      "here (130, 40, 181)\n",
      "here (130, 40, 181)\n",
      "here (130, 40, 181)\n",
      "here (144, 40, 181)\n",
      "here (144, 40, 181)\n",
      "here (144, 40, 181)\n",
      "here (144, 40, 181)\n",
      "here (144, 40, 181)\n",
      "here (180, 40, 181)\n",
      "here (180, 40, 181)\n",
      "here (180, 40, 181)\n",
      "here (180, 40, 181)\n",
      "here (180, 40, 181)\n",
      "here (205, 40, 181)\n",
      "here (205, 40, 181)\n",
      "here (205, 40, 181)\n",
      "here (205, 40, 181)\n",
      "here (205, 40, 181)\n",
      "dataset shapes\n",
      "(133, 200, 181)\n",
      "(215, 200, 181)\n",
      "(147, 200, 181)\n",
      "(105, 200, 181)\n",
      "(164, 200, 181)\n",
      "(197, 200, 181)\n",
      "(146, 200, 181)\n",
      "(140, 200, 181)\n",
      "(305, 200, 181)\n",
      "(130, 200, 181)\n",
      "(144, 200, 181)\n",
      "(180, 200, 181)\n",
      "(205, 200, 181)\n",
      "Trial type 'WH' is not present in the metadata.\n",
      "Trial type 'WH' is not present in the metadata.\n",
      "here (154, 10, 181)\n",
      "here (154, 10, 181)\n",
      "here (154, 10, 181)\n",
      "Trial type 'WH' is not present in the metadata.\n",
      "Trial type 'WH' is not present in the metadata.\n",
      "here (206, 10, 181)\n",
      "here (206, 10, 181)\n",
      "here (206, 10, 181)\n",
      "Trial type 'WH' is not present in the metadata.\n",
      "Trial type 'WH' is not present in the metadata.\n",
      "here (211, 10, 181)\n",
      "here (211, 10, 181)\n",
      "here (211, 10, 181)\n",
      "Trial type 'WH' is not present in the metadata.\n",
      "Trial type 'WH' is not present in the metadata.\n",
      "here (108, 10, 181)\n",
      "here (108, 10, 181)\n",
      "here (108, 10, 181)\n",
      "Trial type 'WH' is not present in the metadata.\n",
      "here (218, 10, 181)\n",
      "here (218, 10, 181)\n",
      "here (218, 10, 181)\n",
      "here (218, 10, 181)\n",
      "Trial type 'WH' is not present in the metadata.\n",
      "Trial type 'WH' is not present in the metadata.\n",
      "here (244, 10, 181)\n",
      "here (244, 10, 181)\n",
      "here (244, 10, 181)\n",
      "Trial type 'WH' is not present in the metadata.\n",
      "Trial type 'WH' is not present in the metadata.\n",
      "here (268, 10, 181)\n",
      "here (268, 10, 181)\n",
      "here (268, 10, 181)\n",
      "Trial type 'WH' is not present in the metadata.\n",
      "Trial type 'WH' is not present in the metadata.\n",
      "here (182, 10, 181)\n",
      "here (182, 10, 181)\n",
      "Trial type 'WH' is not present in the metadata.\n",
      "Trial type 'WH' is not present in the metadata.\n",
      "Trial type 'WH' is not present in the metadata.\n",
      "here (180, 10, 181)\n",
      "here (180, 10, 181)\n",
      "here (180, 10, 181)\n",
      "Trial type 'WH' is not present in the metadata.\n",
      "Trial type 'WH' is not present in the metadata.\n",
      "here (138, 10, 181)\n",
      "here (138, 10, 181)\n",
      "here (138, 10, 181)\n",
      "Trial type 'WH' is not present in the metadata.\n",
      "Trial type 'WH' is not present in the metadata.\n",
      "here (169, 10, 181)\n",
      "here (169, 10, 181)\n",
      "here (169, 10, 181)\n",
      "dataset shapes\n",
      "(154, 10, 181)\n",
      "(206, 28, 181)\n",
      "(211, 18, 181)\n",
      "(108, 17, 181)\n",
      "(218, 27, 181)\n",
      "(244, 16, 181)\n",
      "(268, 29, 181)\n",
      "(182, 20, 181)\n",
      "(180, 30, 181)\n",
      "(138, 30, 181)\n",
      "(169, 30, 181)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "all the input array dimensions except for the concatenation axis must match exactly, but along dimension 1, the array at index 0 has size 10 and the array at index 1 has size 28",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 72\u001b[0m\n\u001b[0;32m     59\u001b[0m \u001b[38;5;66;03m# mouse_list = [m for m in mouse_list if m not in ['AR132', 'MI069']]\u001b[39;00m\n\u001b[0;32m     60\u001b[0m \u001b[38;5;66;03m# mouse_list\u001b[39;00m\n\u001b[0;32m     61\u001b[0m \n\u001b[0;32m     62\u001b[0m \u001b[38;5;66;03m# mouse_list = ['AR127', 'AR133', 'AR135', 'AR143', 'AR144', 'AR131', 'AR137','AR139']\u001b[39;00m\n\u001b[0;32m     64\u001b[0m session_list, nwb_files, _, _ \u001b[38;5;241m=\u001b[39m io\u001b[38;5;241m.\u001b[39mselect_sessions_from_db(\n\u001b[0;32m     65\u001b[0m     db_path, nwb_dir,\n\u001b[0;32m     66\u001b[0m     experimenters\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAR\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mGF\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMI\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     69\u001b[0m     day\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m-2\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m-1\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m0\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m+1\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m+2\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[0;32m     70\u001b[0m     two_p_imaging\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124myes\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m---> 72\u001b[0m act_map_nonrew \u001b[38;5;241m=\u001b[39m \u001b[43mutils_imaging\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape_features_matrix\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmouse_list\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msession_list\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprocessed_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mWH\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     73\u001b[0m \u001b[38;5;66;03m# Subtract baselines.\u001b[39;00m\n\u001b[0;32m     74\u001b[0m act_map_nonrew \u001b[38;5;241m=\u001b[39m act_map_nonrew \u001b[38;5;241m-\u001b[39m np\u001b[38;5;241m.\u001b[39mnanmean(act_map_nonrew[:, :, baseline[\u001b[38;5;241m0\u001b[39m]:baseline[\u001b[38;5;241m1\u001b[39m]],\n\u001b[0;32m     75\u001b[0m                                axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m, keepdims\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[1;32mH:\\anthony\\repos\\fast-learning\\src\\utils\\utils_imaging.py:149\u001b[0m, in \u001b[0;36mshape_features_matrix\u001b[1;34m(mouse_list, session_list, data_dir, trial_type, n_trials)\u001b[0m\n\u001b[0;32m    146\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m arr \u001b[38;5;129;01min\u001b[39;00m mice_dataset:\n\u001b[0;32m    147\u001b[0m     \u001b[38;5;28mprint\u001b[39m(arr\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m--> 149\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconcatenate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmice_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m X\n",
      "\u001b[1;31mValueError\u001b[0m: all the input array dimensions except for the concatenation axis must match exactly, but along dimension 1, the array at index 0 has size 10 and the array at index 1 has size 28"
     ]
    }
   ],
   "source": [
    "# Load data needed to compute before and after learning.\n",
    "\n",
    "sampling_rate = 30\n",
    "win = (1, 1.300)  # from stimulus onset to 300 ms after.\n",
    "win = (int(win[0] * sampling_rate), int(win[1] * sampling_rate))\n",
    "baseline = (0, 1)\n",
    "baseline = (int(baseline[0] * sampling_rate), int(baseline[1] * sampling_rate))\n",
    "n_trials = 20\n",
    "days = ['-2', '-1', '0', '+1', '+2']\n",
    "apply_pca = False\n",
    "variance_to_retain = 0.8\n",
    "\n",
    "\n",
    "\n",
    "# # mouse_list = ['AR127', 'AR133', 'AR135', 'AR143', 'AR144',]\n",
    "# db = io.read_excel_db(db_path)\n",
    "# db = db.loc[\n",
    "#     (db.reward_group=='R+')\n",
    "#             & (db.two_p_imaging=='yes')\n",
    "#             & (db.exclude!='exclude')\n",
    "#             & (db.two_p_exclude!='exclude')]\n",
    "# mouse_list = list(db['subject_id'].unique())\n",
    "\n",
    "# excluded_mice = ['GF307', 'GF310', 'GF333', 'MI075', 'AR144', 'AR135']\n",
    "# mouse_list = [m for m in mouse_list if m not in excluded_mice]\n",
    "# # mouse_list = [m for m in mouse_list if m not in ['AR132', 'MI069']]\n",
    "# # mouse_list\n",
    "\n",
    "# # mouse_list = ['AR127', 'AR133', 'AR135', 'AR143', 'AR144', 'AR131', 'AR137','AR139']\n",
    "\n",
    "\n",
    "# session_list, nwb_files, _, _ = io.select_sessions_from_db(\n",
    "#     db_path, nwb_dir,\n",
    "#     experimenters=['AR', 'GF', 'MI'],\n",
    "#     exclude_cols=['exclude', 'two_p_exclude'],\n",
    "#     subject_id=mouse_list,\n",
    "#     day=['-2', '-1', '0', '+1', '+2'],\n",
    "#     two_p_imaging='yes')\n",
    "\n",
    "# act_map_rew = utils_imaging.shape_features_matrix(mouse_list, session_list, processed_dir, 'UM', 40)\n",
    "# # Subtract baselines.\n",
    "# act_map_rew = act_map_rew - np.nanmean(act_map_rew[:, :, baseline[0]:baseline[1]],\n",
    "#                                axis=2, keepdims=True)\n",
    "# act_learning = utils_imaging.shape_features_matrix(mouse_list, session_list, processed_dir, 'UM', n_trials)\n",
    "# # Subtract baselines.\n",
    "# act_learning = act_learning - np.nanmean(act_learning[:, :, baseline[0]:baseline[1]],\n",
    "#                                axis=2, keepdims=True)\n",
    "# mouse_list = ['AR127', 'AR133', 'AR135', 'AR143', 'AR144',]\n",
    "db = io.read_excel_db(db_path)\n",
    "db = db.loc[\n",
    "    (db.reward_group=='R-')\n",
    "            & (db.two_p_imaging=='yes')\n",
    "            & (db.exclude!='exclude')\n",
    "            & (db.two_p_exclude!='exclude')]\n",
    "mouse_list = list(db['subject_id'].unique())\n",
    "\n",
    "excluded_mice = ['GF307', 'GF310', 'GF333', 'MI075', 'AR144', 'AR135']\n",
    "mouse_list = [m for m in mouse_list if m not in excluded_mice]\n",
    "# mouse_list = [m for m in mouse_list if m not in ['AR132', 'MI069']]\n",
    "# mouse_list\n",
    "\n",
    "# mouse_list = ['AR127', 'AR133', 'AR135', 'AR143', 'AR144', 'AR131', 'AR137','AR139']\n",
    "\n",
    "session_list, nwb_files, _, _ = io.select_sessions_from_db(\n",
    "    db_path, nwb_dir,\n",
    "    experimenters=['AR', 'GF', 'MI'],\n",
    "    exclude_cols=['exclude', 'two_p_exclude'],\n",
    "    subject_id=mouse_list,\n",
    "    day=['-2', '-1', '0', '+1', '+2'],\n",
    "    two_p_imaging='yes')\n",
    "\n",
    "act_map_nonrew = utils_imaging.shape_features_matrix(mouse_list, session_list, processed_dir, 'WH', 10)\n",
    "# Subtract baselines.\n",
    "act_map_nonrew = act_map_nonrew - np.nanmean(act_map_nonrew[:, :, baseline[0]:baseline[1]],\n",
    "                               axis=2, keepdims=True)\n",
    "# act_learning = utils_imaging.shape_features_matrix(mouse_list, session_list, processed_dir, 'UM', n_trials)\n",
    "# # Subtract baselines.\n",
    "# act_learning = act_learning - np.nanmean(act_learning[:, :, baseline[0]:baseline[1]],\n",
    "#                                axis=2, keepdims=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'mice_dataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mmice_dataset\u001b[49m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'mice_dataset' is not defined"
     ]
    }
   ],
   "source": [
    "mice_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "act_map = np.concatenate((act_map_rew, act_map_nonrew), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from src.behavior import compute_performance, plot_single_session\n",
    "\n",
    "# nwb_files = [nwb for nwb in nwb_files if 'MI069' in nwb]\n",
    "# session_list = [s for s in session_list if 'MI069' in s]\n",
    "\n",
    "# # Add behavior of D0 below.\n",
    "# f = nwb_files[1]\n",
    "# session = session_list[1]\n",
    "# behav_table = nwb_read.get_trial_table(f)\n",
    "# behav_table = compute_performance(behav_table, session, db_path)\n",
    "\n",
    "# palette = sns.color_palette()\n",
    "# plot_single_session(behav_table, session)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200, 2078, 181)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# # min-max scaling for each neuron for values between [0,1]\n",
    "\n",
    "# data = np.transpose(act_learning, (1,0,2))\n",
    "# data = spnd.gaussian_filter1d(data.astype('float32'), sigma=2, axis=-1)\n",
    "# data = np.array([d / d.max() for d in np.array([d - d.min() for d in data])])\n",
    "\n",
    "# data = data - np.nanmean(data[:, :, baseline[0]:baseline[1]],\n",
    "#                                axis=2, keepdims=True)\n",
    "\n",
    "data = np.transpose(act_map_nonrew, (1,0,2))\n",
    "print(data.shape)\n",
    "data = spnd.gaussian_filter1d(data.astype('float32'), sigma=2, axis=-1)\n",
    "# data = data - np.mean(data, axis=(0,2), keepdims=True)\n",
    "data = data / np.std(data, axis=(0,2), keepdims=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save dataset to run on google colab.\n",
    "save_dir = r\"\\\\sv-nas1.rcp.epfl.ch\\Petersen-Lab\\analysis\\Anthony_Renard\\data_processed\\tca\"\n",
    "# dataset_name = 'wh_learning_whole_population_both_rew_groups.npy'\n",
    "dataset_name = 'um_whole_population_R-.npy'\n",
    "np.save(os.path.join(save_dir, dataset_name), data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# plt.figure()\n",
    "# for icell in range(50):\n",
    "#     plt.plot(np.mean(data[:,icell], axis=(0)))\n",
    "device = ('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n",
    "data = torch.tensor(data, dtype=torch.float, device=device)\n",
    "# The tensor is decomposed into 2 trial-, 0 neuron- and 3 time-slicing components.\n",
    "components, model = slicetca.decompose(data,\n",
    "                                       number_components=(3,3,3),\n",
    "                                       positive=True,\n",
    "                                       learning_rate=5*10**-3,\n",
    "                                       min_std=10**-3,\n",
    "                                       max_iter=10000,\n",
    "                                       seed=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "model_dir = r\"//sv-nas1.rcp.epfl.ch/Petersen-Lab/analysis/Anthony_Renard/analysis_output/tca/models\"\n",
    "model_name = 'model_wh_learning_whole_population_R+.pkl'\n",
    "# Load the model and components.\n",
    "\n",
    "device = torch.device('cpu')\n",
    "with open(os.path.join(model_dir, model_name), 'rb') as f:\n",
    "    model = torch.load(f, map_location=device, weights_only=False)\n",
    "    # model = torch.load(f, map_location=torch.device('cpu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\aprenard\\Anaconda3\\envs\\fast-learning\\Lib\\site-packages\\slicetca\\plotting\\factors.py:135: UserWarning: Tight layout not applied. tight_layout cannot make axes height small enough to accommodate all axes decorations.\n",
      "  if tight_layout: fig.tight_layout()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0.98, 'z-score')"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sns.set_theme(context='talk', style='ticks', palette='deep')\n",
    "palette = sns.color_palette()\n",
    "trial_colors = np.array([palette[i] for i in range(3) for _ in range(50)])\n",
    "axes = slicetca.plot(model,\n",
    "              variables=('trial', 'neuron', 'time'),\n",
    "              colors=(trial_colors, None, None), # we only want the trials to be colored\n",
    "              ticks=(None, None, np.linspace(0,181,4)), # we only want to modify the time ticks\n",
    "              tick_labels=(None, None, np.linspace(-1,5,4)),\n",
    "              sorting_indices=(None, None, None),\n",
    "              quantile=0.99)\n",
    "plt.gcf().suptitle('z-score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "slicetca.plot_grid(loss_grid, min_ranks=(6, 6, 6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function slicetca.plotting.factors.plot(model, components: Sequence[Sequence[numpy.ndarray]] = None, variables: Sequence[str] = ('trial', 'neuron', 'time'), colors: Union[Sequence[numpy.ndarray], Sequence[Sequence[float]]] = (None, None, None), sorting_indices: Sequence[numpy.ndarray] = (None, None, None), ticks: Sequence[numpy.ndarray] = (None, None, None), tick_labels: Sequence[numpy.ndarray] = (None, None, None), quantile: float = 0.95, factor_height: int = 2, aspect: str = 'auto', s: int = 10, cmap: str = None, tight_layout: bool = True, dpi: int = 60)>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "slicetca.plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[44.69899328],\n",
       "       [ 0.81649658]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "a = np.array([[1, 10, 100],[1,2,3]])\n",
    "np.std(a, axis=1, keepdims=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tca",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
