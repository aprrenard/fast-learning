{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import sys\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from matplotlib import colors\n",
    "from scipy.stats import mannwhitneyu, wilcoxon\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from scipy.stats import spearmanr\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "import xarray as xr\n",
    "\n",
    "# sys.path.append(r'H:/anthony/repos/NWB_analysis')\n",
    "sys.path.append(r'/home/aprenard/repos/NWB_analysis')\n",
    "sys.path.append(r'/home/aprenard/repos/fast-learning')\n",
    "# from nwb_wrappers import nwb_reader_functions as nwb_read\n",
    "import src.utils.utils_imaging as imaging_utils\n",
    "import src.utils.utils_io as io\n",
    "from src.behavior import compute_performance, plot_single_session\n",
    "import warnings\n",
    "\n",
    "# Set plot parameters.\n",
    "plt.rcParams['pdf.fonttype'] = 42\n",
    "plt.rcParams['ps.fonttype'] = 42\n",
    "plt.rcParams['svg.fonttype'] = 'none'\n",
    "sns.set_theme(context='paper', style='ticks', palette='deep', font='sans-serif', font_scale=1)\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to the directory containing the processed data.\n",
    "processed_dir = io.solve_common_paths('processed_data')\n",
    "nwb_dir = io.solve_common_paths('nwb')\n",
    "db_path = io.solve_common_paths('db')\n",
    "# Session metadata file.\n",
    "\n",
    "# # Rewarded and non-rewarded NWB files.\n",
    "# group_yaml_rew = r\"//sv-nas1.rcp.epfl.ch/Petersen-Lab/analysis/Anthony_Renard/mice_info/groups/imaging_rewarded.yaml\"\n",
    "# group_yaml_non_rew = r\"//sv-nas1.rcp.epfl.ch/Petersen-Lab/analysis/Anthony_Renard/mice_info/groups/imaging_non_rewarded.yaml\"\n",
    "# nwb_list_rew = io.read_group_yaml(group_yaml_rew)\n",
    "# nwb_list_non_rew = io.read_group_yaml(group_yaml_non_rew)\n",
    "# nwb_list = nwb_list_rew + nwb_list_non_rew"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(np.zeros((10, 10)))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Illustrations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['AR127_20240221_133407', 'AR127_20240222_152629', 'AR127_20240223_131820', 'AR127_20240224_140853', 'AR127_20240225_142858']\n"
     ]
    }
   ],
   "source": [
    "sampling_rate = 30\n",
    "win = (1, 1.3)  # from stimulus onset to 300 ms after.\n",
    "win = (int(win[0] * sampling_rate), int(win[1] * sampling_rate))\n",
    "baseline_win = (0, 1)\n",
    "baseline_win = (int(baseline_win[0] * sampling_rate), int(baseline_win[1] * sampling_rate))\n",
    "days = ['-2', '-1', '0', '+1', '+2']\n",
    "\n",
    "mouse_id = 'AR127'\n",
    "\n",
    "session_list, nwb_files, _, db_filtered = io.select_sessions_from_db(db_path,\n",
    "                                                                    nwb_dir,\n",
    "                                                                    two_p_imaging='yes',\n",
    "                                                                    subject_id=mouse_id,\n",
    "                                                                    day=days,)\n",
    "print(session_list)\n",
    "\n",
    "data = []\n",
    "mdata_list = []\n",
    "for session_id in session_list:\n",
    "    arr, mdata = imaging_utils.load_session_2p_imaging(mouse_id,\n",
    "                                                        session_id,\n",
    "                                                        processed_dir)\n",
    "    arr = imaging_utils.substract_baseline(arr, 3, baseline_win)\n",
    "    data.append(arr)\n",
    "    mdata_list.append(mdata)\n",
    "\n",
    "# Extract UM trials.\n",
    "for i, arr in enumerate(data):\n",
    "    arr = imaging_utils.extract_trials(arr, mdata_list[i], 'UM', n_trials=None)\n",
    "    data[i] = arr\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aprenard\\AppData\\Local\\Temp\\ipykernel_12556\\2479694653.py:2: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`). Consider using `matplotlib.pyplot.close()`.\n",
      "  fig, axes = plt.subplots(1, 2)\n"
     ]
    }
   ],
   "source": [
    "for icell in range(90, 120):\n",
    "    fig, axes = plt.subplots(1, 2)\n",
    "\n",
    "    for itrial in range(50):\n",
    "        axes[0].plot(data[2][icell, itrial, :] + itrial * 2)\n",
    "    axes[1].plot(data[2][icell, :, :].mean(axis=0))\n",
    "    plt.suptitle(f'Cell {icell}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x257dac34f80>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Plot a single population vector.\n",
    "itrial = 0\n",
    "pop_vector = data[2][:87,itrial,win[0]:win[1]].mean(axis=1)\n",
    "pop_vector = np.repeat(pop_vector[:, np.newaxis], 10, axis=1)\n",
    "vmin = np.percentile(pop_vector, 2)\n",
    "vmax = np.percentile(pop_vector, 98)\n",
    "plt.figure()\n",
    "plt.imshow(pop_vector,cmap='viridis', vmin=vmin, vmax=vmax, aspect=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot LMI vector.\n",
    "lmi = np.load(r'\\\\sv-nas1.rcp.epfl.ch\\Petersen-Lab\\analysis\\Anthony_Renard\\data_processed\\lmi.npy', allow_pickle=True).item()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 3.125000e-04,  1.506250e-01, -7.000000e-02,  1.215625e-01,\n",
       "       -2.468750e-02, -4.518750e-01,  8.562500e-02, -1.734375e-01,\n",
       "        2.156250e-02, -3.968750e-02, -3.203125e-01, -7.500000e-01,\n",
       "       -9.750000e-02, -2.125000e-02, -4.209375e-01,  4.687500e-02,\n",
       "       -6.343750e-02,  1.684375e-01,  9.468750e-02,  1.468750e-02,\n",
       "       -1.665625e-01, -2.384375e-01, -1.812500e-02,  4.843750e-02,\n",
       "        2.437500e-02,  1.375000e-01, -1.225000e-01, -2.662500e-01,\n",
       "        2.300000e-01, -7.687500e-02,  2.750000e-02,  5.343750e-02,\n",
       "       -1.987500e-01, -7.384375e-01, -1.081250e-01, -1.893750e-01,\n",
       "       -2.362500e-01, -2.593750e-02, -6.256250e-01, -1.781250e-02,\n",
       "       -2.812500e-02, -2.362500e-01,  1.531250e-02,  9.375000e-02,\n",
       "       -1.162500e-01, -5.656250e-02,  2.165625e-01, -2.684375e-01,\n",
       "       -9.268750e-01, -4.375000e-02, -4.812500e-02, -2.743750e-01,\n",
       "        8.000000e-02, -1.459375e-01, -1.206250e-01,  1.753125e-01,\n",
       "       -2.900000e-01,  2.403125e-01, -3.218750e-02,  1.687500e-02,\n",
       "       -9.250000e-02, -1.734375e-01,  1.321875e-01, -4.456250e-01,\n",
       "       -1.731250e-01, -1.625000e-01, -1.846875e-01,  8.187500e-02,\n",
       "        1.937500e-02, -2.256250e-01, -1.515625e-01, -6.187500e-02,\n",
       "       -3.540625e-01, -2.571875e-01,  1.781250e-02, -1.515625e-01,\n",
       "       -5.625000e-02,  2.343750e-02,  1.750000e-02,  2.968750e-02,\n",
       "       -6.321875e-01,  1.037500e-01, -1.328125e-01, -2.221875e-01,\n",
       "       -9.687500e-03, -7.656250e-02,  4.871875e-01, -1.093750e-01,\n",
       "       -1.193750e-01,  1.125000e-02, -1.646875e-01, -5.750000e-02,\n",
       "        6.625000e-02, -9.250000e-02, -1.212500e-01, -1.031250e-02,\n",
       "       -1.078125e-01, -7.968750e-02, -6.500000e-02, -5.156250e-02,\n",
       "        2.968750e-02, -1.259375e-01, -4.218750e-02, -1.393750e-01,\n",
       "       -7.325000e-01, -8.750000e-03, -1.171875e-01,  4.531250e-02,\n",
       "       -1.218750e-02,  3.171875e-01,  3.262500e-01,  7.281250e-02,\n",
       "       -2.562500e-02, -1.203125e-01,  1.218750e-01, -1.556250e-01,\n",
       "       -2.193750e-01, -7.906250e-02, -5.656250e-02, -8.093750e-02,\n",
       "       -2.268750e-01, -2.012500e-01, -3.037500e-01, -3.000000e-02,\n",
       "        1.750000e-02, -2.150000e-01, -2.165625e-01, -3.906250e-02,\n",
       "        2.562500e-02, -2.031250e-01, -1.978125e-01, -6.156250e-02,\n",
       "       -1.437500e-01,  6.031250e-02,  2.968750e-02, -1.962500e-01,\n",
       "        7.593750e-02,  2.250000e-02, -4.937500e-02, -3.818750e-01,\n",
       "        6.031250e-02,  1.906250e-02, -2.875000e-02,  8.281250e-02,\n",
       "        0.000000e+00, -1.018750e-01,  5.106250e-01, -7.812500e-02,\n",
       "        1.096875e-01, -5.500000e-02,  5.656250e-02,  1.843750e-02,\n",
       "       -2.646875e-01, -8.490625e-01, -2.687500e-02,  3.968750e-02,\n",
       "       -6.375000e-02,  2.031250e-02, -8.750000e-02,  8.125000e-02,\n",
       "        9.000000e-02, -7.968750e-02, -1.428125e-01, -1.034375e-01,\n",
       "        1.003125e-01,  2.084375e-01, -7.403125e-01, -2.781250e-01,\n",
       "       -7.937500e-02, -9.000000e-02,  5.937500e-03, -1.290625e-01,\n",
       "       -7.968750e-02,  8.500000e-02,  2.656250e-02, -5.390625e-01,\n",
       "        1.093750e-02, -2.021875e-01, -6.781250e-02, -1.931250e-01])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "lmi['AR127']['allcells']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.colorbar.Colorbar at 0x257f026fbc0>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "f, axes = plt.subplots(1, 2, sharey=True)\n",
    "im = axes[0].imshow(np.repeat(lmi['AR127']['allcells'][:, np.newaxis], 10, axis=1), cmap='coolwarm', vmin=-.5, vmax=.5)\n",
    "plt.colorbar(im)\n",
    "# vmax = np.percentile(pop_vectors_dict[mouse_id]['allcells'], 99)\n",
    "# vmin = np.percentile(pop_vectors_dict[mouse_id]['allcells'], 1)\n",
    "# im = axes[1].imshow(pop_vectors_dict[mouse_id]['allcells'], cmap='viridis', vmin=vmin, vmax=vmax)\n",
    "# plt.colorbar(im)\n",
    "# print(vmin, vmax)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute LMI and responsniveness"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Responses to unmotivated mapping trials across learning days."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1. PSTH of unmotivated mapping trials across learning days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['GF305', 'GF306', 'GF307', 'GF308', 'GF310', 'GF311', 'GF313', 'GF314', 'GF317', 'GF318', 'GF319', 'GF323', 'GF333', 'GF334', 'GF348', 'GF350', 'MI062', 'MI069', 'MI072', 'MI075', 'MI076', 'AR132', 'AR133', 'AR137', 'AR139', 'AR127', 'AR143', 'AR177', 'AR178', 'AR179', 'AR180']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "31"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load data needed to compute before and after learning.\n",
    "\n",
    "sampling_rate = 30\n",
    "win_sec = (0.8, 3)  \n",
    "win = (int(win_sec[0] * sampling_rate), int(win_sec[1] * sampling_rate))\n",
    "baseline_win = (0, 1)\n",
    "baseline_win = (int(baseline_win[0] * sampling_rate), int(baseline_win[1] * sampling_rate))\n",
    "days = ['-2', '-1', '0', '+1', '+2']\n",
    "# Correlation matrix for a specific cell type\n",
    "cell_type = None\n",
    "variance_explained_thr = 0.7\n",
    "\n",
    "_, _, mice, _ = io.select_sessions_from_db(db_path,\n",
    "                                            nwb_dir,\n",
    "                                            two_p_imaging='yes')\n",
    "mice = [m for m in mice if m not in ['AR163']]\n",
    "print(mice)\n",
    "len(mice)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['GF305_27112020_083119', 'GF305_28112020_103938', 'GF305_29112020_103331', 'GF305_30112020_110255', 'GF305_02122020_132229']\n",
      "here (133, 40, 181)\n",
      "here (133, 40, 181)\n",
      "here (133, 40, 181)\n",
      "here (133, 40, 181)\n",
      "here (133, 40, 181)\n",
      "['GF306_27112020_104436', 'GF306_28112020_125555', 'GF306_29112020_131929', 'GF306_30112020_133249', 'GF306_02122020_161611']\n",
      "here (215, 40, 181)\n",
      "here (215, 40, 181)\n",
      "here (215, 40, 181)\n",
      "here (215, 40, 181)\n",
      "here (215, 40, 181)\n",
      "['GF307_17112020_080325', 'GF307_18112020_075939', 'GF307_19112020_083908', 'GF307_20112020_082942', 'GF307_21112020_102608']\n",
      "here (150, 40, 181)\n",
      "here (150, 40, 181)\n",
      "here (150, 40, 181)\n",
      "here (150, 40, 181)\n",
      "here (150, 40, 181)\n",
      "['GF308_17112020_105052', 'GF308_18112020_093627', 'GF308_19112020_103527', 'GF308_20112020_122826', 'GF308_21112020_135515']\n",
      "here (147, 40, 181)\n",
      "here (147, 40, 181)\n",
      "here (147, 40, 181)\n",
      "here (147, 40, 181)\n",
      "here (147, 40, 181)\n",
      "['GF310_17112020_132720', 'GF310_18112020_122252', 'GF310_19112020_131953', 'GF310_20112020_150929', 'GF310_21112020_160059']\n",
      "here (243, 40, 181)\n",
      "here (243, 40, 181)\n",
      "here (243, 40, 181)\n",
      "here (243, 40, 181)\n",
      "here (243, 40, 181)\n",
      "['GF311_17112020_155501', 'GF311_18112020_151838', 'GF311_19112020_160412', 'GF311_20112020_171609', 'GF311_21112020_180049']\n",
      "here (105, 40, 181)\n",
      "here (105, 40, 181)\n",
      "here (105, 40, 181)\n",
      "here (105, 40, 181)\n",
      "here (105, 40, 181)\n",
      "['GF313_27112020_141857', 'GF313_28112020_154236', 'GF313_29112020_154625', 'GF313_30112020_154904', 'GF313_03122020_082147']\n",
      "here (164, 40, 181)\n",
      "here (164, 40, 181)\n",
      "here (164, 40, 181)\n",
      "here (164, 40, 181)\n",
      "here (164, 40, 181)\n",
      "['GF314_27112020_160459', 'GF314_28112020_171800', 'GF314_29112020_174831', 'GF314_30112020_171906', 'GF314_03122020_102249']\n",
      "here (197, 40, 181)\n",
      "here (197, 40, 181)\n",
      "here (197, 40, 181)\n",
      "here (197, 40, 181)\n",
      "here (197, 40, 181)\n",
      "['GF317_15122020_081931', 'GF317_16122020_082007', 'GF317_17122020_080715', 'GF317_18122020_104834', 'GF317_20122020_120604']\n",
      "here (146, 40, 181)\n",
      "here (146, 40, 181)\n",
      "here (146, 40, 181)\n",
      "here (146, 40, 181)\n",
      "here (146, 40, 181)\n",
      "['GF318_15122020_095616', 'GF318_16122020_095516', 'GF318_17122020_144100', 'GF318_18122020_132105', 'GF318_19122020_155806']\n",
      "here (140, 40, 181)\n",
      "here (140, 40, 181)\n",
      "here (140, 40, 181)\n",
      "here (140, 40, 181)\n",
      "here (140, 40, 181)\n",
      "['GF319_24122020_120204', 'GF319_25122020_142951', 'GF319_26122020_144746', 'GF319_27122020_135842', 'GF319_28122020_132438']\n",
      "here (154, 40, 181)\n",
      "here (154, 40, 181)\n",
      "here (154, 40, 181)\n",
      "here (154, 40, 181)\n",
      "here (154, 40, 181)\n",
      "['GF323_07012021_092005', 'GF323_08012021_083725', 'GF323_09012021_111716', 'GF323_11012021_084126', 'GF323_12012021_090219']\n",
      "here (305, 40, 181)\n",
      "here (305, 40, 181)\n",
      "here (305, 40, 181)\n",
      "here (305, 40, 181)\n",
      "here (305, 40, 181)\n",
      "['GF333_21012021_125450', 'GF333_22012021_135939', 'GF333_24012021_145617', 'GF333_25012021_141608', 'GF333_26012021_142304']\n",
      "here (124, 40, 181)\n",
      "here (124, 40, 181)\n",
      "here (124, 40, 181)\n",
      "here (124, 40, 181)\n",
      "here (124, 40, 181)\n",
      "['GF334_21012021_160130', 'GF334_22012021_153815', 'GF334_24012021_173019', 'GF334_25012021_163843', 'GF334_26012021_171010']\n",
      "here (130, 40, 181)\n",
      "here (130, 40, 181)\n",
      "here (130, 40, 181)\n",
      "here (130, 40, 181)\n",
      "here (130, 40, 181)\n",
      "['GF348_29052021_100151', 'GF348_30052021_110107', 'GF348_31052021_102411', 'GF348_01062021_095758', 'GF348_02062021_084344']\n",
      "here (206, 40, 181)\n",
      "here (206, 40, 181)\n",
      "here (206, 40, 181)\n",
      "here (206, 40, 181)\n",
      "here (206, 40, 181)\n",
      "['GF350_29052021_124022', 'GF350_30052021_123155', 'GF350_31052021_135001', 'GF350_01062021_122420', 'GF350_02062021_142138']\n",
      "here (211, 40, 181)\n",
      "here (211, 40, 181)\n",
      "here (211, 40, 181)\n",
      "here (211, 40, 181)\n",
      "here (211, 40, 181)\n",
      "['MI062_30092021_091006', 'MI062_01102021_091233', 'MI062_02102021_105027', 'MI062_03102021_103851', 'MI062_04102021_092339']\n",
      "here (108, 40, 181)\n",
      "here (108, 40, 181)\n",
      "here (108, 40, 181)\n",
      "here (108, 40, 181)\n",
      "here (108, 40, 181)\n",
      "['MI069_19122021_100830', 'MI069_20122021_095058', 'MI069_21122021_090648', 'MI069_22122021_090212', 'MI069_23122021_085758']\n",
      "here (218, 40, 181)\n",
      "here (218, 40, 181)\n",
      "here (218, 40, 181)\n",
      "here (218, 40, 181)\n",
      "here (218, 40, 181)\n",
      "['MI072_19122021_140553', 'MI072_20122021_125805', 'MI072_21122021_132704', 'MI072_22122021_132651', 'MI072_23122021_132111']\n",
      "here (244, 40, 181)\n",
      "here (244, 40, 181)\n",
      "here (244, 40, 181)\n",
      "here (244, 40, 181)\n",
      "here (244, 40, 181)\n",
      "['MI075_19122021_152533', 'MI075_20122021_155245', 'MI075_21122021_151949', 'MI075_22122021_152806', 'MI075_23122021_150004']\n",
      "here (189, 40, 181)\n",
      "here (189, 40, 181)\n",
      "here (189, 40, 181)\n",
      "here (189, 40, 181)\n",
      "here (189, 40, 181)\n",
      "['MI076_19122021_120004', 'MI076_20122021_113038', 'MI076_21122021_112146', 'MI076_22122021_114039', 'MI076_23122021_113818']\n",
      "here (268, 40, 181)\n",
      "here (268, 40, 181)\n",
      "here (268, 40, 181)\n",
      "here (268, 40, 181)\n",
      "here (268, 40, 181)\n",
      "['AR132_20240424_112338', 'AR132_20240425_102625', 'AR132_20240426_093953', 'AR132_20240427_122605', 'AR132_20240428_122206']\n",
      "here (182, 40, 181)\n",
      "here (182, 40, 181)\n",
      "here (182, 40, 181)\n",
      "here (182, 40, 181)\n",
      "here (182, 40, 181)\n",
      "['AR133_20240424_130306', 'AR133_20240425_115233', 'AR133_20240426_113430', 'AR133_20240427_142253', 'AR133_20240428_134911']\n",
      "here (144, 40, 181)\n",
      "here (144, 40, 181)\n",
      "here (144, 40, 181)\n",
      "here (144, 40, 181)\n",
      "here (144, 40, 181)\n",
      "['AR137_20240424_172627', 'AR137_20240425_170755', 'AR137_20240426_152510', 'AR137_20240427_171535', 'AR137_20240428_163224']\n",
      "here (180, 40, 181)\n",
      "here (180, 40, 181)\n",
      "here (180, 40, 181)\n",
      "here (180, 40, 181)\n",
      "here (180, 40, 181)\n",
      "['AR139_20240424_185913', 'AR139_20240425_181627', 'AR139_20240426_165725', 'AR139_20240427_183701', 'AR139_20240428_180459']\n",
      "here (138, 40, 181)\n",
      "here (138, 40, 181)\n",
      "here (138, 40, 181)\n",
      "here (138, 40, 181)\n",
      "here (138, 40, 181)\n",
      "['AR127_20240221_133407', 'AR127_20240222_152629', 'AR127_20240223_131820', 'AR127_20240224_140853', 'AR127_20240225_142858']\n",
      "here (180, 40, 181)\n",
      "here (180, 40, 181)\n",
      "here (180, 40, 181)\n",
      "here (180, 40, 181)\n",
      "here (180, 40, 181)\n",
      "['AR143_20240518_174556', 'AR143_20240519_141725', 'AR143_20240520_130137', 'AR143_20240521_125833', 'AR143_20240522_172846']\n",
      "here (205, 40, 181)\n",
      "here (205, 40, 181)\n",
      "here (205, 40, 181)\n",
      "here (205, 40, 181)\n",
      "here (205, 40, 181)\n",
      "['AR177_20241217_170649', 'AR177_20241218_145859', 'AR177_20241219_145458', 'AR177_20241220_134735', 'AR177_20241221_121706']\n",
      "here (118, 40, 181)\n",
      "here (118, 40, 181)\n",
      "here (118, 40, 181)\n",
      "here (118, 40, 181)\n",
      "here (118, 40, 181)\n",
      "['AR178_20241213_121925', 'AR178_20241214_164041', 'AR178_20241215_143044', 'AR178_20241216_111129', 'AR178_20241217_120522']\n",
      "here (138, 40, 181)\n",
      "here (138, 40, 181)\n",
      "here (138, 40, 181)\n",
      "here (138, 40, 181)\n",
      "here (138, 40, 181)\n",
      "['AR179_20241214_181515', 'AR179_20241215_174436', 'AR179_20241216_125718', 'AR179_20241217_144120', 'AR179_20241218_132943']\n",
      "here (133, 40, 181)\n",
      "here (133, 40, 181)\n",
      "here (133, 40, 181)\n",
      "here (133, 40, 181)\n",
      "here (133, 40, 181)\n",
      "['AR180_20241213_150420', 'AR180_20241214_194639', 'AR180_20241215_190049', 'AR180_20241216_145407', 'AR180_20241217_160355']\n",
      "here (113, 40, 181)\n",
      "here (113, 40, 181)\n",
      "here (113, 40, 181)\n",
      "here (113, 40, 181)\n",
      "here (113, 40, 181)\n"
     ]
    }
   ],
   "source": [
    "psth = {}\n",
    "metadata = {}\n",
    "responsive_p_values = {}\n",
    "\n",
    "for mouse_id in mice:\n",
    "    # Disregard these mice as the number of trials is too low.\n",
    "    # if mouse_id in ['GF307', 'GF310', 'GF333', 'AR144', 'AR135']:\n",
    "    #     continue\n",
    "    session_list, nwb_files, _, db_filtered = io.select_sessions_from_db(db_path,\n",
    "                                                                        nwb_dir,\n",
    "                                                                        two_p_imaging='yes',\n",
    "                                                                        subject_id=mouse_id,\n",
    "                                                                        day=days,)\n",
    "    print(session_list)\n",
    "\n",
    "    data = []\n",
    "    mdata_list = []\n",
    "    for session_id in session_list:\n",
    "        arr, mdata = imaging_utils.load_session_2p_imaging(mouse_id,\n",
    "                                                            session_id,\n",
    "                                                            processed_dir)\n",
    "        arr = imaging_utils.substract_baseline(arr, 3, baseline_win)\n",
    "        data.append(arr)\n",
    "        mdata_list.append(mdata)\n",
    "\n",
    "    # Extract UM trials.\n",
    "    for i, arr in enumerate(data):\n",
    "        arr = imaging_utils.extract_trials(arr, mdata_list[i], 'A', n_trials=40)\n",
    "        data[i] = arr\n",
    "\n",
    "    # Get some metadata.\n",
    "    reward_group = io.get_reward_group_from_db(db_path, session_list[0])\n",
    "    metadata[mouse_id] = {}\n",
    "    metadata[mouse_id]['reward_group'] = reward_group\n",
    "    metadata[mouse_id]['cell_types'] = mdata['cell_types']\n",
    "    metadata[mouse_id][\"rois\"] = mdata['rois']\n",
    "    \n",
    "    psth[mouse_id] = {}\n",
    "    responsive_p_values[mouse_id] = {}\n",
    "\n",
    "    for cell_type in ['allcells', 'wS2', 'wM1']:\n",
    "        # Select cell type.\n",
    "        if cell_type == 'allcells':\n",
    "            data_subtype = data\n",
    "        else:\n",
    "            data_subtype = []\n",
    "            cell_type_mask = mdata_list[0]['cell_types']==cell_type\n",
    "            data_subtype = [arr[cell_type_mask] for arr in data]\n",
    "\n",
    "        # If no cells of the specified type, skip.\n",
    "        if data_subtype[0].shape[0] == 0:\n",
    "            continue\n",
    "\n",
    "        # Compute average response for each trial, each day.\n",
    "        # --------------------------------------------------\n",
    "\n",
    "        psth[mouse_id][cell_type] = []\n",
    "        for day in data_subtype:\n",
    "            psth[mouse_id][cell_type].append(np.nanmean(day[:, :, win[0]:win[1]], axis=1))\n",
    "\n",
    "        # # Test responsiveness.\n",
    "        # # --------------------\n",
    "\n",
    "        # baseline_avg = []\n",
    "        # response_avg = []\n",
    "        # for day in data_subtype:\n",
    "        #     baseline_avg.append(np.nanmean(day[:, :, baseline_win[0]:baseline_win[1]], axis=2))\n",
    "        #     response_avg.append(np.nanmean(day[:, :, win[0]:win[1]], axis=2))\n",
    "\n",
    "        # # Compare response amplitude to baseline.\n",
    "        # n_cells = data_subtype[0].shape[0]\n",
    "        # p_values = [np.zeros(n_cells) for _ in range(len(data_subtype))]\n",
    "        # for iday, day in enumerate(data_subtype):\n",
    "        #     for icell in range(n_cells):\n",
    "        #         # Temporary fix for cells that are always 0 due to baseline substraction.\n",
    "        #         if np.all(baseline_avg[iday][icell] == 0.):\n",
    "        #             p_values[iday][icell] = 1\n",
    "        #         else:\n",
    "        #             _, p_values[iday][icell] = wilcoxon(baseline_avg[iday][icell], response_avg[iday][icell])\n",
    "        # p_values = np.stack(p_values, axis=0)\n",
    "        # responsive_p_values[mouse_id][cell_type] = p_values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot PSTH's for all cells and projectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to pandas.\n",
    "mouse_ids = list(psth.keys())\n",
    "df = []\n",
    "\n",
    "for mouse_id in mouse_ids:\n",
    "    # if mouse_id == 'GF308':\n",
    "    #     continue\n",
    "    \n",
    "    for icell, roi in enumerate(metadata[mouse_id]['rois']):\n",
    "        time = np.linspace(win_sec[0], win_sec[1], psth[mouse_id]['allcells'][0].shape[1]) - 1\n",
    "        cell_type = metadata[mouse_id]['cell_types'][icell]\n",
    "        for iday in range(len(days)):\n",
    "            trace = psth[mouse_id]['allcells'][iday][icell]\n",
    "            temp = pd.DataFrame(np.stack([time, trace], axis=1), columns=['time', 'activity'])\n",
    "            temp['day'] = days[iday]\n",
    "            temp['mouse_id'] = mouse_id\n",
    "            temp['roi'] = roi\n",
    "            temp['cell_type'] = cell_type\n",
    "            temp['reward_group'] = metadata[mouse_id]['reward_group']\n",
    "            df.append(temp)\n",
    "df = pd.concat(df)\n",
    "df = df.reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot.\n",
    "data = df.loc[df.time<1.5]\n",
    "\n",
    "# GF305 has baseline artefact on day -1 at auditory trials.\n",
    "data = data.loc[~data.mouse_id.isin(['GF305'])]\n",
    "\n",
    "data = data.loc[data['day'].isin(['-2', '-1', '0', '+1', '+2'])]\n",
    "# data = data.loc[data['cell_type']=='wM1']\n",
    "# df = df.loc[df.mouse_id.isin(['GF305', 'GF306', 'GF307'])]\n",
    "fig = sns.relplot(data=data, x='time', y='activity', errorbar='ci', col='day',\n",
    "            kind='line', hue='reward_group',\n",
    "            hue_order=['R-','R+'], palette=sns.color_palette(['#d51a1c', '#238443']),\n",
    "            height=3, aspect=0.8)\n",
    "for ax in fig.axes.flatten():\n",
    "    ax.axvline(0, color='#FF9600', linestyle='--')\n",
    "    ax.set_title('')    \n",
    "\n",
    "fig = sns.relplot(data=data, x='time', y='activity', errorbar='se', col='day', row='cell_type',\n",
    "            kind='line', hue='reward_group',\n",
    "            hue_order=['R-','R+'], palette=sns.color_palette(['#d51a1c', '#238443']), row_order=['wS2', 'wM1',],\n",
    "            height=3, aspect=0.8)\n",
    "for ax in fig.axes.flatten():\n",
    "    ax.axvline(0, color='#FF9600', linestyle='--')\n",
    "    ax.set_title('')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Single PSTH's per mouse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_file = f'psth_individual_mice_auditory.pdf'\n",
    "output_dir = fr'//sv-nas1.rcp.epfl.ch/Petersen-Lab/analysis/Anthony_Renard/analysis_output/sensory_plasticity/psth'\n",
    "\n",
    "with PdfPages(os.path.join(output_dir, pdf_file)) as pdf:\n",
    "    for mouse_id in mice:\n",
    "        # Plot.\n",
    "        data = df.loc[df['day'].isin(['-2', '-1', '0', '+1', '+2'])\n",
    "                      & (df['mouse_id'] == mouse_id)]\n",
    "\n",
    "        sns.relplot(data=data, x='time', y='activity', errorbar='se', col='day', row='cell_type',\n",
    "                    kind='line', hue='reward_group',\n",
    "                    hue_order=['R-','R+'], palette=sns.color_palette(['#d51a1c', '#238443']))\n",
    "        plt.suptitle(mouse_id)\n",
    "        # pdf.savefig(dpi=300)\n",
    "        # plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PSTH's during learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['GF305', 'GF306', 'GF307', 'GF308', 'GF310', 'GF311', 'GF313', 'GF314', 'GF317', 'GF318', 'GF319', 'GF323', 'GF333', 'GF334', 'GF348', 'GF350', 'MI062', 'MI069', 'MI072', 'MI075', 'MI076', 'AR132', 'AR133', 'AR137', 'AR139', 'AR127', 'AR143', 'AR177', 'AR178', 'AR179', 'AR180']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "31"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load data needed to compute before and after learning.\n",
    "\n",
    "sampling_rate = 30\n",
    "win_sec = (0.8, 3)  \n",
    "win = (int(win_sec[0] * sampling_rate), int(win_sec[1] * sampling_rate))\n",
    "baseline_win = (0, 1)\n",
    "baseline_win = (int(baseline_win[0] * sampling_rate), int(baseline_win[1] * sampling_rate))\n",
    "days = ['-2', '-1', '0', '+1', '+2']\n",
    "\n",
    "_, _, mice, _ = io.select_sessions_from_db(db_path,\n",
    "                                            nwb_dir,\n",
    "                                            two_p_imaging='yes')\n",
    "mice = [m for m in mice if m not in ['AR163']]\n",
    "print(mice)\n",
    "len(mice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['GF305_27112020_083119', 'GF305_28112020_103938', 'GF305_29112020_103331', 'GF305_30112020_110255', 'GF305_02122020_132229']\n",
      "here (133, 40, 181)\n",
      "here (133, 40, 181)\n",
      "here (133, 40, 181)\n",
      "here (133, 40, 181)\n",
      "here (133, 40, 181)\n",
      "['GF306_27112020_104436', 'GF306_28112020_125555', 'GF306_29112020_131929', 'GF306_30112020_133249', 'GF306_02122020_161611']\n",
      "here (215, 40, 181)\n",
      "here (215, 40, 181)\n",
      "here (215, 40, 181)\n",
      "here (215, 40, 181)\n",
      "here (215, 40, 181)\n",
      "['GF307_17112020_080325', 'GF307_18112020_075939', 'GF307_19112020_083908', 'GF307_20112020_082942', 'GF307_21112020_102608']\n",
      "here (150, 40, 181)\n",
      "here (150, 40, 181)\n",
      "here (150, 40, 181)\n",
      "here (150, 40, 181)\n",
      "here (150, 40, 181)\n",
      "['GF308_17112020_105052', 'GF308_18112020_093627', 'GF308_19112020_103527', 'GF308_20112020_122826', 'GF308_21112020_135515']\n",
      "here (147, 40, 181)\n",
      "here (147, 40, 181)\n",
      "here (147, 40, 181)\n",
      "here (147, 40, 181)\n",
      "here (147, 40, 181)\n",
      "['GF310_17112020_132720', 'GF310_18112020_122252', 'GF310_19112020_131953', 'GF310_20112020_150929', 'GF310_21112020_160059']\n",
      "here (243, 40, 181)\n",
      "here (243, 40, 181)\n",
      "here (243, 40, 181)\n",
      "here (243, 40, 181)\n",
      "here (243, 40, 181)\n",
      "['GF311_17112020_155501', 'GF311_18112020_151838', 'GF311_19112020_160412', 'GF311_20112020_171609', 'GF311_21112020_180049']\n",
      "here (105, 40, 181)\n",
      "here (105, 40, 181)\n",
      "here (105, 40, 181)\n",
      "here (105, 40, 181)\n",
      "here (105, 40, 181)\n",
      "['GF313_27112020_141857', 'GF313_28112020_154236', 'GF313_29112020_154625', 'GF313_30112020_154904', 'GF313_03122020_082147']\n",
      "here (164, 40, 181)\n",
      "here (164, 40, 181)\n",
      "here (164, 40, 181)\n",
      "here (164, 40, 181)\n",
      "here (164, 40, 181)\n",
      "['GF314_27112020_160459', 'GF314_28112020_171800', 'GF314_29112020_174831', 'GF314_30112020_171906', 'GF314_03122020_102249']\n",
      "here (197, 40, 181)\n",
      "here (197, 40, 181)\n",
      "here (197, 40, 181)\n",
      "here (197, 40, 181)\n",
      "here (197, 40, 181)\n",
      "['GF317_15122020_081931', 'GF317_16122020_082007', 'GF317_17122020_080715', 'GF317_18122020_104834', 'GF317_20122020_120604']\n",
      "here (146, 40, 181)\n",
      "here (146, 40, 181)\n",
      "here (146, 40, 181)\n",
      "here (146, 40, 181)\n",
      "here (146, 40, 181)\n",
      "['GF318_15122020_095616', 'GF318_16122020_095516', 'GF318_17122020_144100', 'GF318_18122020_132105', 'GF318_19122020_155806']\n",
      "here (140, 40, 181)\n",
      "here (140, 40, 181)\n",
      "here (140, 40, 181)\n",
      "here (140, 40, 181)\n",
      "here (140, 40, 181)\n",
      "['GF319_24122020_120204', 'GF319_25122020_142951', 'GF319_26122020_144746', 'GF319_27122020_135842', 'GF319_28122020_132438']\n",
      "here (154, 40, 181)\n",
      "here (154, 40, 181)\n",
      "here (154, 40, 181)\n",
      "here (154, 40, 181)\n",
      "here (154, 40, 181)\n",
      "['GF323_07012021_092005', 'GF323_08012021_083725', 'GF323_09012021_111716', 'GF323_11012021_084126', 'GF323_12012021_090219']\n",
      "here (305, 40, 181)\n",
      "here (305, 40, 181)\n",
      "here (305, 40, 181)\n",
      "here (305, 40, 181)\n",
      "here (305, 40, 181)\n",
      "['GF333_21012021_125450', 'GF333_22012021_135939', 'GF333_24012021_145617', 'GF333_25012021_141608', 'GF333_26012021_142304']\n",
      "here (124, 40, 181)\n",
      "here (124, 40, 181)\n",
      "here (124, 40, 181)\n",
      "here (124, 40, 181)\n",
      "here (124, 40, 181)\n",
      "['GF334_21012021_160130', 'GF334_22012021_153815', 'GF334_24012021_173019', 'GF334_25012021_163843', 'GF334_26012021_171010']\n",
      "here (130, 40, 181)\n",
      "here (130, 40, 181)\n",
      "here (130, 40, 181)\n",
      "here (130, 40, 181)\n",
      "here (130, 40, 181)\n",
      "['GF348_29052021_100151', 'GF348_30052021_110107', 'GF348_31052021_102411', 'GF348_01062021_095758', 'GF348_02062021_084344']\n",
      "here (206, 40, 181)\n",
      "here (206, 40, 181)\n",
      "here (206, 40, 181)\n",
      "here (206, 40, 181)\n",
      "here (206, 40, 181)\n",
      "['GF350_29052021_124022', 'GF350_30052021_123155', 'GF350_31052021_135001', 'GF350_01062021_122420', 'GF350_02062021_142138']\n",
      "here (211, 40, 181)\n",
      "here (211, 40, 181)\n",
      "here (211, 40, 181)\n",
      "here (211, 40, 181)\n",
      "here (211, 40, 181)\n",
      "['MI062_30092021_091006', 'MI062_01102021_091233', 'MI062_02102021_105027', 'MI062_03102021_103851', 'MI062_04102021_092339']\n",
      "here (108, 40, 181)\n",
      "here (108, 40, 181)\n",
      "here (108, 40, 181)\n",
      "here (108, 40, 181)\n",
      "here (108, 40, 181)\n",
      "['MI069_19122021_100830', 'MI069_20122021_095058', 'MI069_21122021_090648', 'MI069_22122021_090212', 'MI069_23122021_085758']\n",
      "here (218, 40, 181)\n",
      "here (218, 40, 181)\n",
      "here (218, 40, 181)\n",
      "here (218, 40, 181)\n",
      "here (218, 40, 181)\n",
      "['MI072_19122021_140553', 'MI072_20122021_125805', 'MI072_21122021_132704', 'MI072_22122021_132651', 'MI072_23122021_132111']\n",
      "here (244, 40, 181)\n",
      "here (244, 40, 181)\n",
      "here (244, 40, 181)\n",
      "here (244, 40, 181)\n",
      "here (244, 40, 181)\n",
      "['MI075_19122021_152533', 'MI075_20122021_155245', 'MI075_21122021_151949', 'MI075_22122021_152806', 'MI075_23122021_150004']\n",
      "here (189, 40, 181)\n",
      "here (189, 40, 181)\n",
      "here (189, 40, 181)\n",
      "here (189, 40, 181)\n",
      "here (189, 40, 181)\n",
      "['MI076_19122021_120004', 'MI076_20122021_113038', 'MI076_21122021_112146', 'MI076_22122021_114039', 'MI076_23122021_113818']\n",
      "here (268, 40, 181)\n",
      "here (268, 40, 181)\n",
      "here (268, 40, 181)\n",
      "here (268, 40, 181)\n",
      "here (268, 40, 181)\n",
      "['AR132_20240424_112338', 'AR132_20240425_102625', 'AR132_20240426_093953', 'AR132_20240427_122605', 'AR132_20240428_122206']\n",
      "here (182, 40, 181)\n",
      "here (182, 40, 181)\n",
      "here (182, 40, 181)\n",
      "here (182, 40, 181)\n",
      "here (182, 40, 181)\n",
      "['AR133_20240424_130306', 'AR133_20240425_115233', 'AR133_20240426_113430', 'AR133_20240427_142253', 'AR133_20240428_134911']\n",
      "here (144, 40, 181)\n",
      "here (144, 40, 181)\n",
      "here (144, 40, 181)\n",
      "here (144, 40, 181)\n",
      "here (144, 40, 181)\n",
      "['AR137_20240424_172627', 'AR137_20240425_170755', 'AR137_20240426_152510', 'AR137_20240427_171535', 'AR137_20240428_163224']\n",
      "here (180, 40, 181)\n",
      "here (180, 40, 181)\n",
      "here (180, 40, 181)\n",
      "here (180, 40, 181)\n",
      "here (180, 40, 181)\n",
      "['AR139_20240424_185913', 'AR139_20240425_181627', 'AR139_20240426_165725', 'AR139_20240427_183701', 'AR139_20240428_180459']\n",
      "here (138, 40, 181)\n",
      "here (138, 40, 181)\n",
      "here (138, 40, 181)\n",
      "here (138, 40, 181)\n",
      "here (138, 40, 181)\n",
      "['AR127_20240221_133407', 'AR127_20240222_152629', 'AR127_20240223_131820', 'AR127_20240224_140853', 'AR127_20240225_142858']\n",
      "here (180, 40, 181)\n",
      "here (180, 40, 181)\n",
      "here (180, 40, 181)\n",
      "here (180, 40, 181)\n",
      "here (180, 40, 181)\n",
      "['AR143_20240518_174556', 'AR143_20240519_141725', 'AR143_20240520_130137', 'AR143_20240521_125833', 'AR143_20240522_172846']\n",
      "here (205, 40, 181)\n",
      "here (205, 40, 181)\n",
      "here (205, 40, 181)\n",
      "here (205, 40, 181)\n",
      "here (205, 40, 181)\n",
      "['AR177_20241217_170649', 'AR177_20241218_145859', 'AR177_20241219_145458', 'AR177_20241220_134735', 'AR177_20241221_121706']\n",
      "here (118, 40, 181)\n",
      "here (118, 40, 181)\n",
      "here (118, 40, 181)\n",
      "here (118, 40, 181)\n",
      "here (118, 40, 181)\n",
      "['AR178_20241213_121925', 'AR178_20241214_164041', 'AR178_20241215_143044', 'AR178_20241216_111129', 'AR178_20241217_120522']\n",
      "here (138, 40, 181)\n",
      "here (138, 40, 181)\n",
      "here (138, 40, 181)\n",
      "here (138, 40, 181)\n",
      "here (138, 40, 181)\n",
      "['AR179_20241214_181515', 'AR179_20241215_174436', 'AR179_20241216_125718', 'AR179_20241217_144120', 'AR179_20241218_132943']\n",
      "here (133, 40, 181)\n",
      "here (133, 40, 181)\n",
      "here (133, 40, 181)\n",
      "here (133, 40, 181)\n",
      "here (133, 40, 181)\n",
      "['AR180_20241213_150420', 'AR180_20241214_194639', 'AR180_20241215_190049', 'AR180_20241216_145407', 'AR180_20241217_160355']\n",
      "here (113, 40, 181)\n",
      "here (113, 40, 181)\n",
      "here (113, 40, 181)\n",
      "here (113, 40, 181)\n",
      "here (113, 40, 181)\n"
     ]
    }
   ],
   "source": [
    "response_amp = {}\n",
    "psth = {}\n",
    "lmi = {}\n",
    "lmi_p = {}\n",
    "metadata = {}\n",
    "responsive_p_values = {}\n",
    "\n",
    "for mouse_id in mice:\n",
    "    # Disregard these mice as the number of trials is too low.\n",
    "    # if mouse_id in ['GF307', 'GF310', 'GF333', 'AR144', 'AR135']:\n",
    "    #     continue\n",
    "    session_list, nwb_files, _, db_filtered = io.select_sessions_from_db(db_path,\n",
    "                                                                        nwb_dir,\n",
    "                                                                        two_p_imaging='yes',\n",
    "                                                                        subject_id=mouse_id,\n",
    "                                                                        day=days,)\n",
    "    print(session_list)\n",
    "\n",
    "    data = []\n",
    "    mdata_list = []\n",
    "    for session_id in session_list:\n",
    "        arr, mdata = imaging_utils.load_session_2p_imaging(mouse_id,\n",
    "                                                            session_id,\n",
    "                                                            processed_dir)\n",
    "        arr = imaging_utils.substract_baseline(arr, 3, baseline_win)\n",
    "        data.append(arr)\n",
    "        mdata_list.append(mdata)\n",
    "\n",
    "    # Extract UM trials.\n",
    "    for i, arr in enumerate(data):\n",
    "        arr = imaging_utils.extract_trials(arr, mdata_list[i], 'UM', n_trials=40)\n",
    "        data[i] = arr\n",
    "\n",
    "    # Get some metadata.\n",
    "    reward_group = io.get_reward_group_from_db(db_path, session_list[0])\n",
    "    metadata[mouse_id] = {}\n",
    "    metadata[mouse_id]['reward_group'] = reward_group\n",
    "    metadata[mouse_id]['cell_types'] = mdata['cell_types']\n",
    "    metadata[mouse_id][\"rois\"] = mdata['rois']\n",
    "    \n",
    "    psth[mouse_id] = {}\n",
    "    responsive_p_values[mouse_id] = {}\n",
    "    response_amp[mouse_id] = {}\n",
    "    lmi[mouse_id] = {}\n",
    "    lmi_p[mouse_id] = {}\n",
    "\n",
    "    for cell_type in ['allcells', 'wS2', 'wM1']:\n",
    "        # Select cell type.\n",
    "        if cell_type == 'allcells':\n",
    "            data_subtype = data\n",
    "        else:\n",
    "            data_subtype = []\n",
    "            cell_type_mask = mdata_list[0]['cell_types']==cell_type\n",
    "            data_subtype = [arr[cell_type_mask] for arr in data]\n",
    "\n",
    "        # If no cells of the specified type, skip.\n",
    "        if data_subtype[0].shape[0] == 0:\n",
    "            continue\n",
    "\n",
    "        # Compute average response for each trial, each day.\n",
    "        # --------------------------------------------------\n",
    "\n",
    "        psth[mouse_id][cell_type] = []\n",
    "        for day in data_subtype:\n",
    "            psth[mouse_id][cell_type].append(np.nanmean(day[:, :, win[0]:win[1]], axis=1))\n",
    "\n",
    "        # Compute average response for each trial, each day.\n",
    "        response_amp[mouse_id][cell_type] = []\n",
    "        for day in data_subtype:\n",
    "            response_amp[mouse_id][cell_type].append(np.nanmean(day[:, :, win[0]:win[1]], axis=2))\n",
    "\n",
    "        # # Compute LMI.\n",
    "        # if cell_type == 'allcells':\n",
    "        #     # # pre = np.mean(np.concatenate(response_amp[0:2], axis=1), axis=1)\n",
    "        #     # # print(pre.shape)\n",
    "        #     # # post = np.mean(np.concatenate((response_amp[5], response_amp[7]), axis=1), axis=1)\n",
    "        #     # # lmi[mouse_id] = (post - pre) / (np.abs(post) + np.abs(pre))\n",
    "\n",
    "        #     # lmis = []\n",
    "        #     # ncells = len(metadata[mouse_id]['rois'])\n",
    "        #     # for icell in range(ncells):\n",
    "        #     #     # mapping trials of D-2, D-1, D+1, D+2.\n",
    "        #     #     X = np.r_[response_amp[mouse_id][cell_type][0][icell], response_amp[mouse_id][cell_type][1][icell],\n",
    "        #     #               response_amp[mouse_id][cell_type][3][icell], response_amp[mouse_id][cell_type][4][icell]]\n",
    "        #     #     y = np.r_[np.zeros(response_amp[mouse_id][cell_type][0][icell].shape[0]),\n",
    "        #     #               np.zeros(response_amp[mouse_id][cell_type][1][icell].shape[0]),\n",
    "        #     #               np.ones(response_amp[mouse_id][cell_type][3][icell].shape[0]),\n",
    "        #     #               np.ones(response_amp[mouse_id][cell_type][4][icell].shape[0])]\n",
    "        #     #     fpr, tpr, _ = roc_curve(y, X)\n",
    "        #     #     roc_auc = auc(fpr, tpr)\n",
    "        #     #     lmis.append((roc_auc - 0.5) * 2)\n",
    "        #     # lmi[mouse_id]['allcells'] = np.array(lmis)\n",
    "\n",
    "        #     pre = [response_amp[mouse_id][cell_type][days.index('-2')],\n",
    "        #            response_amp[mouse_id][cell_type][days.index('-1')]]\n",
    "        #     pre = np.concatenate(pre, axis=1)\n",
    "        #     post = [response_amp[mouse_id][cell_type][days.index('+1')],\n",
    "        #             response_amp[mouse_id][cell_type][days.index('+2')]]\n",
    "        #     post = np.concatenate(post, axis=1)\n",
    "        #     lmi[mouse_id]['allcells'], lmi_p[mouse_id]['allcells'] = imaging_utils.compute_lmi(pre, post, nshuffles=100)\n",
    "        # else:\n",
    "        #     lmi[mouse_id][cell_type] = lmi[mouse_id]['allcells'][metadata[mouse_id]['cell_types'] == cell_type]\n",
    "        #     lmi_p[mouse_id][cell_type] = lmi_p[mouse_id]['allcells'][metadata[mouse_id]['cell_types'] == cell_type]\n",
    "\n",
    "# # Save lmi dicts.\n",
    "# save_path = r'\\\\sv-nas1.rcp.epfl.ch\\Petersen-Lab\\analysis\\Anthony_Renard\\data_processed\\lmi.npy'\n",
    "# np.save(save_path, lmi, allow_pickle=True)\n",
    "# save_path = r'\\\\sv-nas1.rcp.epfl.ch\\Petersen-Lab\\analysis\\Anthony_Renard\\data_processed\\lmi_p.npy'\n",
    "# np.save(save_path, lmi_p, allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2482 233 115\n",
      "2846 280 277\n"
     ]
    }
   ],
   "source": [
    "# Coutn cells.\n",
    "\n",
    "for reward_group in ['R-', 'R+']:\n",
    "    count_all = []\n",
    "    count_s2 = []\n",
    "    count_m1 = []\n",
    "    for mouse in lmi.keys():\n",
    "        if metadata[mouse]['reward_group'] != reward_group:\n",
    "            continue\n",
    "        for cell_type in lmi[mouse].keys():\n",
    "            if cell_type == 'allcells':\n",
    "                count_all.append(len(lmi[mouse][cell_type]))\n",
    "            elif cell_type == 'wS2':\n",
    "                count_s2.append(len(lmi[mouse][cell_type]))\n",
    "            elif cell_type == 'wM1':\n",
    "                count_m1.append(len(lmi[mouse][cell_type]))\n",
    "    c_all = np.sum(count_all)\n",
    "    c_s2 = np.sum(count_s2)\n",
    "    c_m1 = np.sum(count_m1)\n",
    "    print(c_all, c_s2, c_m1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 3.125000e-04,  1.506250e-01, -7.000000e-02,  1.215625e-01,\n",
       "       -2.468750e-02, -4.518750e-01,  8.562500e-02, -1.734375e-01,\n",
       "        2.156250e-02, -3.968750e-02, -3.203125e-01, -7.500000e-01,\n",
       "       -9.750000e-02, -2.125000e-02, -4.209375e-01,  4.687500e-02,\n",
       "       -6.343750e-02,  1.684375e-01,  9.468750e-02,  1.468750e-02,\n",
       "       -1.665625e-01, -2.384375e-01, -1.812500e-02,  4.843750e-02,\n",
       "        2.437500e-02,  1.375000e-01, -1.225000e-01, -2.662500e-01,\n",
       "        2.300000e-01, -7.687500e-02,  2.750000e-02,  5.343750e-02,\n",
       "       -1.987500e-01, -7.384375e-01, -1.081250e-01, -1.893750e-01,\n",
       "       -2.362500e-01, -2.593750e-02, -6.256250e-01, -1.781250e-02,\n",
       "       -2.812500e-02, -2.362500e-01,  1.531250e-02,  9.375000e-02,\n",
       "       -1.162500e-01, -5.656250e-02,  2.165625e-01, -2.684375e-01,\n",
       "       -9.268750e-01, -4.375000e-02, -4.812500e-02, -2.743750e-01,\n",
       "        8.000000e-02, -1.459375e-01, -1.206250e-01,  1.753125e-01,\n",
       "       -2.900000e-01,  2.403125e-01, -3.218750e-02,  1.687500e-02,\n",
       "       -9.250000e-02, -1.734375e-01,  1.321875e-01, -4.456250e-01,\n",
       "       -1.731250e-01, -1.625000e-01, -1.846875e-01,  8.187500e-02,\n",
       "        1.937500e-02, -2.256250e-01, -1.515625e-01, -6.187500e-02,\n",
       "       -3.540625e-01, -2.571875e-01,  1.781250e-02, -1.515625e-01,\n",
       "       -5.625000e-02,  2.343750e-02,  1.750000e-02,  2.968750e-02,\n",
       "       -6.321875e-01,  1.037500e-01, -1.328125e-01, -2.221875e-01,\n",
       "       -9.687500e-03, -7.656250e-02,  4.871875e-01, -1.093750e-01,\n",
       "       -1.193750e-01,  1.125000e-02, -1.646875e-01, -5.750000e-02,\n",
       "        6.625000e-02, -9.250000e-02, -1.212500e-01, -1.031250e-02,\n",
       "       -1.078125e-01, -7.968750e-02, -6.500000e-02, -5.156250e-02,\n",
       "        2.968750e-02, -1.259375e-01, -4.218750e-02, -1.393750e-01,\n",
       "       -7.325000e-01, -8.750000e-03, -1.171875e-01,  4.531250e-02,\n",
       "       -1.218750e-02,  3.171875e-01,  3.262500e-01,  7.281250e-02,\n",
       "       -2.562500e-02, -1.203125e-01,  1.218750e-01, -1.556250e-01,\n",
       "       -2.193750e-01, -7.906250e-02, -5.656250e-02, -8.093750e-02,\n",
       "       -2.268750e-01, -2.012500e-01, -3.037500e-01, -3.000000e-02,\n",
       "        1.750000e-02, -2.150000e-01, -2.165625e-01, -3.906250e-02,\n",
       "        2.562500e-02, -2.031250e-01, -1.978125e-01, -6.156250e-02,\n",
       "       -1.437500e-01,  6.031250e-02,  2.968750e-02, -1.962500e-01,\n",
       "        7.593750e-02,  2.250000e-02, -4.937500e-02, -3.818750e-01,\n",
       "        6.031250e-02,  1.906250e-02, -2.875000e-02,  8.281250e-02,\n",
       "        0.000000e+00, -1.018750e-01,  5.106250e-01, -7.812500e-02,\n",
       "        1.096875e-01, -5.500000e-02,  5.656250e-02,  1.843750e-02,\n",
       "       -2.646875e-01, -8.490625e-01, -2.687500e-02,  3.968750e-02,\n",
       "       -6.375000e-02,  2.031250e-02, -8.750000e-02,  8.125000e-02,\n",
       "        9.000000e-02, -7.968750e-02, -1.428125e-01, -1.034375e-01,\n",
       "        1.003125e-01,  2.084375e-01, -7.403125e-01, -2.781250e-01,\n",
       "       -7.937500e-02, -9.000000e-02,  5.937500e-03, -1.290625e-01,\n",
       "       -7.968750e-02,  8.500000e-02,  2.656250e-02, -5.390625e-01,\n",
       "        1.093750e-02, -2.021875e-01, -6.781250e-02, -1.931250e-01])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lmi['AR127']['allcells']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Proportion of LMI cells.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "lmi_prop = []\n",
    "for mouse in mice:\n",
    "    reward_group = metadata[mouse]['reward_group']\n",
    "    for cell_type in ['allcells', 'wS2', 'wM1']:\n",
    "        if cell_type in lmi_p[mouse].keys():\n",
    "            n_lmi_up = np.sum(lmi_p[mouse][cell_type] >= 0.975)\n",
    "            n_lmi_down = np.sum(lmi_p[mouse][cell_type] <= 0.025)\n",
    "            prop_lmi_up = n_lmi_up / len(lmi[mouse][cell_type])\n",
    "            prop_lmi_down = n_lmi_down / len(lmi[mouse][cell_type])\n",
    "            lmi_prop.append({'mouse_id': mouse,'reward_group': reward_group, 'cell_type': cell_type, 'n_lmi': n_lmi_up, 'prop_lmi': prop_lmi_up, 'modulation': 'up'})\n",
    "            lmi_prop.append({'mouse_id': mouse,'reward_group': reward_group, 'cell_type': cell_type, 'n_lmi': n_lmi_down, 'prop_lmi': prop_lmi_down, 'modulation': 'down'})\n",
    "        else:\n",
    "            lmi_prop.append({'mouse_id': mouse, 'reward_group': reward_group, 'cell_type': cell_type, 'n_lmi_up': np.nan, 'prop_lmi_up': np.nan})\n",
    "            lmi_prop.append({'mouse_id': mouse, 'reward_group': reward_group, 'cell_type': cell_type, 'n_lmi_down': np.nan, 'prop_lmi_down': np.nan})\n",
    "lmi_prop = pd.DataFrame(lmi_prop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cell type allcells, Modulation up: p-value = 0.00038139799917024205\n",
      "Cell type allcells, Modulation down: p-value = 0.2579351703686603\n",
      "Cell type wS2, Modulation up: p-value = 0.015403528420213176\n",
      "Cell type wS2, Modulation down: p-value = 0.38455254690437146\n",
      "Cell type wM1, Modulation up: p-value = 0.20185429860117265\n",
      "Cell type wM1, Modulation down: p-value = 0.879153887906272\n",
      "  cell_type modulation   p_value\n",
      "0  allcells         up  0.000381\n",
      "1  allcells       down  0.257935\n",
      "2       wS2         up  0.015404\n",
      "3       wS2       down  0.384553\n",
      "4       wM1         up  0.201854\n",
      "5       wM1       down  0.879154\n"
     ]
    }
   ],
   "source": [
    "g = sns.catplot(data=lmi_prop, x='reward_group', y='prop_lmi', kind='bar', col='modulation', row='cell_type', hue='reward_group',\n",
    "            palette=sns.color_palette([ '#238443', '#d51a1c',]), height=3, aspect=0.8)\n",
    "\n",
    "# Perform Mann-Whitney U test to check if the difference between the two reward groups is significant for each modulation and cell type.\n",
    "results = []\n",
    "for cell_type in lmi_prop['cell_type'].unique():\n",
    "    for modulation in ['up', 'down']:\n",
    "        group_rew = lmi_prop[(lmi_prop['reward_group'] == 'R+') & (lmi_prop['cell_type'] == cell_type) & (lmi_prop['modulation'] == modulation)]['prop_lmi']\n",
    "        group_unrew = lmi_prop[(lmi_prop['reward_group'] == 'R-') & (lmi_prop['cell_type'] == cell_type) & (lmi_prop['modulation'] == modulation)]['prop_lmi']\n",
    "        group_rew = group_rew.dropna()\n",
    "        group_unrew = group_unrew.dropna()\n",
    "        stat, p = mannwhitneyu(group_rew, group_unrew)\n",
    "        results.append({'cell_type': cell_type, 'modulation': modulation, 'p_value': p})\n",
    "        print(f'Cell type {cell_type}, Modulation {modulation}: p-value = {p}')\n",
    "\n",
    "# Convert results to a DataFrame\n",
    "results_df = pd.DataFrame(results)\n",
    "print(results_df)\n",
    "\n",
    "# Add stars to the plot for each subplot\n",
    "for ax in g.axes.flat:\n",
    "    cell_type = ax.get_title().split(' = ')[-1]\n",
    "    modulation = ax.get_title().split(' = ')[-2]\n",
    "    for result in results:\n",
    "        if result['cell_type'] == cell_type and result['modulation'] == modulation:\n",
    "            if result['p_value'] < 0.05:\n",
    "                ax.text(0.5, 0.5, '*', ha='center', va='bottom', color='black', transform=ax.transAxes)\n",
    "            if result['p_value'] < 0.01:\n",
    "                ax.text(0.5, 0.5, '**', ha='center', va='bottom', color='black', transform=ax.transAxes)\n",
    "            if result['p_value'] < 0.001:\n",
    "                ax.text(0.5, 0.5, '***', ha='center', va='bottom', color='black', transform=ax.transAxes)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PSTH's with LMI cells\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to pandas.\n",
    "mouse_ids = list(psth.keys())\n",
    "df = []\n",
    "\n",
    "for mouse_id in mouse_ids:\n",
    "    # if mouse_id == 'GF308':\n",
    "    #     continue\n",
    "    \n",
    "    for icell, roi in enumerate(metadata[mouse_id]['rois']):\n",
    "        # if (lmi_p[mouse_id]['allcells'][icell] < 0.975) & (lmi_p[mouse_id]['allcells'][icell] > 0.025):\n",
    "        # if (lmi_p[mouse_id]['allcells'][icell] < 0.975):\n",
    "        if (lmi_p[mouse_id]['allcells'][icell] > 0.025):\n",
    "            continue\n",
    "\n",
    "        time = np.linspace(win_sec[0], win_sec[1], psth[mouse_id]['allcells'][0].shape[1]) - 1\n",
    "        cell_type = metadata[mouse_id]['cell_types'][icell]\n",
    "        for iday in range(len(days)):\n",
    "            trace = psth[mouse_id]['allcells'][iday][icell]\n",
    "            temp = pd.DataFrame(np.stack([time, trace], axis=1), columns=['time', 'activity'])\n",
    "            temp['day'] = days[iday]\n",
    "            temp['mouse_id'] = mouse_id\n",
    "            temp['roi'] = roi\n",
    "            temp['cell_type'] = cell_type\n",
    "            temp['reward_group'] = metadata[mouse_id]['reward_group']\n",
    "            df.append(temp)\n",
    "df = pd.concat(df)\n",
    "df = df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot.\n",
    "data = df.loc[df.time<1.5]\n",
    "\n",
    "# GF305 has baseline artefact on day -1 at auditory trials.\n",
    "data = data.loc[~data.mouse_id.isin(['GF305'])]\n",
    "\n",
    "data = data.loc[data['day'].isin(['-2', '-1', '0', '+1', '+2'])]\n",
    "# data = data.loc[data['cell_type']=='wM1']\n",
    "# df = df.loc[df.mouse_id.isin(['GF305', 'GF306', 'GF307'])]\n",
    "fig = sns.relplot(data=data, x='time', y='activity', errorbar='ci', col='day',\n",
    "            kind='line', hue='reward_group',\n",
    "            hue_order=['R-','R+'], palette=sns.color_palette(['#d51a1c', '#238443']),\n",
    "            height=3, aspect=0.8)\n",
    "for ax in fig.axes.flatten():\n",
    "    ax.axvline(0, color='#FF9600', linestyle='--')\n",
    "    ax.set_title('')        \n",
    "\n",
    "fig = sns.relplot(data=data, x='time', y='activity', errorbar='ci', col='day', row='cell_type',\n",
    "            kind='line', hue='reward_group',\n",
    "            hue_order=['R-','R+'], palette=sns.color_palette(['#d51a1c', '#238443']), row_order=['wS2', 'wM1',],\n",
    "            height=3, aspect=0.8)\n",
    "for ax in fig.axes.flatten():\n",
    "    ax.axvline(0, color='#FF9600', linestyle='--')\n",
    "    ax.set_title('')    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PSTH's with LMI cells -- 5 first whisker/whisker hit trials VS the rest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['GF305', 'GF306', 'GF307', 'GF308', 'GF310', 'GF311', 'GF313', 'GF314', 'GF317', 'GF318', 'GF319', 'GF323', 'GF333', 'GF334', 'GF348', 'GF350', 'MI062', 'MI069', 'MI072', 'MI075', 'MI076', 'AR132', 'AR133', 'AR137', 'AR139', 'AR127', 'AR143', 'AR177', 'AR178', 'AR179', 'AR180']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "31"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load data needed to compute before and after learning.\n",
    "\n",
    "sampling_rate = 30\n",
    "win_sec = (0.8, 3)  \n",
    "win = (int(win_sec[0] * sampling_rate), int(win_sec[1] * sampling_rate))\n",
    "baseline_win = (0, 1)\n",
    "baseline_win = (int(baseline_win[0] * sampling_rate), int(baseline_win[1] * sampling_rate))\n",
    "days = ['0']\n",
    "\n",
    "_, _, mice, _ = io.select_sessions_from_db(db_path,\n",
    "                                            nwb_dir,\n",
    "                                            two_p_imaging='yes')\n",
    "mice = [m for m in mice if m not in ['AR163']]\n",
    "print(mice)\n",
    "len(mice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['GF305_29112020_103331']\n",
      "here (133, 40, 181)\n",
      "['GF306_29112020_131929']\n",
      "here (215, 40, 181)\n",
      "['GF307_19112020_083908']\n",
      "here (150, 40, 181)\n",
      "['GF308_19112020_103527']\n",
      "here (147, 40, 181)\n",
      "['GF310_19112020_131953']\n",
      "here (243, 40, 181)\n",
      "['GF311_19112020_160412']\n",
      "here (105, 40, 181)\n",
      "['GF313_29112020_154625']\n",
      "here (164, 40, 181)\n",
      "['GF314_29112020_174831']\n",
      "here (197, 40, 181)\n",
      "['GF317_17122020_080715']\n",
      "here (146, 40, 181)\n",
      "['GF318_17122020_144100']\n",
      "here (140, 40, 181)\n",
      "['GF319_26122020_144746']\n",
      "here (154, 40, 181)\n",
      "['GF323_09012021_111716']\n",
      "here (305, 40, 181)\n",
      "['GF333_24012021_145617']\n",
      "here (124, 40, 181)\n",
      "['GF334_24012021_173019']\n",
      "here (130, 40, 181)\n",
      "['GF348_31052021_102411']\n",
      "here (206, 40, 181)\n",
      "['GF350_31052021_135001']\n",
      "here (211, 40, 181)\n",
      "['MI062_02102021_105027']\n",
      "here (108, 40, 181)\n",
      "['MI069_21122021_090648']\n",
      "here (218, 40, 181)\n",
      "['MI072_21122021_132704']\n",
      "here (244, 40, 181)\n",
      "['MI075_21122021_151949']\n",
      "here (189, 40, 181)\n",
      "['MI076_21122021_112146']\n",
      "here (268, 40, 181)\n",
      "['AR132_20240426_093953']\n",
      "here (182, 40, 181)\n",
      "['AR133_20240426_113430']\n",
      "here (144, 40, 181)\n",
      "['AR137_20240426_152510']\n",
      "here (180, 40, 181)\n",
      "['AR139_20240426_165725']\n",
      "here (138, 40, 181)\n",
      "['AR127_20240223_131820']\n",
      "here (180, 40, 181)\n",
      "['AR143_20240520_130137']\n",
      "here (205, 40, 181)\n",
      "['AR177_20241219_145458']\n",
      "here (118, 40, 181)\n",
      "['AR178_20241215_143044']\n",
      "here (138, 40, 181)\n",
      "['AR179_20241216_125718']\n",
      "here (133, 40, 181)\n",
      "['AR180_20241215_190049']\n",
      "here (113, 40, 181)\n"
     ]
    }
   ],
   "source": [
    "response_amp = {}\n",
    "psth = {}\n",
    "metadata = {}\n",
    "\n",
    "for mouse_id in mice:\n",
    "    # Disregard these mice as the number of trials is too low.\n",
    "    # if mouse_id in ['GF307', 'GF310', 'GF333', 'AR144', 'AR135']:\n",
    "    #     continue\n",
    "    session_list, nwb_files, _, db_filtered = io.select_sessions_from_db(db_path,\n",
    "                                                                        nwb_dir,\n",
    "                                                                        two_p_imaging='yes',\n",
    "                                                                        subject_id=mouse_id,\n",
    "                                                                        day=days,)\n",
    "    print(session_list)\n",
    "\n",
    "    data = []\n",
    "    mdata_list = []\n",
    "    for session_id in session_list:\n",
    "        arr, mdata = imaging_utils.load_session_2p_imaging(mouse_id,\n",
    "                                                            session_id,\n",
    "                                                            processed_dir)\n",
    "        arr = imaging_utils.substract_baseline(arr, 3, baseline_win)\n",
    "        data.append(arr)\n",
    "        mdata_list.append(mdata)\n",
    "\n",
    "    # Extract UM trials.\n",
    "    for i, arr in enumerate(data):\n",
    "        arr = imaging_utils.extract_trials(arr, mdata_list[i], 'W', n_trials=40)\n",
    "        data[i] = arr\n",
    "\n",
    "    # Get some metadata.\n",
    "    reward_group = io.get_reward_group_from_db(db_path, session_list[0])\n",
    "    metadata[mouse_id] = {}\n",
    "    metadata[mouse_id]['reward_group'] = reward_group\n",
    "    metadata[mouse_id]['cell_types'] = mdata['cell_types']\n",
    "    metadata[mouse_id][\"rois\"] = mdata['rois']\n",
    "    \n",
    "    psth[mouse_id] = {}\n",
    "    responsive_p_values[mouse_id] = {}\n",
    "    response_amp[mouse_id] = {}\n",
    "\n",
    "\n",
    "    for cell_type in ['allcells', 'wS2', 'wM1']:\n",
    "        # Select cell type.\n",
    "        if cell_type == 'allcells':\n",
    "            data_subtype = data\n",
    "        else:\n",
    "            data_subtype = []\n",
    "            cell_type_mask = mdata_list[0]['cell_types']==cell_type\n",
    "            data_subtype = [arr[cell_type_mask] for arr in data]\n",
    "\n",
    "        # If no cells of the specified type, skip.\n",
    "        if data_subtype[0].shape[0] == 0:\n",
    "            continue\n",
    "\n",
    "        # Compute average response for each trial, each day.\n",
    "        # --------------------------------------------------\n",
    "\n",
    "        psth[mouse_id][cell_type] = []\n",
    "        for day in data_subtype:\n",
    "            psth[mouse_id][cell_type].append(day[:, :, win[0]:win[1]])\n",
    "\n",
    "        # Compute average response for each trial, each day.\n",
    "        response_amp[mouse_id][cell_type] = []\n",
    "        for day in data_subtype:\n",
    "            response_amp[mouse_id][cell_type].append(day[:, :, win[0]:win[1]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load lmi dicts.\n",
    "lmi = np.load(r'\\\\sv-nas1.rcp.epfl.ch\\Petersen-Lab\\analysis\\Anthony_Renard\\data_processed\\lmi.npy', allow_pickle=True).item()\n",
    "lmi_p = np.load(r'\\\\sv-nas1.rcp.epfl.ch\\Petersen-Lab\\analysis\\Anthony_Renard\\data_processed\\lmi_p.npy', allow_pickle=True).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to pandas.\n",
    "mouse_ids = list(psth.keys())\n",
    "df = []\n",
    "\n",
    "for mouse_id in mouse_ids:\n",
    "    # if mouse_id == 'GF308':\n",
    "    #     continue\n",
    "    \n",
    "    for icell, roi in enumerate(metadata[mouse_id]['rois']):\n",
    "        if (lmi_p[mouse_id]['allcells'][icell] < 0.975) & (lmi_p[mouse_id]['allcells'][icell] > 0.025):\n",
    "            continue\n",
    "\n",
    "        time = np.linspace(win_sec[0], win_sec[1], psth[mouse_id]['allcells'][0].shape[2]) - 1\n",
    "        cell_type = metadata[mouse_id]['cell_types'][icell]\n",
    "        for iday in range(len(days)):\n",
    "            for itrial in range(40):\n",
    "                trace = psth[mouse_id]['allcells'][iday][icell, itrial, :]\n",
    "                temp = pd.DataFrame(np.stack([time, trace], axis=1), columns=['time', 'activity'])\n",
    "                temp['day'] = days[iday]\n",
    "                temp['mouse_id'] = mouse_id\n",
    "                temp['roi'] = roi\n",
    "                if lmi_p[mouse_id]['allcells'][icell] > 0.975:\n",
    "                    temp['modulation'] = 'up'\n",
    "                else:\n",
    "                    temp['modulation'] = 'down'\n",
    "                temp['trial'] = itrial\n",
    "                temp['cell_type'] = cell_type\n",
    "                temp['reward_group'] = metadata[mouse_id]['reward_group']\n",
    "                df.append(temp)\n",
    "df = pd.concat(df)\n",
    "df = df.reset_index(drop=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0.98, 'First 5 whisker hits VS rest LMI down')"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Plot.\n",
    "data = df.loc[df.time<1.5]\n",
    "modulation = 'down'\n",
    "if modulation:\n",
    "    data = data.loc[data['modulation']==modulation]\n",
    "\n",
    "# # GF305 has baseline artefact on day -1 at auditory trials.\n",
    "# data = data.loc[~data.mouse_id.isin(['GF305'])]\n",
    "\n",
    "\n",
    "fig, axes = plt.subplots(3, 2, sharex=True, sharey=True)\n",
    "\n",
    "temp = data.loc[(data['trial']<5) & (data['reward_group']=='R+')]\n",
    "# Average on cells if stats on mice. On cells otherwise.\n",
    "# temp = temp.groupby(['mouse_id', 'time', 'reward_group', 'cell_type'])['activity'].mean().reset_index()\n",
    "sns.lineplot(data=temp, x='time', y='activity', errorbar='ci', hue='reward_group',\n",
    "            palette=sns.color_palette([ '#238443']), linestyle='--',\n",
    "            ax=axes[0, 0], legend=False)\n",
    "temp = data.loc[(data['trial']>=5) & (data['reward_group']=='R+')]\n",
    "# temp = temp.groupby(['mouse_id', 'time', 'reward_group', 'cell_type'])['activity'].mean().reset_index()\n",
    "sns.lineplot(data=temp, x='time', y='activity', errorbar='ci', hue='reward_group',\n",
    "            palette=sns.color_palette(['#238443']),\n",
    "            ax=axes[0, 0], legend=False)\n",
    "\n",
    "temp = data.loc[(data['trial']<5) & (data['reward_group']=='R-')]\n",
    "# temp = temp.groupby(['mouse_id', 'time', 'reward_group', 'cell_type'])['activity'].mean().reset_index()\n",
    "sns.lineplot(data=temp, x='time', y='activity', errorbar='ci', hue='reward_group',\n",
    "            palette=sns.color_palette([ '#d51a1c']),linestyle='--',\n",
    "            ax=axes[0, 1], legend=False)\n",
    "temp = data.loc[(data['trial']>=5) & (data['reward_group']=='R-')]\n",
    "# temp = temp.groupby(['mouse_id', 'time', 'reward_group', 'cell_type'])['activity'].mean().reset_index()\n",
    "sns.lineplot(data=temp, x='time', y='activity', errorbar='ci', hue='reward_group',\n",
    "            palette=sns.color_palette(['#d51a1c']),\n",
    "            ax=axes[0, 1], legend=False)\n",
    "\n",
    "temp = data.loc[(data['trial']<5)  & (data['cell_type']=='wS2') & (data['reward_group']=='R+')]\n",
    "# temp = temp.groupby(['mouse_id', 'time', 'reward_group', 'cell_type'])['activity'].mean().reset_index()\n",
    "sns.lineplot(data=temp, x='time', y='activity', errorbar='ci', hue='reward_group',\n",
    "            palette=sns.color_palette(['#238443']),linestyle='--',\n",
    "            ax=axes[1, 0], legend=False)\n",
    "temp = data.loc[(data['trial']>=5)  & (data['cell_type']=='wS2') & (data['reward_group']=='R+')]\n",
    "# temp = temp.groupby(['mouse_id', 'time', 'reward_group', 'cell_type'])['activity'].mean().reset_index()\n",
    "sns.lineplot(data=temp, x='time', y='activity', errorbar='ci', hue='reward_group',\n",
    "            palette=sns.color_palette(['#238443',]),\n",
    "            ax=axes[1, 0], legend=False)\n",
    "\n",
    "temp = data.loc[(data['trial']<5)  & (data['cell_type']=='wS2') & (data['reward_group']=='R-')]\n",
    "# temp = temp.groupby(['mouse_id', 'time', 'reward_group', 'cell_type'])['activity'].mean().reset_index()\n",
    "sns.lineplot(data=temp, x='time', y='activity', errorbar='ci', hue='reward_group',\n",
    "            palette=sns.color_palette(['#d51a1c']),linestyle='--',\n",
    "            ax=axes[1, 1], legend=False)\n",
    "temp = data.loc[(data['trial']>=5)  & (data['cell_type']=='wS2') & (data['reward_group']=='R-')]\n",
    "# temp = temp.groupby(['mouse_id', 'time', 'reward_group', 'cell_type'])['activity'].mean().reset_index()\n",
    "sns.lineplot(data=temp, x='time', y='activity', errorbar='ci', hue='reward_group',\n",
    "            palette=sns.color_palette(['#d51a1c',]),\n",
    "            ax=axes[1, 1], legend=False)\n",
    "\n",
    "temp = data.loc[(data['trial']<5)  & (data['cell_type']=='wM1') & (data['reward_group']=='R+')]\n",
    "# temp = temp.groupby(['mouse_id', 'time', 'reward_group', 'cell_type'])['activity'].mean().reset_index()\n",
    "sns.lineplot(data=temp, x='time', y='activity', errorbar='ci', hue='reward_group',\n",
    "            palette=sns.color_palette(['#238443']),linestyle='--',\n",
    "            ax=axes[2, 0], legend=False)\n",
    "temp = data.loc[(data['trial']>=5)  & (data['cell_type']=='wM1') & (data['reward_group']=='R+')]\n",
    "# temp = temp.groupby(['mouse_id', 'time', 'reward_group', 'cell_type'])['activity'].mean().reset_index()\n",
    "sns.lineplot(data=temp, x='time', y='activity', errorbar='ci', hue='reward_group',\n",
    "            palette=sns.color_palette(['#238443']),\n",
    "            ax=axes[2, 0], legend=False)\n",
    "\n",
    "temp = data.loc[(data['trial']<5)  & (data['cell_type']=='wM1') & (data['reward_group']=='R-')]\n",
    "# temp = temp.groupby(['mouse_id', 'time', 'reward_group', 'cell_type'])['activity'].mean().reset_index()\n",
    "sns.lineplot(data=temp, x='time', y='activity', errorbar='ci', hue='reward_group', linestyle='--',\n",
    "            palette=sns.color_palette(['#d51a1c']),\n",
    "            ax=axes[2, 1], legend=False)\n",
    "temp = data.loc[(data['trial']>=5)  & (data['cell_type']=='wM1') & (data['reward_group']=='R-')]\n",
    "# temp = temp.groupby(['mouse_id', 'time', 'reward_group', 'cell_type'])['activity'].mean().reset_index()\n",
    "sns.lineplot(data=temp, x='time', y='activity', errorbar='ci', hue='reward_group',\n",
    "            palette=sns.color_palette(['#d51a1c']),\n",
    "            ax=axes[2, 1], legend=False)\n",
    "\n",
    "\n",
    "for ax in axes.flatten():\n",
    "    ax.axvline(0, color='#FF9600', linestyle='--')\n",
    "    ax.set_title('')\n",
    "\n",
    "fig.suptitle(f'First 5 whisker hits VS rest LMI {modulation}')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(0)"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(data['cell_type']=='allcells').sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2. Quantify those responses.\n",
    "\n",
    "- Amplitude of the response\n",
    "- Number of significant cells\n",
    "- variance across days\n",
    "- dimensionality across days\n",
    "- ...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['GF305', 'GF306', 'GF307', 'GF308', 'GF310', 'GF311', 'GF313', 'GF314', 'GF317', 'GF318', 'GF319', 'GF323', 'GF333', 'GF334', 'GF348', 'GF350', 'MI062', 'MI069', 'MI072', 'MI075', 'MI076', 'AR132', 'AR133', 'AR137', 'AR139', 'AR127', 'AR143', 'AR177', 'AR178', 'AR179', 'AR180']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "31"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load data needed to compute before and after learning.\n",
    "\n",
    "sampling_rate = 30\n",
    "win = (1, 1.3)  # from stimulus onset to 300 ms after.\n",
    "win = (int(win[0] * sampling_rate), int(win[1] * sampling_rate))\n",
    "baseline_win = (0, 1)\n",
    "baseline_win = (int(baseline_win[0] * sampling_rate), int(baseline_win[1] * sampling_rate))\n",
    "days = ['-2', '-1', '0', '+1', '+2']\n",
    "# Correlation matrix for a specific cell type\n",
    "cell_type = None\n",
    "variance_explained_thr = 0.7\n",
    "\n",
    "_, _, mice, _ = io.select_sessions_from_db(db_path,\n",
    "                                            nwb_dir,\n",
    "                                            two_p_imaging='yes',)\n",
    "mice = [m for m in mice if m not in ['AR163']]\n",
    "print(mice)\n",
    "len(mice)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['GF305_27112020_083119', 'GF305_28112020_103938', 'GF305_29112020_103331', 'GF305_30112020_110255', 'GF305_02122020_132229']\n",
      "['GF306_27112020_104436', 'GF306_28112020_125555', 'GF306_29112020_131929', 'GF306_30112020_133249', 'GF306_02122020_161611']\n",
      "['GF307_17112020_080325', 'GF307_18112020_075939', 'GF307_19112020_083908', 'GF307_20112020_082942', 'GF307_21112020_102608']\n",
      "['GF308_17112020_105052', 'GF308_18112020_093627', 'GF308_19112020_103527', 'GF308_20112020_122826', 'GF308_21112020_135515']\n",
      "['GF310_17112020_132720', 'GF310_18112020_122252', 'GF310_19112020_131953', 'GF310_20112020_150929', 'GF310_21112020_160059']\n",
      "['GF311_17112020_155501', 'GF311_18112020_151838', 'GF311_19112020_160412', 'GF311_20112020_171609', 'GF311_21112020_180049']\n",
      "['GF313_27112020_141857', 'GF313_28112020_154236', 'GF313_29112020_154625', 'GF313_30112020_154904', 'GF313_03122020_082147']\n",
      "['GF314_27112020_160459', 'GF314_28112020_171800', 'GF314_29112020_174831', 'GF314_30112020_171906', 'GF314_03122020_102249']\n",
      "['GF317_15122020_081931', 'GF317_16122020_082007', 'GF317_17122020_080715', 'GF317_18122020_104834', 'GF317_20122020_120604']\n",
      "['GF318_15122020_095616', 'GF318_16122020_095516', 'GF318_17122020_144100', 'GF318_18122020_132105', 'GF318_19122020_155806']\n",
      "['GF319_24122020_120204', 'GF319_25122020_142951', 'GF319_26122020_144746', 'GF319_27122020_135842', 'GF319_28122020_132438']\n",
      "['GF323_07012021_092005', 'GF323_08012021_083725', 'GF323_09012021_111716', 'GF323_11012021_084126', 'GF323_12012021_090219']\n",
      "['GF333_21012021_125450', 'GF333_22012021_135939', 'GF333_24012021_145617', 'GF333_25012021_141608', 'GF333_26012021_142304']\n",
      "['GF334_21012021_160130', 'GF334_22012021_153815', 'GF334_24012021_173019', 'GF334_25012021_163843', 'GF334_26012021_171010']\n",
      "['GF348_29052021_100151', 'GF348_30052021_110107', 'GF348_31052021_102411', 'GF348_01062021_095758', 'GF348_02062021_084344']\n",
      "['GF350_29052021_124022', 'GF350_30052021_123155', 'GF350_31052021_135001', 'GF350_01062021_122420', 'GF350_02062021_142138']\n",
      "['MI062_30092021_091006', 'MI062_01102021_091233', 'MI062_02102021_105027', 'MI062_03102021_103851', 'MI062_04102021_092339']\n",
      "['MI069_19122021_100830', 'MI069_20122021_095058', 'MI069_21122021_090648', 'MI069_22122021_090212', 'MI069_23122021_085758']\n",
      "['MI072_19122021_140553', 'MI072_20122021_125805', 'MI072_21122021_132704', 'MI072_22122021_132651', 'MI072_23122021_132111']\n",
      "['MI075_19122021_152533', 'MI075_20122021_155245', 'MI075_21122021_151949', 'MI075_22122021_152806', 'MI075_23122021_150004']\n",
      "['MI076_19122021_120004', 'MI076_20122021_113038', 'MI076_21122021_112146', 'MI076_22122021_114039', 'MI076_23122021_113818']\n",
      "['AR132_20240424_112338', 'AR132_20240425_102625', 'AR132_20240426_093953', 'AR132_20240427_122605', 'AR132_20240428_122206']\n",
      "['AR133_20240424_130306', 'AR133_20240425_115233', 'AR133_20240426_113430', 'AR133_20240427_142253', 'AR133_20240428_134911']\n",
      "['AR137_20240424_172627', 'AR137_20240425_170755', 'AR137_20240426_152510', 'AR137_20240427_171535', 'AR137_20240428_163224']\n",
      "['AR139_20240424_185913', 'AR139_20240425_181627', 'AR139_20240426_165725', 'AR139_20240427_183701', 'AR139_20240428_180459']\n",
      "['AR127_20240221_133407', 'AR127_20240222_152629', 'AR127_20240223_131820', 'AR127_20240224_140853', 'AR127_20240225_142858']\n",
      "['AR143_20240518_174556', 'AR143_20240519_141725', 'AR143_20240520_130137', 'AR143_20240521_125833', 'AR143_20240522_172846']\n",
      "['AR177_20241217_170649', 'AR177_20241218_145859', 'AR177_20241219_145458', 'AR177_20241220_134735', 'AR177_20241221_121706']\n",
      "['AR178_20241213_121925', 'AR178_20241214_164041', 'AR178_20241215_143044', 'AR178_20241216_111129', 'AR178_20241217_120522']\n",
      "['AR179_20241214_181515', 'AR179_20241215_174436', 'AR179_20241216_125718', 'AR179_20241217_144120', 'AR179_20241218_132943']\n",
      "['AR180_20241213_150420', 'AR180_20241214_194639', 'AR180_20241215_190049', 'AR180_20241216_145407', 'AR180_20241217_160355']\n"
     ]
    }
   ],
   "source": [
    "average_response = {}\n",
    "peak_response = {}\n",
    "responsive_p_values = {}\n",
    "dimensionality = {}\n",
    "metadata = {}\n",
    "\n",
    "lmi = {}\n",
    "globally_responsive = {}\n",
    "\n",
    "for mouse_id in mice:\n",
    "    # Disregard these mice as the number of trials is too low.\n",
    "    # if mouse_id in ['GF307', 'GF310', 'GF333', 'AR144', 'AR135']:\n",
    "    #     continue\n",
    "    session_list, nwb_files, _, db_filtered = io.select_sessions_from_db(db_path,\n",
    "                                                                        nwb_dir,\n",
    "                                                                        two_p_imaging='yes',\n",
    "                                                                        subject_id=mouse_id,\n",
    "                                                                        day=days,)\n",
    "    print(session_list)\n",
    "\n",
    "    data = []\n",
    "    mdata_list = []\n",
    "    for session_id in session_list:\n",
    "        arr, mdata = imaging_utils.load_session_2p_imaging(mouse_id,\n",
    "                                                            session_id,\n",
    "                                                            processed_dir)\n",
    "        arr = imaging_utils.substract_baseline(arr, 3, baseline_win)\n",
    "        data.append(arr)\n",
    "        mdata_list.append(mdata)\n",
    "\n",
    "    # Extract UM trials.\n",
    "    for i, arr in enumerate(data):\n",
    "        arr = imaging_utils.extract_trials(arr, mdata_list[i], 'UM', n_trials=None)\n",
    "        data[i] = arr\n",
    "\n",
    "    # Get some metadata.\n",
    "    reward_group = io.get_reward_group_from_db(db_path, session_list[0])\n",
    "    metadata[mouse_id] = {}\n",
    "    metadata[mouse_id]['reward_group'] = reward_group\n",
    "    metadata[mouse_id]['cell_types'] = mdata['cell_types']\n",
    "    \n",
    "    average_response[mouse_id] = {}\n",
    "    peak_response[mouse_id] = {}\n",
    "    responsive_p_values[mouse_id] = {}\n",
    "    dimensionality[mouse_id] = {}\n",
    "\n",
    "    for cell_type in ['allcells', 'wS2', 'wM1']:\n",
    "        # Select cell type.\n",
    "        if cell_type == 'allcells':\n",
    "            data_subtype = data\n",
    "        else:\n",
    "            data_subtype = []\n",
    "            cell_type_mask = mdata_list[0]['cell_types']==cell_type\n",
    "            data_subtype = [arr[cell_type_mask] for arr in data]\n",
    "\n",
    "        # If no cells of the specified type, skip.\n",
    "        if data_subtype[0].shape[0] == 0:\n",
    "            continue\n",
    "\n",
    "        # Compute average response for each trial, each day.\n",
    "        # --------------------------------------------------\n",
    "\n",
    "        average_response[mouse_id][cell_type] = []\n",
    "        for day in data_subtype:\n",
    "            average_response[mouse_id][cell_type].append(np.nanmean(day[:, :, win[0]:win[1]], axis=2))\n",
    "\n",
    "        # Compute peak response for each trial, each day.\n",
    "        # ------------------------------------------------\n",
    "\n",
    "        peak_response[mouse_id][cell_type] = []\n",
    "        for day in data_subtype:\n",
    "            peak_response[mouse_id][cell_type].append(np.nanmax(day[:, :, win[0]:win[1]], axis=2))\n",
    "\n",
    "        # # Compute standard deviation of population response.\n",
    "        # # ----------------------------------------------------  \n",
    "\n",
    "        # std[mouse_id][cell_type] = []\n",
    "        # for day in data_subtype:\n",
    "        #     std[mouse_id][cell_type].append(np.std(np.nanmean(day[:, :, win[0]:win[1]], axis=2), axis=0))\n",
    "\n",
    "\n",
    "        # Test responsiveness.\n",
    "        # --------------------\n",
    "\n",
    "        baseline_avg = []\n",
    "        response_avg = []\n",
    "        for day in data_subtype:\n",
    "            baseline_avg.append(np.nanmean(day[:, :, baseline_win[0]:baseline_win[1]], axis=2))\n",
    "            response_avg.append(np.nanmean(day[:, :, win[0]:win[1]], axis=2))\n",
    "\n",
    "        # Compare response amplitude to baseline.\n",
    "        n_cells = data_subtype[0].shape[0]\n",
    "        p_values = [np.zeros(n_cells) for _ in range(len(data_subtype))]\n",
    "        for iday, day in enumerate(data_subtype):\n",
    "            for icell in range(n_cells):\n",
    "                # Temporary fix for cells that are always 0 due to baseline substraction.\n",
    "                if np.all(baseline_avg[iday][icell] == 0.):\n",
    "                    p_values[iday][icell] = 1\n",
    "                else:\n",
    "                    _, p_values[iday][icell] = wilcoxon(baseline_avg[iday][icell], response_avg[iday][icell])\n",
    "        p_values = np.stack(p_values, axis=0)\n",
    "        responsive_p_values[mouse_id][cell_type] = p_values\n",
    "\n",
    "\n",
    "        # # Compute dimensionality of the population response.\n",
    "        # # --------------------------------------------------\n",
    "\n",
    "        # dimensionality[mouse_id][cell_type] = []\n",
    "        # pca_results = []\n",
    "        # for day in data_subtype:\n",
    "        #     print(day.shape)\n",
    "        #     X = np.mean(day[:,:,win[0]:win[1]], axis=2)\n",
    "        #     X = X.T\n",
    "        #     X = StandardScaler(with_mean=True, with_std=True).fit_transform(X)\n",
    "        #     pca = PCA()\n",
    "        #     model = pca.fit(X)\n",
    "        #     n_comp = np.sum(model.explained_variance_ratio_.cumsum() < variance_explained_thr) + 1\n",
    "        #     dimensionality[mouse_id][cell_type].append(n_comp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quantify population response across days."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "mouse_ids = average_response.keys()\n",
    "\n",
    "df = []\n",
    "for mouse_id in mouse_ids:\n",
    "    for cell_type in average_response[mouse_id].keys():\n",
    "        for iday in range(len(days)):\n",
    "            amp = np.nanmean(np.nanmean(average_response[mouse_id][cell_type][iday], axis=1), axis=0) * 100\n",
    "            peak = np.nanmean(np.nanmean(peak_response[mouse_id][cell_type][iday], axis=1), axis=0) * 100\n",
    "            prop_resp_05 = np.sum(responsive_p_values[mouse_id][cell_type][iday] <= 0.05) / responsive_p_values[mouse_id][cell_type][iday].size * 100\n",
    "            prop_resp_01 = np.sum(responsive_p_values[mouse_id][cell_type][iday] <= 0.01) / responsive_p_values[mouse_id][cell_type][iday].size * 100\n",
    "            # dim = dimensionality[mouse_id][cell_type][iday]\n",
    "            temp = pd.DataFrame([[amp, peak, prop_resp_05, prop_resp_01, days[iday],\n",
    "                                mouse_id, metadata[mouse_id]['reward_group'], cell_type]],\n",
    "                                columns=['population_response', 'peak_response', 'prop_responsive_thr_0.05',\n",
    "                                         'prop_responsive_thr_0.01', 'day', 'mouse_id', 'reward_group', 'cell_type'])\n",
    "            df.append(temp)\n",
    "df = pd.concat(df)\n",
    "\n",
    "output_dir = r'//sv-nas1.rcp.epfl.ch/Petersen-Lab/analysis/Anthony_Renard/analysis_output/sensory_plasticity'\n",
    "for cell_type in ['allcells', 'wS2', 'wM1']:\n",
    "\n",
    "    svg_file = f'responses_across_learning_{cell_type}.svg'\n",
    "    df_file = f'responses_across_learning_{cell_type}.csv'\n",
    "\n",
    "    sns.set_theme(context='talk', style='ticks', palette='deep', font='sans-serif', font_scale=1)\n",
    "    palette = sns.color_palette(['#238443', '#d51a1c'])\n",
    "\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(10, 6), sharex=True)\n",
    "    sns.barplot(data=df[df.cell_type==cell_type], x='day', y='population_response', hue='reward_group',\n",
    "                ax=axes[0,0], legend=False, hue_order=['R+', 'R-'], palette=palette)\n",
    "    axes[0,0].set_title('Amplitude')\n",
    "    axes[0,0].set_ylabel(r'% dF/F')\n",
    "    axes[0,0].set_ylim([0, 6])\n",
    "\n",
    "    sns.barplot(data=df[df.cell_type==cell_type], x='day', y='peak_response', hue='reward_group',\n",
    "                ax=axes[1,0], legend=False, hue_order=['R+', 'R-'], palette=palette)\n",
    "    axes[1,0].set_title('Peak')\n",
    "    axes[1,0].set_ylabel(r'% dF/F')\n",
    "    axes[1,0].set_ylim([0, 30])\n",
    "\n",
    "    sns.barplot(data=df[df.cell_type==cell_type], x='day', y='prop_responsive_thr_0.01', hue='reward_group',\n",
    "                ax=axes[1,1], hue_order=['R+', 'R-'], palette=palette)\n",
    "    axes[1,1].set_title(r'% responsive cells (p<0.01)')\n",
    "    axes[1,1].set_ylabel(r'% responsive')\n",
    "    axes[1,1].set_ylim([0, 100])\n",
    "\n",
    "    sns.despine()\n",
    "    plt.tight_layout()\n",
    "    plt.suptitle(cell_type)\n",
    "    plt.savefig(os.path.join(output_dir, svg_file), format='svg')\n",
    "    df.to_csv(os.path.join(output_dir, df_file), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Amplitude and proportion of significant cells only for each population."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cell type allcells Day -2: p-value = 1.0\n",
      "Cell type allcells Day -1: p-value = 0.9841653411945137\n",
      "Cell type allcells Day 0: p-value = 0.02759273177042067\n",
      "Cell type allcells Day +1: p-value = 0.0013964497904225218\n",
      "Cell type allcells Day +2: p-value = 0.0010574718299194757\n",
      "Cell type wS2 Day -2: p-value = 0.8028850291124622\n",
      "Cell type wS2 Day -1: p-value = 0.5602735733449105\n",
      "Cell type wS2 Day 0: p-value = 0.09067732403710933\n",
      "Cell type wS2 Day +1: p-value = 0.02466970946003466\n",
      "Cell type wS2 Day +2: p-value = 0.0327123776970761\n",
      "Cell type wM1 Day -2: p-value = 0.8580276569875211\n",
      "Cell type wM1 Day -1: p-value = 0.6333423006990662\n",
      "Cell type wM1 Day 0: p-value = 0.37109336952269756\n",
      "Cell type wM1 Day +1: p-value = 0.43823907554994224\n",
      "Cell type wM1 Day +2: p-value = 0.10740463633025366\n"
     ]
    }
   ],
   "source": [
    "\n",
    "output_dir = r'//sv-nas1.rcp.epfl.ch/Petersen-Lab/analysis/Anthony_Renard/analysis_output/sensory_plasticity/psth'\n",
    "\n",
    "svg_file = f'amplitude_histogram_unmotivated.svg'\n",
    "df_file = f'amplitude_histogram_unmotivated.csv'\n",
    "pvalue_file = f'amplitude_histogram_unmotivated_pvalues.csv'\n",
    "\n",
    "sns.set_theme(context='talk', style='ticks', palette='deep', font='sans-serif', font_scale=1)\n",
    "palette = sns.color_palette(['#238443', '#d51a1c'])\n",
    "\n",
    "fig = sns.catplot(data=df, x='day', y='population_response', hue='reward_group', col='cell_type',\n",
    "            kind='bar', legend=False, hue_order=['R+', 'R-'], palette=palette)\n",
    "plt.suptitle('Amplitude')\n",
    "plt.ylabel(r'% dF/F')   \n",
    "# plt.ylim([0, 100])\n",
    "\n",
    "# Perform Mann-Whitney U test to check if the difference between the two reward groups is significant for each day and cell type.\n",
    "results = []\n",
    "for cell_type in df['cell_type'].unique():\n",
    "    for day in df['day'].unique():\n",
    "        group_rew = df[(df['day'] == day) & (df['reward_group'] == 'R+') & (df['cell_type'] == cell_type)]['population_response']\n",
    "        group_unrew = df[(df['day'] == day) & (df['reward_group'] == 'R-') & (df['cell_type'] == cell_type)]['population_response']\n",
    "        stat, p = mannwhitneyu(group_rew, group_unrew)\n",
    "        results.append({'cell_type': cell_type, 'day': day, 'p_value': p})\n",
    "        print(f'Cell type {cell_type} Day {day}: p-value = {p}')\n",
    "\n",
    "# Convert results to a DataFrame and save as CSV\n",
    "results_df = pd.DataFrame(results)\n",
    "# Add stars to the plot for each subplot\n",
    "for ax in fig.axes.flat:\n",
    "    cell_type = ax.get_title().split(' = ')[-1]\n",
    "    for result in results:\n",
    "        if result['cell_type'] == cell_type:\n",
    "            day_index = list(df['day'].unique()).index(result['day'])\n",
    "            if result['p_value'] < 0.05:\n",
    "                ax.text(day_index, 10, '*', ha='center', va='bottom', color='black')\n",
    "            if result['p_value'] < 0.01:\n",
    "                ax.text(day_index, 10, '**', ha='center', va='bottom', color='black')\n",
    "            if result['p_value'] < 0.001:\n",
    "                ax.text(day_index, 10, '***', ha='center', va='bottom', color='black')\n",
    "\n",
    "sns.despine()\n",
    "# plt.tight_layout()\n",
    "plt.savefig(os.path.join(output_dir, svg_file), format='svg')\n",
    "df.to_csv(os.path.join(output_dir, df_file), index=False)\n",
    "results_df.to_csv(os.path.join(output_dir, pvalue_file), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cell type allcells Day -2: p-value = 0.07090482557629343\n",
      "Cell type allcells Day -1: p-value = 0.08422189624865307\n",
      "Cell type allcells Day 0: p-value = 0.016328024119138175\n",
      "Cell type allcells Day +1: p-value = 0.0007960612010168237\n",
      "Cell type allcells Day +2: p-value = 0.00012788770850288427\n",
      "Cell type wS2 Day -2: p-value = 0.38990740161738124\n",
      "Cell type wS2 Day -1: p-value = 0.2916362440467125\n",
      "Cell type wS2 Day 0: p-value = 0.24389001329596105\n",
      "Cell type wS2 Day +1: p-value = 0.002038784480434768\n",
      "Cell type wS2 Day +2: p-value = 0.0024970589395121056\n",
      "Cell type wM1 Day -2: p-value = 0.17923911846412488\n",
      "Cell type wM1 Day -1: p-value = 0.14360745604501088\n",
      "Cell type wM1 Day 0: p-value = 0.24451814060285926\n",
      "Cell type wM1 Day +1: p-value = 0.033846876635162365\n",
      "Cell type wM1 Day +2: p-value = 0.002518533777682309\n"
     ]
    }
   ],
   "source": [
    "\n",
    "output_dir = r'//sv-nas1.rcp.epfl.ch/Petersen-Lab/analysis/Anthony_Renard/analysis_output/sensory_plasticity/psth'\n",
    "\n",
    "svg_file = f'responsivecells_histogram_unmotivated.svg'\n",
    "df_file = f'responsivecells_histogram_unmotivated.csv'\n",
    "pvalue_file = f'responsivecells_histogram_unmotivated_pvalues.csv'\n",
    "\n",
    "sns.set_theme(context='talk', style='ticks', palette='deep', font='sans-serif', font_scale=1)\n",
    "palette = sns.color_palette(['#238443', '#d51a1c'])\n",
    "\n",
    "fig = sns.catplot(data=df, x='day', y='prop_responsive_thr_0.01', hue='reward_group', col='cell_type',\n",
    "            kind='bar', legend=False, hue_order=['R+', 'R-'], palette=palette)\n",
    "plt.suptitle('Proportion responsive cells (MW test p<0.01)')\n",
    "# plt.ylabel(r'% dF/F')   \n",
    "plt.ylim([0, 100])\n",
    "\n",
    "# Perform Mann-Whitney U test to check if the difference between the two reward groups is significant for each day and cell type.\n",
    "results = []\n",
    "for cell_type in df['cell_type'].unique():\n",
    "    for day in df['day'].unique():\n",
    "        group_rew = df[(df['day'] == day) & (df['reward_group'] == 'R+') & (df['cell_type'] == cell_type)]['prop_responsive_thr_0.01']\n",
    "        group_unrew = df[(df['day'] == day) & (df['reward_group'] == 'R-') & (df['cell_type'] == cell_type)]['prop_responsive_thr_0.01']\n",
    "        stat, p = mannwhitneyu(group_rew, group_unrew)\n",
    "        results.append({'cell_type': cell_type, 'day': day, 'p_value': p})\n",
    "        print(f'Cell type {cell_type} Day {day}: p-value = {p}')\n",
    "\n",
    "# Convert results to a DataFrame and save as CSV\n",
    "results_df = pd.DataFrame(results)\n",
    "# Add stars to the plot for each subplot\n",
    "for ax in fig.axes.flat:\n",
    "    cell_type = ax.get_title().split(' = ')[-1]\n",
    "    for result in results:\n",
    "        if result['cell_type'] == cell_type:\n",
    "            day_index = list(df['day'].unique()).index(result['day'])\n",
    "            if result['p_value'] < 0.05:\n",
    "                ax.text(day_index, 10, '*', ha='center', va='bottom', color='black')\n",
    "            if result['p_value'] < 0.01:\n",
    "                ax.text(day_index, 10, '**', ha='center', va='bottom', color='black')\n",
    "            if result['p_value'] < 0.001:\n",
    "                ax.text(day_index, 10, '***', ha='center', va='bottom', color='black')\n",
    "\n",
    "sns.despine()\n",
    "# plt.tight_layout()\n",
    "plt.savefig(os.path.join(output_dir, svg_file), format='svg')\n",
    "df.to_csv(os.path.join(output_dir, df_file), index=False)\n",
    "results_df.to_csv(os.path.join(output_dir, pvalue_file), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Correlation matrices and responsive similarity across learning.\n",
    "\n",
    "## 2.1. For each mouse individually.\n",
    "\n",
    "Plot population vectors rasters and correlation matrices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['GF305', 'GF306', 'GF307', 'GF308', 'GF310', 'GF311', 'GF313', 'GF314', 'GF317', 'GF318', 'GF319', 'GF323', 'GF333', 'GF334', 'GF348', 'GF350', 'MI062', 'MI069', 'MI072', 'MI075', 'MI076', 'AR132', 'AR133', 'AR137', 'AR139', 'AR127', 'AR143', 'AR163', 'AR177', 'AR178', 'AR179', 'AR180']\n"
     ]
    }
   ],
   "source": [
    "# Parameters.\n",
    "\n",
    "sampling_rate = 30\n",
    "win = (1, 1.180)  # from stimulus onset to 300 ms after.\n",
    "win_length = f'{int(np.round((win[1]-win[0]) * 1000))}'  # for file naming.\n",
    "win = (int(win[0] * sampling_rate), int(win[1] * sampling_rate))\n",
    "baseline_win = (0, 1)\n",
    "baseline_win = (int(baseline_win[0] * sampling_rate), int(baseline_win[1] * sampling_rate))\n",
    "days = ['-2', '-1', '0', '+1', '+2']\n",
    "substract_baseline = True\n",
    "sns.set_theme(context='paper', style='ticks', palette='deep', font='sans-serif', font_scale=1)\n",
    "\n",
    "_, _, mice, _ = io.select_sessions_from_db(db_path,\n",
    "                                            nwb_dir,\n",
    "                                            two_p_imaging='yes',)\n",
    "print(mice)\n",
    "excluded_mice = ['GF307', 'GF310', 'GF333', 'MI075', 'AR144', 'AR135', 'AR163']\n",
    "mice = [m for m in mice if m not in excluded_mice]\n",
    "mice = ['AR127']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['GF305', 'GF306', 'GF308', 'GF311', 'GF313', 'GF314', 'GF317', 'GF318', 'GF323', 'GF334', 'AR133', 'AR127', 'AR143', 'AR177']\n",
      "14\n",
      "['GF319', 'GF348', 'GF350', 'MI062', 'MI069', 'MI072', 'MI076', 'AR132', 'AR137', 'AR139', 'AR178', 'AR179', 'AR180']\n",
      "13\n"
     ]
    }
   ],
   "source": [
    "rewarded_mice = [mouse_id for mouse_id in metadata.keys() if metadata[mouse_id]['reward_group'] == 'R+']\n",
    "count_rewarded_mice = len(rewarded_mice)\n",
    "nonrewarded_mice = [mouse_id for mouse_id in metadata.keys() if metadata[mouse_id]['reward_group'] == 'R-']\n",
    "count_nonrewarded_mice = len(nonrewarded_mice)\n",
    "print(rewarded_mice)\n",
    "print(len(rewarded_mice))\n",
    "print(nonrewarded_mice)\n",
    "print(len(nonrewarded_mice))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the data and save computations in dictionnaries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['AR127_20240221_133407', 'AR127_20240222_152629', 'AR127_20240223_131820', 'AR127_20240224_140853', 'AR127_20240225_142858']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "def load_psth_data(mouse_id, days, win, baseline_win, processed_dir):\n",
    "    session_list, _, _, _ = io.select_sessions_from_db(db_path,\n",
    "                                                        nwb_dir,\n",
    "                                                        two_p_imaging='yes',\n",
    "                                                        subject_id=mouse_id,\n",
    "                                                        day=days,)\n",
    "    print(session_list)\n",
    "\n",
    "    data = []\n",
    "    mdata_list = []\n",
    "    for session_id in session_list:\n",
    "        arr, mdata = imaging_utils.load_session_2p_imaging(mouse_id,\n",
    "                                                            session_id,\n",
    "                                                            processed_dir)\n",
    "        if substract_baseline:\n",
    "            arr = imaging_utils.substract_baseline(arr, 3, baseline_win)\n",
    "            \n",
    "        data.append(arr)\n",
    "        mdata_list.append(mdata)\n",
    "        \n",
    "        # Create xarray including the metadata\n",
    "        coords = {'trial': np.arange(data[0].shape[1]), 'cell': np.arange(data[0].shape[0]), 'day': days}\n",
    "        data_xr = xr.DataArray(np.stack(data, axis=-1), dims=('cell', 'trial', 'day'), coords=coords)\n",
    "        data_xr.attrs['mouse_id'] = mouse_id\n",
    "        data_xr.attrs['reward_group'] = reward_group\n",
    "        data_xr.attrs['cell_types'] = mdata_list[0]['cell_types']\n",
    "        data_xr.attrs['rois'] = mdata_list[0]['rois']\n",
    "\n",
    "\n",
    "\n",
    "metadata = {}\n",
    "response_amp = {}\n",
    "corr_avg_days = {}\n",
    "corr_avg_pre_post = {}\n",
    "lmi = {}\n",
    "lmi_p = {}\n",
    "responsive_p_values = {}\n",
    "globally_responsive = {}\n",
    "\n",
    "# mice = ['AR127']\n",
    "\n",
    "for mouse_id in mice:\n",
    "    session_list, nwb_files, _, db_filtered = io.select_sessions_from_db(db_path,\n",
    "                                                                        nwb_dir,\n",
    "                                                                        two_p_imaging='yes',\n",
    "                                                                        subject_id=mouse_id,\n",
    "                                                                        day=days,)\n",
    "    print(session_list)\n",
    "\n",
    "    data = []\n",
    "    mdata_list = []\n",
    "    for session_id in session_list:\n",
    "        arr, mdata = imaging_utils.load_session_2p_imaging(mouse_id,\n",
    "                                                            session_id,\n",
    "                                                            processed_dir)\n",
    "        if substract_baseline:\n",
    "            arr = imaging_utils.substract_baseline(arr, 3, baseline_win)\n",
    "        data.append(arr)\n",
    "        mdata_list.append(mdata)\n",
    "\n",
    "    reward_group = io.get_reward_group_from_db(db_path, session_list[0])\n",
    "    metadata[mouse_id] = {}\n",
    "    metadata[mouse_id]['reward_group'] = reward_group\n",
    "    metadata[mouse_id]['rois'] = mdata_list[0]['rois']\n",
    "    metadata[mouse_id]['cell_types'] = mdata_list[0]['cell_types']\n",
    "    \n",
    "    for d, mday in enumerate(mdata_list):\n",
    "        metadata[mouse_id][days[d]] = {}\n",
    "        metadata[mouse_id][days[d]]['trials'] = mdata_list[d]['trials']\n",
    "        metadata[mouse_id][days[d]]['trial_types'] = mdata_list[d]['trial_types']\n",
    "\n",
    "    # Extract UM trials.\n",
    "    for i, arr in enumerate(data):\n",
    "        arr = imaging_utils.extract_trials(arr, mdata_list[i], trial_type, n_trials=None)\n",
    "        data[i] = arr\n",
    "\n",
    "    return data, \n",
    "\n",
    "\n",
    "metadata = {}\n",
    "response_amp = {}\n",
    "corr_avg_days = {}\n",
    "corr_avg_pre_post = {}\n",
    "responsive_p_values = {}\n",
    "globally_responsive = {}\n",
    "\n",
    "# Load lmi dicts.\n",
    "lmi = np.load(r'\\\\sv-nas1.rcp.epfl.ch\\Petersen-Lab\\analysis\\Anthony_Renard\\data_processed\\lmi.npy', allow_pickle=True).item()\n",
    "lmi_p = np.load(r'\\\\sv-nas1.rcp.epfl.ch\\Petersen-Lab\\analysis\\Anthony_Renard\\data_processed\\lmi_p.npy', allow_pickle=True).item()\n",
    "\n",
    "# mice = ['AR127']\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    response_amp[mouse_id] = {}\n",
    "    corr_avg_days[mouse_id] = {}\n",
    "    corr_avg_pre_post[mouse_id] = {}\n",
    "    responsive_p_values[mouse_id] = {}\n",
    "    globally_responsive[mouse_id] = {}\n",
    "\n",
    "    for cell_type in ['allcells', 'wS2', 'wM1']:\n",
    "\n",
    "        # Select cell type.\n",
    "        if cell_type == 'allcells':\n",
    "            data_subtype = data\n",
    "        else:\n",
    "            data_subtype = []\n",
    "            cell_type_mask = mdata_list[0]['cell_types']==cell_type\n",
    "            data_subtype = [arr[cell_type_mask] for arr in data]\n",
    "\n",
    "        # if cell_type == 'allcells':\n",
    "        #     # Example with and without strong cells for mouse AR127.\n",
    "        #     strong_cells = [3,11,33,48,57,67,80,86,104,153,166,175]\n",
    "        #     mask = np.ones(data_subtype[0].shape[0], dtype=bool)\n",
    "        #     mask[strong_cells] = False\n",
    "        #     data_subtype = [arr[mask] for arr in data_subtype]\n",
    "\n",
    "        # If no cells of the specified type, skip.\n",
    "        if data_subtype[0].shape[0] == 0:\n",
    "            continue\n",
    "\n",
    "        # Compute average response for each trial, each day.\n",
    "        response_amp[mouse_id][cell_type] = []\n",
    "        for day in data_subtype:\n",
    "            response_amp[mouse_id][cell_type].append(np.nanmean(day[:, :, win[0]:win[1]], axis=2))\n",
    "\n",
    "        # Compute LMI.\n",
    "        # if cell_type == 'allcells':\n",
    "        #     # # pre = np.mean(np.concatenate(response_amp[0:2], axis=1), axis=1)\n",
    "        #     # # print(pre.shape)\n",
    "        #     # # post = np.mean(np.concatenate((response_amp[5], response_amp[7]), axis=1), axis=1)\n",
    "        #     # # lmi[mouse_id] = (post - pre) / (np.abs(post) + np.abs(pre))\n",
    "\n",
    "        #     # lmis = []\n",
    "        #     # ncells = len(metadata[mouse_id]['rois'])\n",
    "        #     # for icell in range(ncells):\n",
    "        #     #     # mapping trials of D-2, D-1, D+1, D+2.\n",
    "        #     #     X = np.r_[response_amp[mouse_id][cell_type][0][icell], response_amp[mouse_id][cell_type][1][icell],\n",
    "        #     #               response_amp[mouse_id][cell_type][3][icell], response_amp[mouse_id][cell_type][4][icell]]\n",
    "        #     #     y = np.r_[np.zeros(response_amp[mouse_id][cell_type][0][icell].shape[0]),\n",
    "        #     #               np.zeros(response_amp[mouse_id][cell_type][1][icell].shape[0]),\n",
    "        #     #               np.ones(response_amp[mouse_id][cell_type][3][icell].shape[0]),\n",
    "        #     #               np.ones(response_amp[mouse_id][cell_type][4][icell].shape[0])]\n",
    "        #     #     fpr, tpr, _ = roc_curve(y, X)\n",
    "        #     #     roc_auc = auc(fpr, tpr)\n",
    "        #     #     lmis.append((roc_auc - 0.5) * 2)\n",
    "        #     # lmi[mouse_id]['allcells'] = np.array(lmis)\n",
    "\n",
    "        #     pre = [response_amp[mouse_id][cell_type][days.index('-2')],\n",
    "        #            response_amp[mouse_id][cell_type][days.index('-1')]]\n",
    "        #     pre = np.concatenate(pre, axis=1)\n",
    "        #     post = [response_amp[mouse_id][cell_type][days.index('+1')],\n",
    "        #             response_amp[mouse_id][cell_type][days.index('+2')]]\n",
    "        #     post = np.concatenate(post, axis=1)\n",
    "        #     lmi[mouse_id]['allcells'], lmi_p[mouse_id]['allcells'] = imaging_utils.compute_lmi(pre, post, nshuffles=None)\n",
    "        # else:\n",
    "        #     lmi[mouse_id][cell_type] = lmi[mouse_id]['allcells'][metadata[mouse_id]['cell_types'] == cell_type]\n",
    "        #     lmi_p[mouse_id][cell_type] = lmi_p[mouse_id]['allcells'][metadata[mouse_id]['cell_types'] == cell_type]\n",
    "\n",
    "\n",
    "        # # Test responsiveness.\n",
    "        # if cell_type == 'allcells':\n",
    "        #     base = []\n",
    "        #     resp = []\n",
    "        #     for day in data_subtype:\n",
    "        #         base.append(np.nanmean(day[:, :, baseline_win[0]:baseline_win[1]], axis=2))\n",
    "        #         resp.append(np.nanmean(day[:, :, win[0]:win[1]], axis=2))\n",
    "\n",
    "        #     # Compare response amplitude to baseline.\n",
    "        #     n_cells = data_subtype[0].shape[0]\n",
    "        #     p_values = [np.zeros(n_cells) for _ in range(len(data_subtype))]\n",
    "        #     for iday, day in enumerate(data_subtype):\n",
    "        #         for icell in range(n_cells):\n",
    "        #             # Temporary fix for cells that are always 0 due to baseline substraction.\n",
    "        #             if np.all(base[iday][icell] == 0.):\n",
    "        #                 p_values[iday][icell] = 1\n",
    "        #             else:\n",
    "        #                 _, p_values[iday][icell] = wilcoxon(base[iday][icell], resp[iday][icell])\n",
    "        #     p_values = np.stack(p_values, axis=1)\n",
    "        #     responsive_p_values[mouse_id][cell_type] = p_values\n",
    "\n",
    "        #     # Test global responsiveness by pulling trials of all days together.\n",
    "        #     base = np.concatenate(base, axis=1)\n",
    "        #     resp = np.concatenate(resp, axis=1)\n",
    "        #     p_values = np.zeros(n_cells)\n",
    "        #     for icell in range(n_cells):\n",
    "        #         # Temporary fix for cells that are always 0 due to baseline substraction.\n",
    "        #         if np.all(base[icell] == 0.):\n",
    "        #             p_values[icell] = 1\n",
    "        #         else:\n",
    "        #             _, p_values[icell] = wilcoxon(base[icell], resp[icell])\n",
    "        #         globally_responsive[mouse_id][cell_type] = p_values\n",
    "        # else:\n",
    "        #     responsive_p_values[mouse_id][cell_type] = responsive_p_values[mouse_id]['allcells'][metadata[mouse_id]['cell_types'] == cell_type]\n",
    "        #     globally_responsive[mouse_id][cell_type] = globally_responsive[mouse_id]['allcells'][metadata[mouse_id]['cell_types'] == cell_type]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot individual population vector rasters and correlation matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "cell_selection = 'no_selection'\n",
    "responsiveness_thr = 0.001\n",
    "# percent_best_lmi = 15\n",
    "# lmi_thr = np.percentile(np.abs(np.concatenate([lmi[mouse_id]['allcells'] for mouse_id in mice])), 100-percent_best_lmi)\n",
    "sns.set_theme(context='paper', style='ticks', palette='deep', font='sans-serif', font_scale=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GF305 [50, 50, 50, 50, 50]\n",
      "GF305 [50, 50, 50, 50, 50]\n",
      "GF305 [50, 50, 50, 50, 50]\n",
      "GF306 [50, 50, 50, 50, 50]\n",
      "GF306 [50, 50, 50, 50, 50]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\envs\\fast-learning\\Lib\\site-packages\\numpy\\lib\\_function_base_impl.py:2991: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  c = cov(x, y, rowvar, dtype=dtype)\n",
      "c:\\ProgramData\\anaconda3\\envs\\fast-learning\\Lib\\site-packages\\numpy\\lib\\_function_base_impl.py:2848: RuntimeWarning: divide by zero encountered in divide\n",
      "  c *= np.true_divide(1, fact)\n",
      "c:\\ProgramData\\anaconda3\\envs\\fast-learning\\Lib\\site-packages\\numpy\\lib\\_function_base_impl.py:2848: RuntimeWarning: invalid value encountered in multiply\n",
      "  c *= np.true_divide(1, fact)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GF306 [50, 50, 50, 50, 50]\n",
      "GF308 [50, 50, 50, 50, 50]\n",
      "GF308 [50, 50, 50, 50, 50]\n",
      "GF308 [50, 50, 50, 50, 50]\n",
      "GF311 [50, 50, 50, 50, 50]\n",
      "GF311 [50, 50, 50, 50, 50]\n",
      "GF313 [50, 50, 50, 50, 50]\n",
      "GF313 [50, 50, 50, 50, 50]\n",
      "GF313 [50, 50, 50, 50, 50]\n",
      "GF314 [50, 50, 50, 50, 50]\n",
      "GF314 [50, 50, 50, 50, 50]\n",
      "GF314 [50, 50, 50, 50, 50]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\envs\\fast-learning\\Lib\\site-packages\\numpy\\lib\\_function_base_impl.py:2991: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  c = cov(x, y, rowvar, dtype=dtype)\n",
      "c:\\ProgramData\\anaconda3\\envs\\fast-learning\\Lib\\site-packages\\numpy\\lib\\_function_base_impl.py:2848: RuntimeWarning: divide by zero encountered in divide\n",
      "  c *= np.true_divide(1, fact)\n",
      "c:\\ProgramData\\anaconda3\\envs\\fast-learning\\Lib\\site-packages\\numpy\\lib\\_function_base_impl.py:2848: RuntimeWarning: invalid value encountered in multiply\n",
      "  c *= np.true_divide(1, fact)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GF317 [50, 50, 50, 50, 50]\n",
      "GF317 [50, 50, 50, 50, 50]\n",
      "GF317 [50, 50, 50, 50, 50]\n",
      "GF318 [50, 50, 50, 50, 50]\n",
      "GF318 [50, 50, 50, 50, 50]\n",
      "GF318 [50, 50, 50, 50, 50]\n",
      "GF319 [50, 50, 50, 50, 50]\n",
      "GF323 [50, 50, 50, 50, 50]\n",
      "GF323 [50, 50, 50, 50, 50]\n",
      "GF323 [50, 50, 50, 50, 50]\n",
      "GF334 [50, 50, 50, 50, 50]\n",
      "GF334 [50, 50, 50, 50, 50]\n",
      "GF334 [50, 50, 50, 50, 50]\n",
      "GF348 [50, 50, 50, 50, 50]\n",
      "GF350 [50, 50, 50, 50, 50]\n",
      "MI062 [50, 50, 50, 50, 50]\n",
      "MI069 [50, 50, 50, 50, 50]\n",
      "MI069 [50, 50, 50, 50, 50]\n",
      "MI072 [50, 50, 50, 50, 50]\n",
      "MI072 [50, 50, 50, 50, 50]\n",
      "MI072 [50, 50, 50, 50, 50]\n",
      "MI076 [50, 50, 50, 50, 50]\n",
      "MI076 [50, 50, 50, 50, 50]\n",
      "MI076 [50, 50, 50, 50, 50]\n",
      "AR132 [50, 50, 50, 50, 50]\n",
      "AR132 [50, 50, 50, 50, 50]\n",
      "AR132 [50, 50, 50, 50, 50]\n",
      "AR133 [50, 49, 50, 50, 50]\n",
      "AR133 [50, 49, 50, 50, 50]\n",
      "AR137 [50, 49, 50, 50, 50]\n",
      "AR137 [50, 49, 50, 50, 50]\n",
      "AR137 [50, 49, 50, 50, 50]\n",
      "AR139 [50, 50, 50, 50, 50]\n",
      "AR139 [50, 50, 50, 50, 50]\n",
      "AR127 [49, 49, 50, 49, 49]\n",
      "AR127 [49, 49, 50, 49, 49]\n",
      "AR143 [50, 50, 50, 50, 50]\n",
      "AR143 [50, 50, 50, 50, 50]\n",
      "AR143 [50, 50, 50, 50, 50]\n",
      "AR177 [50, 50, 50, 50, 50]\n",
      "AR177 [50, 50, 50, 50, 50]\n",
      "AR178 [50, 50, 50, 50, 50]\n",
      "AR178 [50, 50, 50, 50, 50]\n",
      "AR179 [50, 50, 50, 50, 50]\n",
      "AR179 [50, 50, 50, 50, 50]\n",
      "AR179 [50, 50, 50, 50, 50]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\envs\\fast-learning\\Lib\\site-packages\\numpy\\lib\\_function_base_impl.py:2991: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  c = cov(x, y, rowvar, dtype=dtype)\n",
      "c:\\ProgramData\\anaconda3\\envs\\fast-learning\\Lib\\site-packages\\numpy\\lib\\_function_base_impl.py:2848: RuntimeWarning: divide by zero encountered in divide\n",
      "  c *= np.true_divide(1, fact)\n",
      "c:\\ProgramData\\anaconda3\\envs\\fast-learning\\Lib\\site-packages\\numpy\\lib\\_function_base_impl.py:2848: RuntimeWarning: invalid value encountered in multiply\n",
      "  c *= np.true_divide(1, fact)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AR180 [50, 50, 50, 50, 50]\n",
      "AR180 [50, 50, 50, 50, 50]\n",
      "AR180 [50, 50, 50, 50, 50]\n"
     ]
    }
   ],
   "source": [
    "pdf_file = f'correlation_matrices_pop_vector_individual_mice_win_{win_length}_ms_{cell_selection}.pdf'\n",
    "output_dir = fr'//sv-nas1.rcp.epfl.ch/Petersen-Lab/analysis/Anthony_Renard/analysis_output/sensory_plasticity/correlation_matrices'\n",
    "\n",
    "with PdfPages(os.path.join(output_dir, pdf_file)) as pdf:\n",
    "    for mouse_id in mice:\n",
    "        for cell_type in ['allcells', 'wS2', 'wM1']:\n",
    "            reward_group = metadata[mouse_id]['reward_group']\n",
    "\n",
    "            if cell_type not in response_amp[mouse_id].keys():\n",
    "                continue\n",
    "\n",
    "            if cell_selection == 'no_selection':\n",
    "                selected_cells = np.ones(response_amp[mouse_id][cell_type][0].shape[0], dtype=bool)\n",
    "            elif cell_selection == 'responsive':\n",
    "                selected_cells = globally_responsive[mouse_id][cell_type] <= responsiveness_thr\n",
    "            elif cell_selection == 'lmi':\n",
    "                selected_cells = (lmi_p[mouse_id][cell_type] >= 0.975) | (lmi_p[mouse_id][cell_type] <= 0.025)\n",
    "            \n",
    "            if np.sum(selected_cells) == 0:\n",
    "                continue\n",
    "\n",
    "            pop_vectors = [np.copy(arr[selected_cells]) for arr in response_amp[mouse_id][cell_type]]\n",
    "            n_trials = [arr.shape[1] for arr in pop_vectors]\n",
    "            print(f'{mouse_id} {n_trials}')\n",
    "            pop_vectors = np.concatenate(pop_vectors, axis=1)\n",
    "            corr_matrix = np.corrcoef(pop_vectors.T)\n",
    "\n",
    "            # Plot population vectors.\n",
    "            vmax = np.percentile(pop_vectors, 98)\n",
    "            vmin = np.percentile(pop_vectors, 2)\n",
    "            edges = np.cumsum(n_trials)\n",
    "            for i in edges[:-1] - 0.5:\n",
    "                plt.axvline(x=i, color='#252525', linestyle='-', lw=0.5)\n",
    "            plt.xticks(edges - 0.5, edges)\n",
    "            f = plt.figure()\n",
    "            im = plt.imshow(pop_vectors, cmap='viridis', vmin=vmin, vmax=vmax)\n",
    "            cbar = f.colorbar(im, ticks=[vmin, 0, vmax])\n",
    "            cbar.ax.set_yticklabels([f'{vmin:.2f}', '0', f'> {vmax:.2f}'])\n",
    "            cbar.ax.tick_params(size=0)\n",
    "            pdf.savefig(dpi=300)\n",
    "            plt.close()\n",
    "\n",
    "            # Set color map limit to the max without the diagonal.\n",
    "            vmax = np.percentile(corr_matrix[~np.eye(corr_matrix.shape[0], dtype=bool)], 98)\n",
    "            vmin = np.percentile(corr_matrix, 2)\n",
    "            f = plt.figure(figsize=(15, 15))\n",
    "            im = plt.imshow(corr_matrix, vmin = vmin, vmax=vmax, cmap='viridis')\n",
    "            n_trials = [arr.shape[1] for arr in response_amp[mouse_id][cell_type]]\n",
    "\n",
    "            for i in edges[:-1] - 0.5:\n",
    "                plt.axvline(x=i, color='#252525', linestyle='-', lw=0.5)\n",
    "                plt.axhline(y=i, color='#252525', linestyle='-', lw=0.5)\n",
    "            plt.xticks(edges - 0.5, edges)\n",
    "            plt.yticks(edges - 0.5, edges)\n",
    "            plt.title(f'{mouse_id} {reward_group} {cell_type}')\n",
    "            cbar_ax = f.add_axes([0.85, 0.15, 0.05, 0.7])\n",
    "            cbar = f.colorbar(im, cax=cbar_ax, ticks=[vmin, 0, vmax])\n",
    "            cbar.ax.set_yticklabels([f'{vmin:.2f}', '0', f'> {vmax:.2f}'])\n",
    "            cbar.ax.tick_params(size=0)\n",
    "            pdf.savefig(dpi=300)\n",
    "            plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2. Global population correlation matrix and population vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "\n",
    "zscore = False\n",
    "cell_selection = 'lmi'\n",
    "responsiveness_thr = 0.01\n",
    "# percent_best_lmi = 20\n",
    "# lmi_thr = np.percentile(np.abs(np.concatenate([lmi[mouse_id]['allcells'] for mouse_id in mice])), 100-percent_best_lmi)\n",
    "sns.set_theme(context='paper', style='ticks', palette='deep', font='sans-serif', font_scale=1)\n",
    "\n",
    "lmi = np.load(r'\\\\sv-nas1.rcp.epfl.ch\\Petersen-Lab\\analysis\\Anthony_Renard\\data_processed\\lmi.npy', allow_pickle=True).item()\n",
    "lmi_p = np.load(r'\\\\sv-nas1.rcp.epfl.ch\\Petersen-Lab\\analysis\\Anthony_Renard\\data_processed\\lmi_p.npy', allow_pickle=True).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "allcells R+ ['GF305', 'GF306', 'GF308', 'GF311', 'GF313', 'GF314', 'GF317', 'GF318', 'GF323', 'GF334', 'AR133', 'AR127', 'AR143', 'AR177']\n",
      "[50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 49, 50, 50]\n",
      "[50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 49, 49, 50, 50]\n",
      "[50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50]\n",
      "[50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 49, 50, 50]\n",
      "[50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 49, 50, 50]\n",
      "[np.int64(49), np.int64(49), np.int64(50), np.int64(49), np.int64(49)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aprenard\\AppData\\Local\\Temp\\ipykernel_33704\\1362183162.py:67: UserWarning: Attempting to set identical low and high ylims makes transformation singular; automatically expanding.\n",
      "  im = axes[i].imshow(pop_vectors[cell_start:cell_end], cmap='viridis', vmin=vmin_vectors, vmax=vmax_vectors)\n",
      "C:\\Users\\aprenard\\AppData\\Local\\Temp\\ipykernel_33704\\1362183162.py:67: UserWarning: Attempting to set identical low and high ylims makes transformation singular; automatically expanding.\n",
      "  im = axes[i].imshow(pop_vectors[cell_start:cell_end], cmap='viridis', vmin=vmin_vectors, vmax=vmax_vectors)\n",
      "C:\\Users\\aprenard\\AppData\\Local\\Temp\\ipykernel_33704\\1362183162.py:67: UserWarning: Attempting to set identical low and high ylims makes transformation singular; automatically expanding.\n",
      "  im = axes[i].imshow(pop_vectors[cell_start:cell_end], cmap='viridis', vmin=vmin_vectors, vmax=vmax_vectors)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "allcells R- ['GF319', 'GF348', 'GF350', 'MI062', 'MI076', 'AR132', 'AR137', 'AR139', 'AR178', 'AR179', 'AR180']\n",
      "[50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50]\n",
      "[50, 50, 50, 50, 50, 50, 49, 50, 50, 50, 50]\n",
      "[50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50]\n",
      "[50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50]\n",
      "[50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50]\n",
      "[np.int64(50), np.int64(49), np.int64(50), np.int64(50), np.int64(50)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aprenard\\AppData\\Local\\Temp\\ipykernel_33704\\1362183162.py:67: UserWarning: Attempting to set identical low and high ylims makes transformation singular; automatically expanding.\n",
      "  im = axes[i].imshow(pop_vectors[cell_start:cell_end], cmap='viridis', vmin=vmin_vectors, vmax=vmax_vectors)\n",
      "C:\\Users\\aprenard\\AppData\\Local\\Temp\\ipykernel_33704\\1362183162.py:67: UserWarning: Attempting to set identical low and high ylims makes transformation singular; automatically expanding.\n",
      "  im = axes[i].imshow(pop_vectors[cell_start:cell_end], cmap='viridis', vmin=vmin_vectors, vmax=vmax_vectors)\n",
      "C:\\Users\\aprenard\\AppData\\Local\\Temp\\ipykernel_33704\\1362183162.py:67: UserWarning: Attempting to set identical low and high ylims makes transformation singular; automatically expanding.\n",
      "  im = axes[i].imshow(pop_vectors[cell_start:cell_end], cmap='viridis', vmin=vmin_vectors, vmax=vmax_vectors)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wS2 R+ ['GF305', 'GF306', 'GF308', 'GF311', 'GF313', 'GF314', 'GF317', 'GF318', 'GF323', 'GF334', 'AR133', 'AR143', 'AR177']\n",
      "[50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50]\n",
      "[50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 49, 50, 50]\n",
      "[50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50]\n",
      "[50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50]\n",
      "[50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50]\n",
      "[np.int64(50), np.int64(49), np.int64(50), np.int64(50), np.int64(50)]\n",
      "wS2 R- ['MI076', 'AR132', 'AR137', 'AR139', 'AR178', 'AR179', 'AR180']\n",
      "[50, 50, 50, 50, 50, 50, 50]\n",
      "[50, 50, 49, 50, 50, 50, 50]\n",
      "[50, 50, 50, 50, 50, 50, 50]\n",
      "[50, 50, 50, 50, 50, 50, 50]\n",
      "[50, 50, 50, 50, 50, 50, 50]\n",
      "[np.int64(50), np.int64(49), np.int64(50), np.int64(50), np.int64(50)]\n",
      "wM1 R+ ['GF305', 'GF306', 'GF308', 'GF311', 'GF313', 'GF314', 'GF317', 'GF318', 'GF323', 'GF334', 'AR127', 'AR143', 'AR177']\n",
      "[50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 49, 50, 50]\n",
      "[50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 49, 50, 50]\n",
      "[50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50]\n",
      "[50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 49, 50, 50]\n",
      "[50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 49, 50, 50]\n",
      "[np.int64(49), np.int64(49), np.int64(50), np.int64(49), np.int64(49)]\n",
      "wM1 R- ['MI076', 'AR132', 'AR137', 'AR178', 'AR179', 'AR180']\n",
      "[50, 50, 50, 50, 50, 50]\n",
      "[50, 50, 49, 50, 50, 50]\n",
      "[50, 50, 50, 50, 50, 50]\n",
      "[50, 50, 50, 50, 50, 50]\n",
      "[50, 50, 50, 50, 50, 50]\n",
      "[np.int64(50), np.int64(49), np.int64(50), np.int64(50), np.int64(50)]\n"
     ]
    }
   ],
   "source": [
    "output_dir = fr'//sv-nas1.rcp.epfl.ch/Petersen-Lab/analysis/Anthony_Renard/analysis_output/sensory_plasticity/correlation_matrices'\n",
    "pdf_file = f'correlation_matrices_pop_vector_global_population_win_{win_length}_ms_cell_selection_{cell_selection}_zscore_{zscore}.pdf'\n",
    "\n",
    "response_amp_selection = {}\n",
    "with PdfPages(os.path.join(output_dir, pdf_file)) as pdf:\n",
    "    for cell_type in ['allcells', 'wS2', 'wM1']:\n",
    "        for reward_group in ['R+', 'R-']:\n",
    "            mice_ids = [mouse_id for mouse_id in mice if (metadata[mouse_id]['reward_group'] == reward_group)\n",
    "                                                         and (cell_type in response_amp[mouse_id].keys())]\n",
    "            mice_ids = [m for m in mice_ids if m not in ['MI069', 'MI072']]\n",
    "            print(cell_type, reward_group, mice_ids)\n",
    "            # # Copying because I will take a subset of the data.\n",
    "            # response_amp_selection = np.copy(response_amp).item()\n",
    "            # response_amp_selection = {mouse_id: response_amp_selection[mouse_id] for mouse_id in mice_ids if cell_type in response_amp_selection[mouse_id].keys()}\n",
    "\n",
    "            response_amp_selection[cell_type] = {}\n",
    "            for mouse_id in mice_ids:\n",
    "\n",
    "                response_amp_selection[cell_type][mouse_id] = []\n",
    "\n",
    "                if cell_selection == 'no_selection':\n",
    "                    selected_cells = np.ones(response_amp[mouse_id][cell_type][0].shape[0], dtype=bool)\n",
    "                elif cell_selection == 'responsive':\n",
    "                    selected_cells = globally_responsive[mouse_id][cell_type] <= responsiveness_thr\n",
    "                elif cell_selection == 'lmi':\n",
    "                    selected_cells = (lmi_p[mouse_id][cell_type] >= 0.975) | (lmi_p[mouse_id][cell_type] <= 0.025)\n",
    "\n",
    "\n",
    "                for iday in range(len(days)):\n",
    "                    temp = [np.copy(response_amp[mouse_id][cell_type][iday][selected_cells]) for iday in range(len(days))]\n",
    "                    response_amp_selection[cell_type][mouse_id] = temp\n",
    "\n",
    "            # Even the number of trials per days across mice.\n",
    "            min_trials = []\n",
    "            for iday in range(len(days)):\n",
    "                m = [data[iday].shape[1] for _, data in response_amp_selection[cell_type].items()]\n",
    "                print(m)\n",
    "                min_trials.append(np.min(m))\n",
    "            print(min_trials)\n",
    "\n",
    "            for mouse_id, data in response_amp_selection[cell_type].items():\n",
    "                for iday in range(len(days)):\n",
    "                    response_amp_selection[cell_type][mouse_id][iday] = data[iday][:, :min_trials[iday]]\n",
    "            \n",
    "            pop_vectors = np.concatenate([np.concatenate(data, axis=1) for _, data in response_amp_selection[cell_type].items()], axis=0)\n",
    "            # AR180 has some cells with 0. response whichi gives nan.\n",
    "            pop_vectors = np.nan_to_num(pop_vectors, nan=0.0)\n",
    "            if zscore:\n",
    "                pop_vectors = (pop_vectors - np.mean(pop_vectors, axis=1, keepdims=True)) / np.std(pop_vectors, axis=1, keepdims=True)\n",
    "                pop_vectors = np.nan_to_num(pop_vectors, nan=0.0)\n",
    "\n",
    "\n",
    "            \n",
    "            corr_matrix = np.corrcoef(pop_vectors.T)\n",
    "            # corr_matrix = spearmanr(pop_vectors.T, axis=1)[0]\n",
    "\n",
    "            # Plot population vectors.\n",
    "            # To have same color scale across R+ and R-.\n",
    "            if reward_group == 'R+':\n",
    "                vmax_vectors = np.percentile(pop_vectors, 98)\n",
    "                vmin_vectors = np.percentile(pop_vectors, 1)\n",
    "\n",
    "            if cell_type == 'allcells':\n",
    "                # Split in subplots for readability.\n",
    "                f, axes = plt.subplots(1, 4)\n",
    "                for i, (cell_start, cell_end) in enumerate([(0, 600), (600, 1200), (1200, 1800),(1800, 2400)]):\n",
    "                    im = axes[i].imshow(pop_vectors[cell_start:cell_end], cmap='viridis', vmin=vmin_vectors, vmax=vmax_vectors)\n",
    "                    n_trials = min_trials\n",
    "                    edges = np.cumsum(n_trials)\n",
    "                    for j in edges[:-1] - 0.5:\n",
    "                        axes[i].axvline(x=j, color='#252525', linestyle='-', lw=0.5)\n",
    "                    axes[i].set_xticks(edges - 0.5)\n",
    "                    axes[i].set_xticklabels(edges)\n",
    "                cb_ax = f.add_axes([.91,.124,.04,.754])\n",
    "                cbar = f.colorbar(im, ticks=[vmin_vectors, 0, vmax_vectors], cax=cb_ax)\n",
    "                cbar.ax.set_yticklabels([f'<{vmin_vectors:.2f}', '0', f'> {vmax_vectors:.2f}'])\n",
    "                cbar.ax.tick_params(size=0)\n",
    "                plt.suptitle(f'Population vectors {reward_group} {cell_type}')\n",
    "                pdf.savefig(dpi=300)\n",
    "                plt.close()\n",
    "                plt.tight_layout()\n",
    "            else:\n",
    "                f = plt.figure()\n",
    "                im = plt.imshow(pop_vectors, cmap='viridis', vmin=vmin_vectors, vmax=vmax_vectors)\n",
    "                n_trials = min_trials\n",
    "                edges = np.cumsum(n_trials)\n",
    "                for i in edges[:-1] - 0.5:\n",
    "                    plt.axvline(x=i, color='#252525', linestyle='-', lw=0.5)\n",
    "                plt.xticks(edges - 0.5, edges)\n",
    "                cbar = f.colorbar(im, ticks=[vmin_vectors, 0, vmax_vectors])\n",
    "                cbar.ax.set_yticklabels([f'<{vmin_vectors:.2f}', '0', f'> {vmax_vectors:.2f}'])\n",
    "                cbar.ax.tick_params(size=0)\n",
    "                plt.title(f'Population vectors {reward_group} {cell_type}')\n",
    "                pdf.savefig(dpi=300)\n",
    "                plt.close()\n",
    "\n",
    "\n",
    "            # Set color map limit to the max without the diagonal.\n",
    "            if reward_group == 'R+':\n",
    "                vmax_matrix = np.percentile(corr_matrix[~np.eye(corr_matrix.shape[0], dtype=bool)], 98)\n",
    "                vmin_matrix = np.percentile(corr_matrix, 2)\n",
    "\n",
    "            f = plt.figure(figsize=(15, 15))\n",
    "            im = plt.imshow(corr_matrix, vmin = vmin_matrix, vmax=vmax_matrix, cmap='viridis')\n",
    "            n_trials = min_trials\n",
    "            edges = np.cumsum(n_trials)\n",
    "            for i in edges[:-1] - 0.5:\n",
    "                plt.axvline(x=i, color='#252525', linestyle='-', lw=0.5)\n",
    "                plt.axhline(y=i, color='#252525', linestyle='-', lw=0.5)\n",
    "            plt.xticks(edges - 0.5, edges)\n",
    "            plt.yticks(edges - 0.5, edges)\n",
    "            plt.title(f'Correlation over trials {reward_group} {cell_type}')\n",
    "            cbar_ax = f.add_axes([0.85, 0.15, 0.05, 0.7])\n",
    "            cbar = f.colorbar(im, cax=cbar_ax, ticks=[vmin_matrix, 0, vmax_matrix])\n",
    "            cbar.ax.set_yticklabels([f'{vmin_matrix:.2f}', '0', f'> {vmax_matrix:.2f}'])\n",
    "            cbar.ax.tick_params(size=0)\n",
    "            pdf.savefig(dpi=300)\n",
    "            plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correlation matrices with average population vectors.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "cell_selection = 'lmi'\n",
    "responsiveness_thr = 0.01\n",
    "percent_best_lmi = 20\n",
    "zscore = True\n",
    "average_trials = 50  # Number of trials to average for each day.\n",
    "lmi_thr = np.percentile(np.abs(np.concatenate([lmi[mouse_id]['allcells'] for mouse_id in mice])), 100-percent_best_lmi)\n",
    "sns.set_theme(context='paper', style='ticks', palette='deep', font='sans-serif', font_scale=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 49, 50, 50]\n",
      "[50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 49, 49, 50, 50]\n",
      "[50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50]\n",
      "[50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 49, 50, 50]\n",
      "[50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 49, 50, 50]\n",
      "[np.int64(49), np.int64(49), np.int64(50), np.int64(49), np.int64(49)]\n",
      "GF305\n",
      "GF306\n",
      "GF308\n",
      "GF311\n",
      "GF313\n",
      "GF314\n",
      "GF317\n",
      "GF318\n",
      "GF323\n",
      "GF334\n",
      "AR133\n",
      "AR127\n",
      "AR143\n",
      "AR177\n",
      "[(40, 5), (58, 5), (24, 5), (23, 5), (53, 5), (46, 5), (37, 5), (45, 5), (54, 5), (49, 5), (34, 5), (50, 5), (39, 5), (8, 5)]\n",
      "[50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50]\n",
      "[50, 50, 50, 50, 50, 50, 50, 50, 49, 50, 50, 50, 50]\n",
      "[50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50]\n",
      "[50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50]\n",
      "[50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50]\n",
      "[np.int64(50), np.int64(49), np.int64(50), np.int64(50), np.int64(50)]\n",
      "GF319\n",
      "GF348\n",
      "GF350\n",
      "MI062\n",
      "MI069\n",
      "MI072\n",
      "MI076\n",
      "AR132\n",
      "AR137\n",
      "AR139\n",
      "AR178\n",
      "AR179\n",
      "AR180\n",
      "[(23, 5), (31, 5), (33, 5), (22, 5), (29, 5), (42, 5), (45, 5), (46, 5), (24, 5), (15, 5), (16, 5), (14, 5), (25, 5)]\n",
      "[50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50]\n",
      "[50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 49, 50, 50]\n",
      "[50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50]\n",
      "[50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50]\n",
      "[50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50]\n",
      "[np.int64(50), np.int64(49), np.int64(50), np.int64(50), np.int64(50)]\n",
      "GF305\n",
      "GF306\n",
      "GF308\n",
      "GF311\n",
      "GF313\n",
      "GF314\n",
      "GF317\n",
      "GF318\n",
      "GF323\n",
      "GF334\n",
      "AR133\n",
      "AR143\n",
      "AR177\n",
      "[(4, 5), (1, 5), (5, 5), (0, 250), (4, 5), (6, 5), (4, 5), (6, 5), (13, 5), (8, 5), (8, 5), (4, 5), (1, 5)]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "all the input array dimensions except for the concatenation axis must match exactly, but along dimension 1, the array at index 0 has size 5 and the array at index 3 has size 250",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 58\u001b[0m\n\u001b[0;32m     55\u001b[0m         response_amp_selection[cell_type][mouse_id][iday] \u001b[38;5;241m=\u001b[39m temp\n\u001b[0;32m     57\u001b[0m \u001b[38;5;28mprint\u001b[39m([np\u001b[38;5;241m.\u001b[39mconcatenate(data, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mshape \u001b[38;5;28;01mfor\u001b[39;00m _, data \u001b[38;5;129;01min\u001b[39;00m response_amp_selection[cell_type]\u001b[38;5;241m.\u001b[39mitems()])\n\u001b[1;32m---> 58\u001b[0m pop_vectors \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconcatenate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconcatenate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mresponse_amp_selection\u001b[49m\u001b[43m[\u001b[49m\u001b[43mcell_type\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitems\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     59\u001b[0m \u001b[38;5;66;03m# AR180 has some cells with 0. response whichi gives nan.\u001b[39;00m\n\u001b[0;32m     60\u001b[0m pop_vectors \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mnan_to_num(pop_vectors, nan\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.0\u001b[39m)\n",
      "\u001b[1;31mValueError\u001b[0m: all the input array dimensions except for the concatenation axis must match exactly, but along dimension 1, the array at index 0 has size 5 and the array at index 3 has size 250"
     ]
    }
   ],
   "source": [
    "output_dir = fr'//sv-nas1.rcp.epfl.ch/Petersen-Lab/analysis/Anthony_Renard/analysis_output/sensory_plasticity/correlation_matrices'\n",
    "pdf_file = f'correlation_matrices_average_pop_vector_global_population_win_{win_length}_ms_cell_selection_{cell_selection}_zscore_{zscore}.pdf'\n",
    "\n",
    "response_amp_selection = {}\n",
    "with PdfPages(os.path.join(output_dir, pdf_file)) as pdf:\n",
    "    for cell_type in ['allcells', 'wS2', 'wM1']:\n",
    "        for reward_group in ['R+', 'R-']:\n",
    "            mice_ids = [mouse_id for mouse_id in mice if (metadata[mouse_id]['reward_group'] == reward_group)\n",
    "                                                            and (cell_type in response_amp[mouse_id].keys())]\n",
    "            # mice_ids = [m for m in mice_ids if m not in ['MI072', 'MI069', 'AR132']]\n",
    "            # print(cell_type, reward_group, mice_ids)\n",
    "            # # Copying because I will take a subset of the data.\n",
    "            # response_amp_selection = np.copy(response_amp).item()\n",
    "            # response_amp_selection = {mouse_id: response_amp_selection[mouse_id] for mouse_id in mice_ids if cell_type in response_amp_selection[mouse_id].keys()}\n",
    "\n",
    "            response_amp_selection[cell_type] = {}\n",
    "            for mouse_id in mice_ids:\n",
    "\n",
    "                response_amp_selection[cell_type][mouse_id] = []\n",
    "\n",
    "                if cell_selection == 'no_selection':\n",
    "                    selected_cells = np.ones(response_amp[mouse_id][cell_type][0].shape[0], dtype=bool)\n",
    "                elif cell_selection == 'responsive':\n",
    "                    selected_cells = globally_responsive[mouse_id][cell_type] <= responsiveness_thr\n",
    "                elif cell_selection == 'lmi':\n",
    "                    \n",
    "                    selected_cells = np.abs(lmi[mouse_id][cell_type]) >= lmi_thr\n",
    "\n",
    "\n",
    "                for iday in range(len(days)):\n",
    "                    temp = [np.copy(response_amp[mouse_id][cell_type][iday][selected_cells]) for iday in range(len(days))]\n",
    "                    response_amp_selection[cell_type][mouse_id] = temp\n",
    "\n",
    "            # Even the number of trials per days across mice.\n",
    "            min_trials = []\n",
    "            for iday in range(len(days)):\n",
    "                m = [data[iday].shape[1] for _, data in response_amp_selection[cell_type].items()]\n",
    "                print(m)\n",
    "                min_trials.append(np.min(m))\n",
    "            print(min_trials)\n",
    "\n",
    "            for mouse_id, data in response_amp_selection[cell_type].items():\n",
    "                print(mouse_id)\n",
    "                # If no cells of the specified type, skip.\n",
    "                if data[0].shape[0] == 0:\n",
    "                    continue\n",
    "                for iday in range(len(days)):\n",
    "                    temp = data[iday][:, :min_trials[iday]]\n",
    "                    \n",
    "                    # Average trials.\n",
    "                    if temp.shape[1] % average_trials != 0:\n",
    "                        # Add nan to complete the last average if needed by missing trials.\n",
    "                        temp = np.concatenate([temp, np.full((temp.shape[0], average_trials - (temp.shape[1] % average_trials)), np.nan)], axis=1)\n",
    "                    temp = np.nanmean(temp.reshape(temp.shape[0], -1, average_trials), axis=2)\n",
    "                    response_amp_selection[cell_type][mouse_id][iday] = temp\n",
    "            \n",
    "            print([np.concatenate(data, axis=1).shape for _, data in response_amp_selection[cell_type].items()])\n",
    "            pop_vectors = np.concatenate([np.concatenate(data, axis=1) for _, data in response_amp_selection[cell_type].items()], axis=0)\n",
    "            # AR180 has some cells with 0. response whichi gives nan.\n",
    "            pop_vectors = np.nan_to_num(pop_vectors, nan=0.0)\n",
    "            if zscore:\n",
    "                pop_vectors = (pop_vectors - np.mean(pop_vectors, axis=1, keepdims=True)) / np.std(pop_vectors, axis=1, keepdims=True)\n",
    "                pop_vectors = np.nan_to_num(pop_vectors, nan=0.0)\n",
    "\n",
    "            corr_matrix = np.corrcoef(pop_vectors.T)\n",
    "            # corr_matrix = spearmanr(pop_vectors.T, axis=1)[0]\n",
    "\n",
    "            # Set color map limit to the max without the diagonal.\n",
    "            if reward_group == 'R+':\n",
    "                vmax_matrix = np.percentile(corr_matrix[~np.eye(corr_matrix.shape[0], dtype=bool)], 98)\n",
    "                vmin_matrix = np.percentile(corr_matrix, 1)\n",
    "\n",
    "            f = plt.figure(figsize=(15, 15))\n",
    "            im = plt.imshow(corr_matrix, vmin = 0, vmax=1, cmap='viridis')\n",
    "            n_trials = [50 / average_trials] * 5\n",
    "            edges = np.cumsum(n_trials)\n",
    "            for i in edges[:-1] - 0.5:\n",
    "                plt.axvline(x=i, color='#252525', linestyle='-', lw=0.5)\n",
    "                plt.axhline(y=i, color='#252525', linestyle='-', lw=0.5)\n",
    "            plt.xticks(edges - 0.5, edges)\n",
    "            plt.yticks(edges - 0.5, edges)\n",
    "            plt.title(f'Correlation over trials {reward_group} {cell_type}')\n",
    "            cbar_ax = f.add_axes([0.85, 0.15, 0.05, 0.7])\n",
    "            cbar = f.colorbar(im, cax=cbar_ax, ticks=[vmin_matrix, 0, vmax_matrix])\n",
    "            cbar.ax.set_yticklabels([f'{vmin_matrix:.2f}', '0', f'> {vmax_matrix:.2f}'])\n",
    "            cbar.ax.tick_params(size=0)\n",
    "\n",
    "            pdf.savefig(dpi=300)\n",
    "            plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(5, 5),\n",
       " (1, 5),\n",
       " (2, 5),\n",
       " (0, 250),\n",
       " (3, 5),\n",
       " (7, 5),\n",
       " (5, 5),\n",
       " (10, 5),\n",
       " (14, 5),\n",
       " (9, 5),\n",
       " (7, 5),\n",
       " (4, 5),\n",
       " (2, 5)]"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "response_amp_selection[cell_type][mouse_id][iday].shape\n",
    "cell_type\n",
    "[np.concatenate(data, axis=1).shape for _, data in response_amp_selection[cell_type].items()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 5)\n",
      "(2, 5)\n",
      "(2, 5)\n",
      "(2, 5)\n",
      "(2, 5)\n",
      "(0, 50)\n",
      "(0, 50)\n",
      "(0, 50)\n",
      "(0, 50)\n",
      "(0, 50)\n",
      "(2, 5)\n",
      "(2, 5)\n",
      "(2, 5)\n",
      "(2, 5)\n",
      "(2, 5)\n",
      "(0, 50)\n",
      "(0, 50)\n",
      "(0, 50)\n",
      "(0, 50)\n",
      "(0, 50)\n",
      "(1, 5)\n",
      "(1, 5)\n",
      "(1, 5)\n",
      "(1, 5)\n",
      "(1, 5)\n",
      "(5, 5)\n",
      "(5, 5)\n",
      "(5, 5)\n",
      "(5, 5)\n",
      "(5, 5)\n",
      "(3, 5)\n",
      "(3, 5)\n",
      "(3, 5)\n",
      "(3, 5)\n",
      "(3, 5)\n",
      "(6, 5)\n",
      "(6, 5)\n",
      "(6, 5)\n",
      "(6, 5)\n",
      "(6, 5)\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'GF319'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[161], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m mouse_id \u001b[38;5;129;01min\u001b[39;00m mice:\n\u001b[1;32m----> 2\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[43mresponse_amp_selection\u001b[49m\u001b[43m[\u001b[49m\u001b[43mcell_type\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43mmouse_id\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m      3\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m d \u001b[38;5;129;01min\u001b[39;00m data:\n\u001b[0;32m      4\u001b[0m         \u001b[38;5;28mprint\u001b[39m(d\u001b[38;5;241m.\u001b[39mshape)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'GF319'"
     ]
    }
   ],
   "source": [
    "for mouse_id in mice:\n",
    "    data = response_amp_selection[cell_type][mouse_id]\n",
    "    for d in data:\n",
    "        print(d.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3. Quantify the correlation between days.\n",
    "\n",
    "- average correlation inside each day -- response variability\n",
    "- average correlation between pre and post learning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell selection.\n",
    "\n",
    "cell_selection = 'responsive'\n",
    "responsiveness_thr = 0.001\n",
    "percent_best_lmi = 15\n",
    "sns.set_theme(context='paper', style='ticks', palette='deep', font='sans-serif', font_scale=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GF305 allcells 55/ 133 responsive cells\n",
      "[ 50 100 150 200 250]\n",
      "GF305 wS2 7/ 12 responsive cells\n",
      "[ 50 100 150 200 250]\n",
      "GF305 wM1 9/ 20 responsive cells\n",
      "[ 50 100 150 200 250]\n",
      "GF306 allcells 95/ 215 responsive cells\n",
      "[ 50 100 150 200 250]\n",
      "GF306 wS2 1/ 3 responsive cells\n",
      "[ 50 100 150 200 250]\n",
      "GF306 wM1 6/ 15 responsive cells\n",
      "[ 50 100 150 200 250]\n",
      "GF308 allcells 42/ 147 responsive cells\n",
      "[ 50 100 150 200 250]\n",
      "GF308 wS2 8/ 23 responsive cells\n",
      "[ 50 100 150 200 250]\n",
      "GF308 wM1 2/ 16 responsive cells\n",
      "[ 50 100 150 200 250]\n",
      "GF311 allcells 42/ 105 responsive cells\n",
      "[ 50 100 150 200 250]\n",
      "GF311 wS2 0/ 4 responsive cells\n",
      "[ 50 100 150 200 250]\n",
      "GF311 wM1 9/ 17 responsive cells\n",
      "[ 50 100 150 200 250]\n",
      "GF313 allcells 71/ 164 responsive cells\n",
      "[ 50 100 150 200 250]\n",
      "GF313 wS2 7/ 15 responsive cells\n",
      "[ 50 100 150 200 250]\n",
      "GF313 wM1 7/ 14 responsive cells\n",
      "[ 50 100 150 200 250]\n",
      "GF314 allcells 116/ 197 responsive cells\n",
      "[ 50 100 150 200 250]\n",
      "GF314 wS2 13/ 18 responsive cells\n",
      "[ 50 100 150 200 250]\n",
      "GF314 wM1 4/ 10 responsive cells\n",
      "[ 50 100 150 200 250]\n",
      "GF317 allcells 72/ 146 responsive cells\n",
      "[ 50 100 150 200 250]\n",
      "GF317 wS2 14/ 19 responsive cells\n",
      "[ 50 100 150 200 250]\n",
      "GF317 wM1 7/ 16 responsive cells\n",
      "[ 50 100 150 200 250]\n",
      "GF318 allcells 69/ 140 responsive cells\n",
      "[ 50 100 150 200 250]\n",
      "GF318 wS2 7/ 18 responsive cells\n",
      "[ 50 100 150 200 250]\n",
      "GF318 wM1 11/ 20 responsive cells\n",
      "[ 50 100 150 200 250]\n",
      "GF319 allcells 50/ 154 responsive cells\n",
      "[ 50 100 150 200 250]\n",
      "GF323 allcells 71/ 305 responsive cells\n",
      "[ 50 100 150 200 250]\n",
      "GF323 wS2 5/ 47 responsive cells\n",
      "[ 50 100 150 200 250]\n",
      "GF323 wM1 7/ 30 responsive cells\n",
      "[ 50 100 150 200 250]\n",
      "GF334 allcells 66/ 130 responsive cells\n",
      "[ 50 100 150 200 250]\n",
      "GF334 wS2 10/ 15 responsive cells\n",
      "[ 50 100 150 200 250]\n",
      "GF334 wM1 4/ 9 responsive cells\n",
      "[ 50 100 150 200 250]\n",
      "GF348 allcells 64/ 206 responsive cells\n",
      "[ 50 100 150 200 250]\n",
      "MI062 allcells 36/ 108 responsive cells\n",
      "[ 50 100 150 200 250]\n",
      "MI069 allcells 62/ 218 responsive cells\n",
      "[ 50 100 150 200 250]\n",
      "MI069 wS2 3/ 20 responsive cells\n",
      "[ 50 100 150 200 250]\n",
      "MI069 wM1 1/ 2 responsive cells\n",
      "[ 50 100 150 200 250]\n",
      "MI072 allcells 74/ 244 responsive cells\n",
      "[ 50 100 150 200 250]\n",
      "MI072 wS2 2/ 7 responsive cells\n",
      "[ 50 100 150 200 250]\n",
      "MI072 wM1 6/ 25 responsive cells\n",
      "[ 50 100 150 200 250]\n",
      "MI075 allcells 40/ 189 responsive cells\n",
      "[ 50  92 135 185 229]\n",
      "MI075 wS2 3/ 13 responsive cells\n",
      "[ 50  92 135 185 229]\n",
      "MI075 wM1 2/ 17 responsive cells\n",
      "[ 50  92 135 185 229]\n",
      "MI076 allcells 81/ 268 responsive cells\n",
      "[ 50 100 150 200 250]\n",
      "MI076 wS2 5/ 14 responsive cells\n",
      "[ 50 100 150 200 250]\n",
      "MI076 wM1 8/ 28 responsive cells\n",
      "[ 50 100 150 200 250]\n",
      "AR132 allcells 60/ 182 responsive cells\n",
      "[ 50 100 150 201 251]\n",
      "AR132 wS2 5/ 26 responsive cells\n",
      "[ 50 100 150 201 251]\n",
      "AR132 wM1 4/ 9 responsive cells\n",
      "[ 50 100 150 201 251]\n",
      "AR133 allcells 72/ 144 responsive cells\n",
      "[ 50  99 149 199 248]\n",
      "AR133 wS2 16/ 29 responsive cells\n",
      "[ 50  99 149 199 248]\n",
      "AR137 allcells 52/ 180 responsive cells\n",
      "[ 50  99 149 199 249]\n",
      "AR137 wS2 16/ 45 responsive cells\n",
      "[ 50  99 149 199 249]\n",
      "AR137 wM1 2/ 12 responsive cells\n",
      "[ 50  99 149 199 249]\n",
      "AR139 allcells 33/ 138 responsive cells\n",
      "[ 50 100 150 200 247]\n",
      "AR139 wS2 11/ 38 responsive cells\n",
      "[ 50 100 150 200 247]\n",
      "AR127 allcells 72/ 180 responsive cells\n",
      "[ 49  98 148 197 246]\n",
      "AR127 wM1 11/ 29 responsive cells\n",
      "[ 49  98 148 197 246]\n",
      "AR131 allcells 62/ 169 responsive cells\n",
      "[ 50 100 150 199 249]\n",
      "AR131 wS2 0/ 1 responsive cells\n",
      "[ 50 100 150 199 249]\n",
      "AR131 wM1 8/ 17 responsive cells\n",
      "[ 50 100 150 199 249]\n",
      "AR143 allcells 55/ 205 responsive cells\n",
      "[ 50 100 150 200 250]\n",
      "AR143 wS2 6/ 27 responsive cells\n",
      "[ 50 100 150 200 250]\n",
      "AR143 wM1 4/ 16 responsive cells\n",
      "[ 50 100 150 200 250]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\envs\\fast-learning\\Lib\\site-packages\\numpy\\lib\\_function_base_impl.py:2991: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  c = cov(x, y, rowvar, dtype=dtype)\n",
      "c:\\ProgramData\\anaconda3\\envs\\fast-learning\\Lib\\site-packages\\numpy\\lib\\_function_base_impl.py:2848: RuntimeWarning: divide by zero encountered in divide\n",
      "  c *= np.true_divide(1, fact)\n",
      "c:\\ProgramData\\anaconda3\\envs\\fast-learning\\Lib\\site-packages\\numpy\\lib\\_function_base_impl.py:2848: RuntimeWarning: invalid value encountered in multiply\n",
      "  c *= np.true_divide(1, fact)\n",
      "c:\\ProgramData\\anaconda3\\envs\\fast-learning\\Lib\\site-packages\\numpy\\lib\\_function_base_impl.py:562: RuntimeWarning: Mean of empty slice.\n",
      "  avg = a.mean(axis, **keepdims_kw)\n",
      "c:\\ProgramData\\anaconda3\\envs\\fast-learning\\Lib\\site-packages\\numpy\\_core\\_methods.py:139: RuntimeWarning: invalid value encountered in divide\n",
      "  ret = um.true_divide(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Day -2: p-value = 0.643011484398551\n",
      "Day -1: p-value = 0.5239281449175213\n",
      "Day 0: p-value = 0.03700438758047722\n",
      "Day +1: p-value = 0.023850728855048315\n",
      "Day +2: p-value = 0.017530018461674984\n",
      "  day   p_value\n",
      "0  -2  0.643011\n",
      "1  -1  0.523928\n",
      "2   0  0.037004\n",
      "3  +1  0.023851\n",
      "4  +2  0.017530\n",
      "Comp pre_in: p-value = 1.0\n",
      "Comp post_in: p-value = 0.014960455146298667\n",
      "Comp pre_post: p-value = 1.0\n",
      "       comp  p_value\n",
      "0    pre_in  1.00000\n",
      "1   post_in  0.01496\n",
      "2  pre_post  1.00000\n",
      "Day -2: p-value = nan\n",
      "Day -1: p-value = nan\n",
      "Day 0: p-value = nan\n",
      "Day +1: p-value = nan\n",
      "Day +2: p-value = nan\n",
      "  day  p_value\n",
      "0  -2      NaN\n",
      "1  -1      NaN\n",
      "2   0      NaN\n",
      "3  +1      NaN\n",
      "4  +2      NaN\n",
      "Comp pre_in: p-value = nan\n",
      "Comp post_in: p-value = nan\n",
      "Comp pre_post: p-value = nan\n",
      "       comp  p_value\n",
      "0    pre_in      NaN\n",
      "1   post_in      NaN\n",
      "2  pre_post      NaN\n",
      "Day -2: p-value = nan\n",
      "Day -1: p-value = nan\n",
      "Day 0: p-value = nan\n",
      "Day +1: p-value = nan\n",
      "Day +2: p-value = nan\n",
      "  day  p_value\n",
      "0  -2      NaN\n",
      "1  -1      NaN\n",
      "2   0      NaN\n",
      "3  +1      NaN\n",
      "4  +2      NaN\n",
      "Comp pre_in: p-value = nan\n",
      "Comp post_in: p-value = nan\n",
      "Comp pre_post: p-value = nan\n",
      "       comp  p_value\n",
      "0    pre_in      NaN\n",
      "1   post_in      NaN\n",
      "2  pre_post      NaN\n"
     ]
    }
   ],
   "source": [
    "output_dir = fr'//sv-nas1.rcp.epfl.ch/Petersen-Lab/analysis/Anthony_Renard/analysis_output/sensory_plasticity/correlation_matrices'\n",
    "pdf_file = f'correlation_matrix_quantification_{win_length}_ms_cell_selection_{cell_selection}.pdf'\n",
    "\n",
    "corr_avg_days = {}\n",
    "corr_avg_pre_post = {}\n",
    "\n",
    "# Because cell selection changes the data.\n",
    "response_amp_copy = np.copy(response_amp).item()\n",
    "\n",
    "for mouse_id in mouse_ids:\n",
    "    corr_avg_days[mouse_id] = {}\n",
    "    corr_avg_pre_post[mouse_id] = {}\n",
    "\n",
    "    for cell_type in ['allcells', 'wS2', 'wM1']:\n",
    "\n",
    "        if cell_type not in response_amp[mouse_id].keys():\n",
    "            continue\n",
    "        \n",
    "        if cell_selection == 'no_selection':\n",
    "            pop_vectors = np.concatenate(response_amp_copy[mouse_id][cell_type], axis=1)\n",
    "        elif cell_selection == 'responsive':\n",
    "            responsive_cells = globally_responsive[mouse_id][cell_type] <= responsiveness_thr\n",
    "            pop_vectors = np.concatenate([response_amp_copy[mouse_id][cell_type][iday][responsive_cells, :] for iday in range(len(days))], axis=1)\n",
    "            print(f'{mouse_id} {cell_type} {np.sum(responsive_cells)}/ {responsive_cells.shape[0]} responsive cells')\n",
    "        elif cell_selection == 'lmi':\n",
    "            lmi_thr = np.percentile(np.abs(np.concatenate([lmi[mouse_id]['allcells'] for mouse_id in mice])), 100-percent_best_lmi)\n",
    "            modulated_cells = lmi[mouse_id][cell_type] >= lmi_thr\n",
    "            pop_vectors = np.concatenate([response_amp_copy[mouse_id][cell_type][iday][modulated_cells, :] for iday in range(len(days))], axis=1)\n",
    "\n",
    "        # if cell_selection == 'responsive_cells':\n",
    "        #     corr_matrix = np.corrcoef(pop_vectors[mouse_id][cell_type][globally_responsive[mouse_id][cell_type], :].T)\n",
    "        # elif cell_selection == 'lmi':\n",
    "        #     corr_matrix = np.corrcoef(pop_vectors[mouse_id][cell_type][lmi[mouse_id][cell_type], :].T)\n",
    "        # else:\n",
    "        #     corr_matrix = np.corrcoef(pop_vectors[mouse_id][cell_type].T)\n",
    "\n",
    "        corr_matrix = np.corrcoef(pop_vectors.T)\n",
    "\n",
    "        # Compute average correlation inside each days.\n",
    "        corr_avg_days[mouse_id][cell_type] = []\n",
    "        n_trials = [arr.shape[1] for arr in response_amp[mouse_id][cell_type]]\n",
    "        print(np.cumsum(n_trials))\n",
    "        for start, end in zip(np.cumsum([0] + n_trials[:-1]), np.cumsum(n_trials)):\n",
    "            upper_triangle = np.triu(corr_matrix[start:end, start:end], k=1)\n",
    "            corr_avg_days[mouse_id][cell_type].append(np.mean(upper_triangle))\n",
    "\n",
    "        # Compare correlation between inside pre training days,\n",
    "        # inside post training days and between pre and post training days.\n",
    "        trial_cumsum = np.cumsum([0] + n_trials)\n",
    "        pre_in_start_x, pre_in_end_x = trial_cumsum[1], trial_cumsum[2]\n",
    "        pre_in_start_y, pre_in_end_y = trial_cumsum[0], trial_cumsum[1]\n",
    "        pre_in = np.mean(corr_matrix[pre_in_start_x:pre_in_end_x, pre_in_start_y:pre_in_end_y])\n",
    "\n",
    "        post_in_start_x, post_in_end_x = trial_cumsum[4], trial_cumsum[5]\n",
    "        post_in_start_y, post_in_end_y = trial_cumsum[3], trial_cumsum[4]\n",
    "        post_in = np.mean(corr_matrix[post_in_start_x:post_in_end_x, post_in_start_y:post_in_end_y])\n",
    "\n",
    "        pre_post_start_x, pre_post_end_x = trial_cumsum[3], trial_cumsum[5]\n",
    "        pre_post_start_y, pre_post_end_y = trial_cumsum[0], trial_cumsum[2]\n",
    "        pre_post = np.mean(corr_matrix[pre_post_start_x:pre_post_end_x, pre_post_start_y:pre_post_end_y])\n",
    "\n",
    "        corr_avg_pre_post[mouse_id][cell_type] = [pre_in, post_in, pre_post]\n",
    "\n",
    "# Convert to pandas.\n",
    "# ------------------\n",
    "\n",
    "df_corr_days = []\n",
    "for mouse_id in mouse_ids:\n",
    "    for cell_type in corr_avg_days[mouse_id].keys():\n",
    "        for iday in range(len(days)):\n",
    "            corr = corr_avg_days[mouse_id][cell_type][iday]\n",
    "            temp = pd.DataFrame([[corr, days[iday], cell_type, mouse_id, metadata[mouse_id]['reward_group']]],\n",
    "                                columns=['correlation','day', 'cell_type', 'mouse_id', 'reward_group'])\n",
    "            df_corr_days.append(temp)\n",
    "df_corr_days = pd.concat(df_corr_days, ignore_index=True)\n",
    "\n",
    "\n",
    "compare = ['pre_in', 'post_in', 'pre_post']\n",
    "df_corr_pre_post = []\n",
    "for mouse_id in mouse_ids:\n",
    "    for cell_type in corr_avg_days[mouse_id].keys():\n",
    "        for i, comp in enumerate(compare):\n",
    "            corr = corr_avg_pre_post[mouse_id][cell_type][i]\n",
    "            temp = pd.DataFrame([[corr, comp, cell_type, mouse_id, metadata[mouse_id]['reward_group']]],\n",
    "                                columns=['correlation', 'comparison', 'cell_type', 'mouse_id', 'reward_group'])\n",
    "            df_corr_pre_post.append(temp)\n",
    "df_corr_pre_post = pd.concat(df_corr_pre_post, ignore_index=True)\n",
    "\n",
    "\n",
    "# Save plot and stats.\n",
    "# --------------------\n",
    "\n",
    "with PdfPages(os.path.join(output_dir, pdf_file)) as pdf:\n",
    "\n",
    "    palette = sns.color_palette(['#238443', '#d51a1c'])\n",
    "    for ct in ['allcells', 'wS2', 'wM1']:\n",
    "\n",
    "        plt.figure()\n",
    "        sns.barplot(data=df_corr_days.loc[df_corr_days.cell_type==ct], x='day', y='correlation', hue='reward_group', palette=palette, hue_order=['R+', 'R-'])\n",
    "        sns.despine()\n",
    "        plt.title(f'Correlation inside days - {ct}')\n",
    "        pdf.savefig(dpi=300)\n",
    "        plt.close()\n",
    "\n",
    "        # Perform Mann-Whitney U test to check if the difference between the two reward groups is significant for each day.\n",
    "        p_values = []\n",
    "        for day in days:\n",
    "            group_rew = df_corr_days[(df_corr_days['day'] == day) & (df_corr_days['reward_group'] == 'R+') & (df_corr_days.cell_type==ct)]['correlation']\n",
    "            group_rew = group_rew[~np.isnan(group_rew)]\n",
    "            group_unrew = df_corr_days[(df_corr_days['day'] == day) & (df_corr_days['reward_group'] == 'R-') & (df_corr_days.cell_type==ct)]['correlation']\n",
    "            group_rew = group_rew[~np.isnan(group_rew)]\n",
    "            stat, p = mannwhitneyu(group_rew, group_unrew)\n",
    "            p_values.append(p)\n",
    "            print(f'Day {day}: p-value = {p}')\n",
    "        # Add p-values to the dataframe for visualization\n",
    "        df_p_values = pd.DataFrame({'day': days, 'p_value': p_values})\n",
    "        print(df_p_values)\n",
    "        df_p_values.to_csv(os.path.join(output_dir, f'correlation_matrix_quantification_{win_length}_ms_{cell_selection}_inside_days.csv'), index=False)\n",
    "\n",
    "        plt.figure()\n",
    "        sns.barplot(data=df_corr_pre_post.loc[df_corr_pre_post.cell_type==ct], x='comparison', y='correlation', hue='reward_group', palette=palette, hue_order=['R+', 'R-'])\n",
    "        sns.despine()\n",
    "        plt.title(f'Correlation inside pre-training, post-training and across both - {ct}')\n",
    "        pdf.savefig(dpi=300)\n",
    "        plt.close()\n",
    "\n",
    "        # Perform Mann-Whitney U test to check if the difference between the two reward groups is significant for each day.\n",
    "        p_values = []\n",
    "        for comp in compare:\n",
    "            group_rew = df_corr_pre_post[(df_corr_pre_post['comparison'] == comp) & (df_corr_pre_post['reward_group'] == 'R+') & (df_corr_pre_post.cell_type==ct)]['correlation']\n",
    "            group_rew = group_rew[~np.isnan(group_rew)]\n",
    "            group_unrew = df_corr_pre_post[(df_corr_pre_post['comparison'] == comp) & (df_corr_pre_post['reward_group'] == 'R-') & (df_corr_pre_post.cell_type==ct)]['correlation']\n",
    "            group_rew = group_rew[~np.isnan(group_rew)]\n",
    "            stat, p = mannwhitneyu(group_rew, group_unrew)\n",
    "            p_values.append(p)\n",
    "            print(f'Comp {comp}: p-value = {p}')\n",
    "        # Add p-values to the dataframe for visualization\n",
    "        df_p_values = pd.DataFrame({'comp': compare, 'p_value': p_values})\n",
    "        print(df_p_values)\n",
    "        df_p_values.to_csv(os.path.join(output_dir, f'correlation_matrix_quantification_{win_length}_ms_{cell_selection}_across_pre_post.csv'), index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quantify correlations across pre post learning on the global population matrix.\n",
    "\n",
    "Variance is computated across pairs of trials rather than mice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "cell_selection = 'no_selection'\n",
    "responsiveness_thr = 0.001\n",
    "percent_best_lmi = 15\n",
    "sns.set_theme(context='paper', style='ticks', palette='deep', font='sans-serif', font_scale=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[np.int64(49), np.int64(49), np.int64(50), np.int64(49), np.int64(49)]\n",
      "0 49\n",
      "49 98\n",
      "98 148\n",
      "148 197\n",
      "197 246\n",
      "(np.int64(49), np.int64(98)) (np.int64(0), np.int64(49))\n",
      "(np.int64(197), np.int64(246)) (np.int64(148), np.int64(197))\n",
      "(np.int64(148), np.int64(246)) (np.int64(0), np.int64(98))\n",
      "[np.int64(50), np.int64(42), np.int64(43), np.int64(49), np.int64(44)]\n",
      "0 50\n",
      "50 92\n",
      "92 135\n",
      "135 184\n",
      "184 228\n",
      "(np.int64(50), np.int64(92)) (np.int64(0), np.int64(50))\n",
      "(np.int64(184), np.int64(228)) (np.int64(135), np.int64(184))\n",
      "(np.int64(135), np.int64(228)) (np.int64(0), np.int64(92))\n",
      "[np.int64(50), np.int64(49), np.int64(50), np.int64(50), np.int64(49)]\n",
      "0 50\n",
      "50 99\n",
      "99 149\n",
      "149 199\n",
      "199 248\n",
      "(np.int64(50), np.int64(99)) (np.int64(0), np.int64(50))\n",
      "(np.int64(199), np.int64(248)) (np.int64(149), np.int64(199))\n",
      "(np.int64(149), np.int64(248)) (np.int64(0), np.int64(99))\n",
      "[np.int64(50), np.int64(42), np.int64(43), np.int64(49), np.int64(44)]\n",
      "0 50\n",
      "50 92\n",
      "92 135\n",
      "135 184\n",
      "184 228\n",
      "(np.int64(50), np.int64(92)) (np.int64(0), np.int64(50))\n",
      "(np.int64(184), np.int64(228)) (np.int64(135), np.int64(184))\n",
      "(np.int64(135), np.int64(228)) (np.int64(0), np.int64(92))\n",
      "[np.int64(49), np.int64(49), np.int64(50), np.int64(49), np.int64(49)]\n",
      "0 49\n",
      "49 98\n",
      "98 148\n",
      "148 197\n",
      "197 246\n",
      "(np.int64(49), np.int64(98)) (np.int64(0), np.int64(49))\n",
      "(np.int64(197), np.int64(246)) (np.int64(148), np.int64(197))\n",
      "(np.int64(148), np.int64(246)) (np.int64(0), np.int64(98))\n",
      "[np.int64(50), np.int64(42), np.int64(43), np.int64(49), np.int64(44)]\n",
      "0 50\n",
      "50 92\n",
      "92 135\n",
      "135 184\n",
      "184 228\n",
      "(np.int64(50), np.int64(92)) (np.int64(0), np.int64(50))\n",
      "(np.int64(184), np.int64(228)) (np.int64(135), np.int64(184))\n",
      "(np.int64(135), np.int64(228)) (np.int64(0), np.int64(92))\n"
     ]
    }
   ],
   "source": [
    "output_dir = fr'//sv-nas1.rcp.epfl.ch/Petersen-Lab/analysis/Anthony_Renard/analysis_output/sensory_plasticity/correlation_matrices'\n",
    "pdf_file = f'correlation_matrix_quantification_global_matrix_{win_length}_ms_cell_selection_{cell_selection}.pdf'\n",
    "\n",
    "response_amp_selection = {}\n",
    "df_corr_days = []\n",
    "df_corr_pre_post = []\n",
    "\n",
    "for cell_type in ['allcells', 'wS2', 'wM1']:\n",
    "    for reward_group in ['R+', 'R-']:\n",
    "        mice_ids = [mouse_id for mouse_id in mice if (metadata[mouse_id]['reward_group'] == reward_group)\n",
    "                                                        and (cell_type in response_amp[mouse_id].keys())]\n",
    "\n",
    "        # # Copying because I will take a subset of the data.\n",
    "        # response_amp_selection = np.copy(response_amp).item()\n",
    "        # response_amp_selection = {mouse_id: response_amp_selection[mouse_id] for mouse_id in mice_ids if cell_type in response_amp_selection[mouse_id].keys()}\n",
    "\n",
    "        response_amp_selection[cell_type] = {}\n",
    "\n",
    "\n",
    "        for mouse_id in mice_ids:\n",
    "\n",
    "            response_amp_selection[cell_type][mouse_id] = []\n",
    "\n",
    "            if cell_selection == 'no_selection':\n",
    "                selected_cells = np.ones(response_amp[mouse_id][cell_type][0].shape[0], dtype=bool)\n",
    "            elif cell_selection == 'responsive':\n",
    "                selected_cells = globally_responsive[mouse_id][cell_type] <= responsiveness_thr\n",
    "            elif cell_selection == 'lmi':\n",
    "                lmi_thr = np.percentile(np.abs(np.concatenate([lmi[mouse_id]['allcells'] for mouse_id in mice])), 100-percent_best_lmi)\n",
    "                selected_cells = lmi[mouse_id][cell_type] >= lmi_thr\n",
    "\n",
    "            for iday in range(len(days)):\n",
    "                temp = [np.copy(response_amp[mouse_id][cell_type][iday][selected_cells]) for iday in range(len(days))]\n",
    "                response_amp_selection[cell_type][mouse_id] = temp\n",
    "\n",
    "        # Even the number of trials per days across mice.\n",
    "        min_trials = []\n",
    "        for iday in range(len(days)):\n",
    "            m = [data[iday].shape[1] for _, data in response_amp_selection[cell_type].items()]\n",
    "            min_trials.append(np.min(m))\n",
    "        print(min_trials)\n",
    "\n",
    "        for mouse_id, data in response_amp_selection[cell_type].items():\n",
    "            for iday in range(len(days)):\n",
    "                response_amp_selection[cell_type][mouse_id][iday] = data[iday][:, :min_trials[iday]]\n",
    "        \n",
    "        pop_vectors = np.concatenate([np.concatenate(data, axis=1) for _, data in response_amp_selection[cell_type].items()], axis=0)\n",
    "        corr_matrix = np.corrcoef(pop_vectors.T)\n",
    "        # corr_matrix = spearmanr(pop_vectors.T, axis=1)[0]\n",
    "\n",
    "        plt.figure()\n",
    "        plt.imshow(corr_matrix)\n",
    "        plt.title(f'{cell_type} {reward_group}')\n",
    "\n",
    "        corr_avg_days = []\n",
    "        corr_avg_pre_post = []\n",
    "\n",
    "        # Compute average correlation inside each days.\n",
    "        n_trials = min_trials\n",
    "        for start, end in zip(np.cumsum([0] + n_trials[:-1]), np.cumsum(n_trials)):\n",
    "            print(start, end)\n",
    "            upper_triangle = np.triu(corr_matrix[start:end, start:end], k=1)\n",
    "            corr_avg_days.append(upper_triangle.flatten())\n",
    "\n",
    "        # Compare correlation between inside pre training days,\n",
    "        # inside post training days and between pre and post training days.\n",
    "        trial_cumsum = np.cumsum([0] + n_trials)\n",
    "        pre_in_start_x, pre_in_end_x = trial_cumsum[1], trial_cumsum[2]\n",
    "        pre_in_start_y, pre_in_end_y = trial_cumsum[0], trial_cumsum[1]\n",
    "        pre_in = corr_matrix[pre_in_start_x:pre_in_end_x, pre_in_start_y:pre_in_end_y]\n",
    "        print((pre_in_start_x,pre_in_end_x), (pre_in_start_y, pre_in_end_y))\n",
    "\n",
    "        post_in_start_x, post_in_end_x = trial_cumsum[4], trial_cumsum[5]\n",
    "        post_in_start_y, post_in_end_y = trial_cumsum[3], trial_cumsum[4]\n",
    "        post_in = corr_matrix[post_in_start_x:post_in_end_x, post_in_start_y:post_in_end_y]\n",
    "        print((post_in_start_x,post_in_end_x), (post_in_start_y, post_in_end_y))\n",
    "\n",
    "        pre_post_start_x, pre_post_end_x = trial_cumsum[3], trial_cumsum[5]\n",
    "        pre_post_start_y, pre_post_end_y = trial_cumsum[0], trial_cumsum[2]\n",
    "        pre_post = corr_matrix[pre_post_start_x:pre_post_end_x, pre_post_start_y:pre_post_end_y]\n",
    "        print((pre_post_start_x,pre_post_end_x), (pre_post_start_y, pre_post_end_y))\n",
    "\n",
    "        corr_avg_pre_post = [pre_in.flatten(), post_in.flatten(), pre_post.flatten()]\n",
    "\n",
    "        # Convert to pandas.\n",
    "        # ------------------\n",
    "\n",
    "        for iday in range(len(days)):\n",
    "            for i, corr in enumerate(corr_avg_days[iday]):\n",
    "                temp = pd.DataFrame([[corr, days[iday], i, cell_type, reward_group]],\n",
    "                                    columns=['correlation', 'day', 'trial_pair', 'cell_type', 'reward_group'])\n",
    "                df_corr_days.append(temp)\n",
    "\n",
    "        compare = ['pre_in', 'post_in', 'pre_post']\n",
    "        for icomp, comp in enumerate(compare):\n",
    "            for ipair, corr in enumerate(corr_avg_pre_post[icomp]):\n",
    "                temp = pd.DataFrame([[corr, comp, ipair, cell_type, reward_group]],\n",
    "                                    columns=['correlation', 'comparison', 'trial_pair', 'cell_type', 'reward_group'])\n",
    "                df_corr_pre_post.append(temp)\n",
    "\n",
    "df_corr_days = pd.concat(df_corr_days, ignore_index=True)\n",
    "df_corr_pre_post = pd.concat(df_corr_pre_post, ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save plot and stats.\n",
    "# --------------------\n",
    "with PdfPages(os.path.join(output_dir, pdf_file)) as pdf:\n",
    "\n",
    "    palette = sns.color_palette(['#238443', '#d51a1c'])\n",
    "    for ct in ['allcells', 'wS2', 'wM1']:\n",
    "\n",
    "        plt.figure()\n",
    "        sns.barplot(data=df_corr_days.loc[df_corr_days.cell_type==ct], x='day', y='correlation', hue='reward_group', palette=palette, hue_order=['R+', 'R-'])\n",
    "        sns.despine()\n",
    "        plt.title(f'Correlation inside days - {ct}')\n",
    "        pdf.savefig(dpi=300)\n",
    "        plt.close()\n",
    "\n",
    "        # # Perform Mann-Whitney U test to check if the difference between the two reward groups is significant for each day.\n",
    "        # p_values = []\n",
    "        # for day in days:\n",
    "        #     group_rew = df_corr_days[(df_corr_days['day'] == day) & (df_corr_days['reward_group'] == 'R+') & (df_corr_days.cell_type==ct)]['correlation']\n",
    "        #     group_rew = group_rew[~np.isnan(group_rew)]\n",
    "        #     group_unrew = df_corr_days[(df_corr_days['day'] == day) & (df_corr_days['reward_group'] == 'R-') & (df_corr_days.cell_type==ct)]['correlation']\n",
    "        #     group_rew = group_rew[~np.isnan(group_rew)]\n",
    "        #     stat, p = mannwhitneyu(group_rew, group_unrew)\n",
    "        #     p_values.append(p)\n",
    "        #     print(f'Day {day}: p-value = {p}')\n",
    "        # # Add p-values to the dataframe for visualization\n",
    "        # df_p_values = pd.DataFrame({'day': days, 'p_value': p_values})\n",
    "        # print(df_p_values)\n",
    "        # df_p_values.to_csv(os.path.join(output_dir, f'correlation_matrix_quantification_{win_length}_ms_{cell_selection}_inside_days.csv'), index=False)\n",
    "\n",
    "\n",
    "        plt.figure()\n",
    "        sns.barplot(data=df_corr_pre_post.loc[df_corr_pre_post.cell_type==ct], x='comparison', y='correlation', hue='reward_group', palette=palette, hue_order=['R+', 'R-'])\n",
    "        sns.despine()\n",
    "        plt.title(f'Correlation inside pre-training, post-training and across both - {ct}')\n",
    "        pdf.savefig(dpi=300)\n",
    "        plt.close()\n",
    "\n",
    "        # # Perform Mann-Whitney U test to check if the difference between the two reward groups is significant for each day.\n",
    "        # p_values = []\n",
    "        # for comp in compare:\n",
    "        #     group_rew = df_corr_pre_post[(df_corr_pre_post['comparison'] == comp) & (df_corr_pre_post['reward_group'] == 'R+') & (df_corr_pre_post.cell_type==ct)]['correlation']\n",
    "        #     group_rew = group_rew[~np.isnan(group_rew)]\n",
    "        #     group_unrew = df_corr_pre_post[(df_corr_pre_post['comparison'] == comp) & (df_corr_pre_post['reward_group'] == 'R-') & (df_corr_pre_post.cell_type==ct)]['correlation']\n",
    "        #     group_rew = group_rew[~np.isnan(group_rew)]\n",
    "        #     stat, p = mannwhitneyu(group_rew, group_unrew)\n",
    "        #     p_values.append(p)\n",
    "        #     print(f'Comp {comp}: p-value = {p}')\n",
    "        # # Add p-values to the dataframe for visualization\n",
    "        # df_p_values = pd.DataFrame({'comp': compare, 'p_value': p_values})\n",
    "        # print(df_p_values)\n",
    "        # df_p_values.to_csv(os.path.join(output_dir, f'correlation_matrix_quantification_{win_length}_ms_{cell_selection}_across_pre_post.csv'), index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the population vectors and lmi.\n",
    "\n",
    "This is to show that lmi select cells that go on and off as expected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "(slice(None, None, None), None)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[186], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m f, axes \u001b[38;5;241m=\u001b[39m plt\u001b[38;5;241m.\u001b[39msubplots(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m, sharey\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m----> 2\u001b[0m im \u001b[38;5;241m=\u001b[39m axes[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mimshow(np\u001b[38;5;241m.\u001b[39mrepeat(\u001b[43mlmi\u001b[49m\u001b[43m[\u001b[49m\u001b[43mmouse_id\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnewaxis\u001b[49m\u001b[43m]\u001b[49m, \u001b[38;5;241m10\u001b[39m, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m), cmap\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mviridis\u001b[39m\u001b[38;5;124m'\u001b[39m, vmin\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, vmax\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m      3\u001b[0m plt\u001b[38;5;241m.\u001b[39mcolorbar(im)\n\u001b[0;32m      4\u001b[0m vmax \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mpercentile(pop_vectors_dict[mouse_id][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mallcells\u001b[39m\u001b[38;5;124m'\u001b[39m], \u001b[38;5;241m99\u001b[39m)\n",
      "\u001b[1;31mKeyError\u001b[0m: (slice(None, None, None), None)"
     ]
    }
   ],
   "source": [
    "f, axes = plt.subplots(1, 2, sharey=True)\n",
    "im = axes[0].imshow(np.repeat(lmi[mouse_id][:, np.newaxis], 10, axis=1), cmap='viridis', vmin=-1, vmax=1)\n",
    "plt.colorbar(im)\n",
    "vmax = np.percentile(pop_vectors_dict[mouse_id]['allcells'], 99)\n",
    "vmin = np.percentile(pop_vectors_dict[mouse_id]['allcells'], 1)\n",
    "im = axes[1].imshow(pop_vectors_dict[mouse_id]['allcells'], cmap='viridis', vmin=vmin, vmax=vmax)\n",
    "plt.colorbar(im)\n",
    "print(vmin, vmax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 Correlation during learning.\n",
    "\n",
    "When is the change of correlation triggered during D0 whisker learning?\n",
    "\n",
    "- First, plot correlation matrix with WH trials stacked with UM.\n",
    "- then point plot the correlation of each trial with the average maaping response of D+2\n",
    "- select modulated cells with LMI and plot population vectors for WH and UM. Is there a graded response? a discret change? or do they respond strong since the very first trial?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['GF305', 'GF306', 'GF307', 'GF308', 'GF310', 'GF311', 'GF313', 'GF314', 'GF317', 'GF318', 'GF319', 'GF323', 'GF333', 'GF334', 'GF348', 'GF350', 'MI062', 'MI069', 'MI072', 'MI075', 'MI076', 'AR132', 'AR133', 'AR137', 'AR139', 'AR127', 'AR143', 'AR163', 'AR177', 'AR178', 'AR179', 'AR180']\n"
     ]
    }
   ],
   "source": [
    "# Load data needed to compute before and after learning.\n",
    "\n",
    "sampling_rate = 30\n",
    "win = (1, 1.180)  # from stimulus onset to 300 ms after.\n",
    "win_length = f'{int(np.round((win[1]-win[0]) * 1000))}'  # for file naming.\n",
    "win = (int(win[0] * sampling_rate), int(win[1] * sampling_rate))\n",
    "baseline_win = (0, 1)\n",
    "baseline_win = (int(baseline_win[0] * sampling_rate), int(baseline_win[1] * sampling_rate))\n",
    "days = ['-2', '-1', '0', '+1', '+2']\n",
    "trial_type = 'W'\n",
    "plot_save_figs = False\n",
    "\n",
    "_, _, mice, _ = io.select_sessions_from_db(db_path,\n",
    "                                            nwb_dir,\n",
    "                                            two_p_imaging='yes')\n",
    "print(mice)\n",
    "# excluded_mice = ['GF307', 'GF310', 'GF333', 'MI075', 'AR144', 'AR135', 'AR163', 'MI069', 'MI072', 'AR132']\n",
    "excluded_mice = ['GF307', 'GF310', 'GF333', 'MI075', 'AR144', 'AR135', 'AR163',]\n",
    "mice = [m for m in mice if m not in excluded_mice]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['GF305_27112020_083119', 'GF305_28112020_103938', 'GF305_29112020_103331', 'GF305_30112020_110255', 'GF305_02122020_132229']\n",
      "here (133, 45, 181)\n",
      "here (133, 45, 181)\n",
      "here (133, 60, 181)\n",
      "here (133, 45, 181)\n",
      "here (133, 60, 181)\n",
      "here (133, 45, 181)\n",
      "here (133, 60, 181)\n",
      "here (133, 45, 181)\n",
      "['GF306_27112020_104436', 'GF306_28112020_125555', 'GF306_29112020_131929', 'GF306_30112020_133249', 'GF306_02122020_161611']\n",
      "here (215, 45, 181)\n",
      "here (215, 45, 181)\n",
      "here (215, 60, 181)\n",
      "here (215, 45, 181)\n",
      "here (215, 60, 181)\n",
      "here (215, 45, 181)\n",
      "here (215, 60, 181)\n",
      "here (215, 45, 181)\n",
      "['GF308_17112020_105052', 'GF308_18112020_093627', 'GF308_19112020_103527', 'GF308_20112020_122826', 'GF308_21112020_135515']\n",
      "here (147, 45, 181)\n",
      "here (147, 45, 181)\n",
      "here (147, 60, 181)\n",
      "here (147, 45, 181)\n",
      "here (147, 60, 181)\n",
      "here (147, 45, 181)\n",
      "here (147, 60, 181)\n",
      "here (147, 45, 181)\n",
      "['GF311_17112020_155501', 'GF311_18112020_151838', 'GF311_19112020_160412', 'GF311_20112020_171609', 'GF311_21112020_180049']\n",
      "here (105, 45, 181)\n",
      "here (105, 45, 181)\n",
      "here (105, 60, 181)\n",
      "here (105, 45, 181)\n",
      "here (105, 60, 181)\n",
      "here (105, 45, 181)\n",
      "here (105, 60, 181)\n",
      "here (105, 45, 181)\n",
      "['GF313_27112020_141857', 'GF313_28112020_154236', 'GF313_29112020_154625', 'GF313_30112020_154904', 'GF313_03122020_082147']\n",
      "here (164, 45, 181)\n",
      "here (164, 45, 181)\n",
      "here (164, 60, 181)\n",
      "here (164, 45, 181)\n",
      "here (164, 60, 181)\n",
      "here (164, 45, 181)\n",
      "here (164, 60, 181)\n",
      "here (164, 45, 181)\n",
      "['GF314_27112020_160459', 'GF314_28112020_171800', 'GF314_29112020_174831', 'GF314_30112020_171906', 'GF314_03122020_102249']\n",
      "here (197, 45, 181)\n",
      "here (197, 45, 181)\n",
      "here (197, 60, 181)\n",
      "here (197, 45, 181)\n",
      "here (197, 60, 181)\n",
      "here (197, 45, 181)\n",
      "here (197, 60, 181)\n",
      "here (197, 45, 181)\n",
      "['GF317_15122020_081931', 'GF317_16122020_082007', 'GF317_17122020_080715', 'GF317_18122020_104834', 'GF317_20122020_120604']\n",
      "here (146, 45, 181)\n",
      "here (146, 45, 181)\n",
      "here (146, 60, 181)\n",
      "here (146, 45, 181)\n",
      "here (146, 60, 181)\n",
      "here (146, 45, 181)\n",
      "here (146, 60, 181)\n",
      "here (146, 45, 181)\n",
      "['GF318_15122020_095616', 'GF318_16122020_095516', 'GF318_17122020_144100', 'GF318_18122020_132105', 'GF318_19122020_155806']\n",
      "here (140, 45, 181)\n",
      "here (140, 45, 181)\n",
      "here (140, 60, 181)\n",
      "here (140, 45, 181)\n",
      "here (140, 60, 181)\n",
      "here (140, 45, 181)\n",
      "here (140, 60, 181)\n",
      "here (140, 45, 181)\n",
      "['GF319_24122020_120204', 'GF319_25122020_142951', 'GF319_26122020_144746', 'GF319_27122020_135842', 'GF319_28122020_132438']\n",
      "here (154, 45, 181)\n",
      "here (154, 45, 181)\n",
      "here (154, 60, 181)\n",
      "here (154, 45, 181)\n",
      "here (154, 60, 181)\n",
      "here (154, 45, 181)\n",
      "here (154, 60, 181)\n",
      "here (154, 45, 181)\n",
      "['GF323_07012021_092005', 'GF323_08012021_083725', 'GF323_09012021_111716', 'GF323_11012021_084126', 'GF323_12012021_090219']\n",
      "here (305, 45, 181)\n",
      "here (305, 45, 181)\n",
      "here (305, 60, 181)\n",
      "here (305, 45, 181)\n",
      "here (305, 60, 181)\n",
      "here (305, 45, 181)\n",
      "here (305, 60, 181)\n",
      "here (305, 45, 181)\n",
      "['GF334_21012021_160130', 'GF334_22012021_153815', 'GF334_24012021_173019', 'GF334_25012021_163843', 'GF334_26012021_171010']\n",
      "here (130, 45, 181)\n",
      "here (130, 45, 181)\n",
      "here (130, 60, 181)\n",
      "here (130, 45, 181)\n",
      "here (130, 60, 181)\n",
      "here (130, 45, 181)\n",
      "here (130, 60, 181)\n",
      "here (130, 45, 181)\n",
      "['GF348_29052021_100151', 'GF348_30052021_110107', 'GF348_31052021_102411', 'GF348_01062021_095758', 'GF348_02062021_084344']\n",
      "here (206, 45, 181)\n",
      "here (206, 45, 181)\n",
      "here (206, 60, 181)\n",
      "here (206, 45, 181)\n",
      "here (206, 60, 181)\n",
      "here (206, 45, 181)\n",
      "here (206, 60, 181)\n",
      "here (206, 45, 181)\n",
      "['GF350_29052021_124022', 'GF350_30052021_123155', 'GF350_31052021_135001', 'GF350_01062021_122420', 'GF350_02062021_142138']\n",
      "here (211, 45, 181)\n",
      "here (211, 45, 181)\n",
      "here (211, 60, 181)\n",
      "here (211, 45, 181)\n",
      "here (211, 60, 181)\n",
      "here (211, 45, 181)\n",
      "here (211, 60, 181)\n",
      "here (211, 45, 181)\n",
      "['MI062_30092021_091006', 'MI062_01102021_091233', 'MI062_02102021_105027', 'MI062_03102021_103851', 'MI062_04102021_092339']\n",
      "here (108, 45, 181)\n",
      "here (108, 45, 181)\n",
      "here (108, 60, 181)\n",
      "here (108, 45, 181)\n",
      "here (108, 60, 181)\n",
      "here (108, 45, 181)\n",
      "here (108, 60, 181)\n",
      "here (108, 45, 181)\n",
      "['MI069_19122021_100830', 'MI069_20122021_095058', 'MI069_21122021_090648', 'MI069_22122021_090212', 'MI069_23122021_085758']\n",
      "here (218, 45, 181)\n",
      "here (218, 45, 181)\n",
      "here (218, 60, 181)\n",
      "here (218, 45, 181)\n",
      "here (218, 60, 181)\n",
      "here (218, 45, 181)\n",
      "here (218, 60, 181)\n",
      "here (218, 45, 181)\n",
      "['MI072_19122021_140553', 'MI072_20122021_125805', 'MI072_21122021_132704', 'MI072_22122021_132651', 'MI072_23122021_132111']\n",
      "here (244, 45, 181)\n",
      "here (244, 45, 181)\n",
      "here (244, 60, 181)\n",
      "here (244, 45, 181)\n",
      "here (244, 60, 181)\n",
      "here (244, 45, 181)\n",
      "here (244, 60, 181)\n",
      "here (244, 45, 181)\n",
      "['MI076_19122021_120004', 'MI076_20122021_113038', 'MI076_21122021_112146', 'MI076_22122021_114039', 'MI076_23122021_113818']\n",
      "here (268, 45, 181)\n",
      "here (268, 45, 181)\n",
      "here (268, 60, 181)\n",
      "here (268, 45, 181)\n",
      "here (268, 60, 181)\n",
      "here (268, 45, 181)\n",
      "here (268, 60, 181)\n",
      "here (268, 45, 181)\n",
      "['AR132_20240424_112338', 'AR132_20240425_102625', 'AR132_20240426_093953', 'AR132_20240427_122605', 'AR132_20240428_122206']\n",
      "here (182, 45, 181)\n",
      "here (182, 45, 181)\n",
      "here (182, 60, 181)\n",
      "here (182, 45, 181)\n",
      "here (182, 60, 181)\n",
      "here (182, 45, 181)\n",
      "here (182, 60, 181)\n",
      "here (182, 45, 181)\n",
      "['AR133_20240424_130306', 'AR133_20240425_115233', 'AR133_20240426_113430', 'AR133_20240427_142253', 'AR133_20240428_134911']\n",
      "here (144, 45, 181)\n",
      "here (144, 45, 181)\n",
      "here (144, 60, 181)\n",
      "here (144, 45, 181)\n",
      "here (144, 60, 181)\n",
      "here (144, 45, 181)\n",
      "here (144, 60, 181)\n",
      "here (144, 45, 181)\n",
      "['AR137_20240424_172627', 'AR137_20240425_170755', 'AR137_20240426_152510', 'AR137_20240427_171535', 'AR137_20240428_163224']\n",
      "here (180, 45, 181)\n",
      "here (180, 45, 181)\n",
      "here (180, 60, 181)\n",
      "here (180, 45, 181)\n",
      "here (180, 60, 181)\n",
      "here (180, 45, 181)\n",
      "here (180, 60, 181)\n",
      "here (180, 45, 181)\n",
      "['AR139_20240424_185913', 'AR139_20240425_181627', 'AR139_20240426_165725', 'AR139_20240427_183701', 'AR139_20240428_180459']\n",
      "here (138, 45, 181)\n",
      "here (138, 45, 181)\n",
      "here (138, 60, 181)\n",
      "here (138, 45, 181)\n",
      "here (138, 60, 181)\n",
      "here (138, 45, 181)\n",
      "here (138, 60, 181)\n",
      "here (138, 45, 181)\n",
      "['AR127_20240221_133407', 'AR127_20240222_152629', 'AR127_20240223_131820', 'AR127_20240224_140853', 'AR127_20240225_142858']\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[21], line 32\u001b[0m\n\u001b[0;32m     30\u001b[0m mdata_list \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m     31\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m session_id \u001b[38;5;129;01min\u001b[39;00m session_list:\n\u001b[1;32m---> 32\u001b[0m     arr, mdata \u001b[38;5;241m=\u001b[39m \u001b[43mimaging_utils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_session_2p_imaging\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmouse_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     33\u001b[0m \u001b[43m                                                        \u001b[49m\u001b[43msession_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     34\u001b[0m \u001b[43m                                                        \u001b[49m\u001b[43mprocessed_dir\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     35\u001b[0m     arr \u001b[38;5;241m=\u001b[39m imaging_utils\u001b[38;5;241m.\u001b[39msubstract_baseline(arr, \u001b[38;5;241m3\u001b[39m, baseline_win)\n\u001b[0;32m     36\u001b[0m     data\u001b[38;5;241m.\u001b[39mappend(arr)\n",
      "File \u001b[1;32mH:\\anthony\\repos\\fast-learning\\src\\utils\\utils_imaging.py:13\u001b[0m, in \u001b[0;36mload_session_2p_imaging\u001b[1;34m(mouse_id, session_id, dir_path)\u001b[0m\n\u001b[0;32m     11\u001b[0m array_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(dir_path, mouse_id, session_id, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtensor_4d.npy\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     12\u001b[0m tensor_metadata_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(dir_path, mouse_id, session_id, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtensor_4d_metadata.pickle\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 13\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43marray_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(tensor_metadata_path, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m     15\u001b[0m     metadata \u001b[38;5;241m=\u001b[39m pickle\u001b[38;5;241m.\u001b[39mload(f)\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\envs\\fast-learning\\Lib\\site-packages\\numpy\\lib\\_npyio_impl.py:488\u001b[0m, in \u001b[0;36mload\u001b[1;34m(file, mmap_mode, allow_pickle, fix_imports, encoding, max_header_size)\u001b[0m\n\u001b[0;32m    485\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mformat\u001b[39m\u001b[38;5;241m.\u001b[39mopen_memmap(file, mode\u001b[38;5;241m=\u001b[39mmmap_mode,\n\u001b[0;32m    486\u001b[0m                                   max_header_size\u001b[38;5;241m=\u001b[39mmax_header_size)\n\u001b[0;32m    487\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 488\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mformat\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mallow_pickle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mallow_pickle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    489\u001b[0m \u001b[43m                                 \u001b[49m\u001b[43mpickle_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpickle_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    490\u001b[0m \u001b[43m                                 \u001b[49m\u001b[43mmax_header_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_header_size\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    491\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    492\u001b[0m     \u001b[38;5;66;03m# Try a pickle\u001b[39;00m\n\u001b[0;32m    493\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m allow_pickle:\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\envs\\fast-learning\\Lib\\site-packages\\numpy\\lib\\format.py:836\u001b[0m, in \u001b[0;36mread_array\u001b[1;34m(fp, allow_pickle, pickle_kwargs, max_header_size)\u001b[0m\n\u001b[0;32m    833\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    834\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m isfileobj(fp):\n\u001b[0;32m    835\u001b[0m         \u001b[38;5;66;03m# We can use the fast fromfile() function.\u001b[39;00m\n\u001b[1;32m--> 836\u001b[0m         array \u001b[38;5;241m=\u001b[39m \u001b[43mnumpy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfromfile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcount\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcount\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    837\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    838\u001b[0m         \u001b[38;5;66;03m# This is not a real file. We have to read it the\u001b[39;00m\n\u001b[0;32m    839\u001b[0m         \u001b[38;5;66;03m# memory-intensive way.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    847\u001b[0m         \u001b[38;5;66;03m# not correctly instantiate zero-width string dtypes; see\u001b[39;00m\n\u001b[0;32m    848\u001b[0m         \u001b[38;5;66;03m# https://github.com/numpy/numpy/pull/6430\u001b[39;00m\n\u001b[0;32m    849\u001b[0m         array \u001b[38;5;241m=\u001b[39m numpy\u001b[38;5;241m.\u001b[39mndarray(count, dtype\u001b[38;5;241m=\u001b[39mdtype)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "corr_avg_days = {}\n",
    "corr_avg_pre_post = {}\n",
    "metadata = {}\n",
    "response_amp = {}\n",
    "pop_vectors_dict = {}\n",
    "n_trials = {}\n",
    "\n",
    "globally_responsive = {}\n",
    "responsive_p_values = {}\n",
    "\n",
    "# mice = ['GF334']\n",
    "# Load lmi dicts.\n",
    "lmi = np.load(r'\\\\sv-nas1.rcp.epfl.ch\\Petersen-Lab\\analysis\\Anthony_Renard\\data_processed\\lmi.npy', allow_pickle=True).item()\n",
    "lmi_p = np.load(r'\\\\sv-nas1.rcp.epfl.ch\\Petersen-Lab\\analysis\\Anthony_Renard\\data_processed\\lmi_p.npy', allow_pickle=True).item()\n",
    "\n",
    "\n",
    "for mouse_id in mice:\n",
    "    output_dir = fr'//sv-nas1.rcp.epfl.ch/Petersen-Lab/analysis/Anthony_Renard/analysis_output/mice/{mouse_id}'\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "\n",
    "    session_list, nwb_files, _, db_filtered = io.select_sessions_from_db(db_path,\n",
    "                                                                        nwb_dir,\n",
    "                                                                        two_p_imaging='yes',\n",
    "                                                                        subject_id=mouse_id,\n",
    "                                                                        day=days,)\n",
    "    print(session_list)\n",
    "    \n",
    "    data = []\n",
    "    mdata_list = []\n",
    "    for session_id in session_list:\n",
    "        arr, mdata = imaging_utils.load_session_2p_imaging(mouse_id,\n",
    "                                                            session_id,\n",
    "                                                            processed_dir)\n",
    "        arr = imaging_utils.substract_baseline(arr, 3, baseline_win)\n",
    "        data.append(arr)\n",
    "        mdata_list.append(mdata)\n",
    "    reward_group = io.get_reward_group_from_db(db_path, session_list[0])\n",
    "    metadata[mouse_id] = {}\n",
    "    metadata[mouse_id]['reward_group'] = reward_group\n",
    "    metadata[mouse_id]['rois'] = mdata_list[0]['rois']\n",
    "    metadata[mouse_id]['cell_types'] = mdata_list[0]['cell_types']\n",
    "    for d, mday in enumerate(mdata_list):\n",
    "        metadata[mouse_id][days[d]] = {}\n",
    "        metadata[mouse_id][days[d]]['trials'] = mdata_list[d]['trials']\n",
    "        metadata[mouse_id][days[d]]['trial_types'] = mdata_list[d]['trial_types']\n",
    "    \n",
    "    # Extract UM and WH trials.\n",
    "    if reward_group == 'R+':\n",
    "        n_um = 45\n",
    "        n_wh = 30\n",
    "    else:\n",
    "        n_um = 45\n",
    "        n_wh = 5\n",
    "\n",
    "    if trial_type == 'W':\n",
    "        n_um = 45\n",
    "        n_wh = 60\n",
    "    \n",
    "    if trial_type == 'WH':\n",
    "        # Some days have no WH trials for the mouse.\n",
    "        if mouse_id == 'AR132':\n",
    "            continue\n",
    "\n",
    "    activity = []\n",
    "    arr = imaging_utils.extract_trials(data[0], mdata_list[0], 'UM', n_trials=n_um)\n",
    "    activity.append(arr)\n",
    "    arr = imaging_utils.extract_trials(data[1], mdata_list[1], 'UM', n_trials=n_um)\n",
    "    activity.append(arr)\n",
    "    arr = imaging_utils.extract_trials(data[2], mdata_list[2], trial_type, n_trials=n_wh)\n",
    "    activity.append(arr)\n",
    "    arr = imaging_utils.extract_trials(data[2], mdata_list[2], 'UM', n_trials=n_um)\n",
    "    activity.append(arr)\n",
    "    arr = imaging_utils.extract_trials(data[3], mdata_list[3], trial_type, n_trials=n_wh)\n",
    "    activity.append(arr)\n",
    "    arr = imaging_utils.extract_trials(data[3], mdata_list[3], 'UM', n_trials=n_um)\n",
    "    activity.append(arr)\n",
    "    arr = imaging_utils.extract_trials(data[4], mdata_list[4], trial_type, n_trials=n_wh)\n",
    "    activity.append(arr)\n",
    "    arr = imaging_utils.extract_trials(data[4], mdata_list[4], 'UM', n_trials=n_um)\n",
    "    activity.append(arr)\n",
    "\n",
    "    # # Print n trials.\n",
    "    # print([arr.shape[1] for arr in activity])\n",
    "\n",
    "    corr_avg_days[mouse_id] = {}\n",
    "    corr_avg_pre_post[mouse_id] = {}\n",
    "    response_amp[mouse_id] = {}\n",
    "    pop_vectors_dict[mouse_id] = {}\n",
    "    n_trials[mouse_id] = {}\n",
    "    globally_responsive[mouse_id] = {}\n",
    "    responsive_p_values[mouse_id] = {}\n",
    "\n",
    "    for cell_type in ['allcells', 'wS2', 'wM1']:\n",
    "        # Select cell type.\n",
    "        if cell_type == 'allcells':\n",
    "            activity_subtype = activity\n",
    "        else:\n",
    "            activity_subtype = []\n",
    "            cell_type_mask = mdata_list[0]['cell_types']==cell_type\n",
    "            activity_subtype = [arr[cell_type_mask] for arr in activity]\n",
    "        \n",
    "        # strong_cells = [3,11,33,48,57,67,80,86,104,153,166,175]\n",
    "        # mask = np.ones(data_subtype[0].shape[0], dtype=bool)\n",
    "        # mask[strong_cells] = False\n",
    "        # data_subtype = [arr[mask] for arr in data_subtype]\n",
    "\n",
    "        # If no cells of the specified type, skip.\n",
    "        if activity_subtype[0].shape[0] == 0:\n",
    "            continue\n",
    "\n",
    "        # Compute average response for each trial, each day.\n",
    "        response_avg = []\n",
    "        for d in activity_subtype:\n",
    "            response_avg.append(np.nanmean(d[:, :, win[0]:win[1]], axis=2))\n",
    "        response_amp[mouse_id][cell_type] = response_avg\n",
    "        pop_vectors = np.concatenate(response_avg, axis=1)\n",
    "        pop_vectors_dict[mouse_id][cell_type] = pop_vectors\n",
    "        \n",
    "        # Compute LMI.\n",
    "        # if cell_type == 'allcells':\n",
    "        #     # pre = np.mean(np.concatenate(response_avg[0:2], axis=1), axis=1)\n",
    "        #     # post = np.mean(np.concatenate((response_avg[5], response_avg[7]), axis=1), axis=1)\n",
    "        #     # lmi[mouse_id] = (post - pre) / (np.abs(post) + np.abs(pre))\n",
    "        #     # lmis = []\n",
    "        #     # for icell in range(pop_vectors.shape[0]):\n",
    "        #     #     # mapping trials of D-2, D-1, D+1, D+2.\n",
    "        #     #     X = np.r_[response_avg[0][icell],\n",
    "        #     #               response_avg[1][icell],\n",
    "        #     #               response_avg[5][icell],\n",
    "        #     #               response_avg[7][icell]]\n",
    "        #     #     y = np.r_[np.zeros(response_avg[0][icell].shape[0]),\n",
    "        #     #               np.zeros(response_avg[1][icell].shape[0]),\n",
    "        #     #               np.ones(response_avg[5][icell].shape[0]),\n",
    "        #     #               np.ones(response_avg[7][icell].shape[0])]\n",
    "        #     #     fpr, tpr, _ = roc_curve(y, X)\n",
    "        #     #     roc_auc = auc(fpr, tpr)\n",
    "        #     #     lmis.append((roc_auc - 0.5) * 2)\n",
    "        #     # lmi[mouse_id] = np.array(lmis)\n",
    "\n",
    "        #     pre = np.concatenate(response_avg[0:2], axis=1)\n",
    "        #     post = np.concatenate((response_avg[5], response_avg[7]), axis=1)\n",
    "        #     lmi[mouse_id]['allcells'], lmi_p[mouse_id]['allcells'] = imaging_utils.compute_lmi(pre, post, nshuffles=None)\n",
    "        # else:\n",
    "        #     lmi[mouse_id][cell_type] = lmi[mouse_id]['allcells'][metadata[mouse_id]['cell_types'] == cell_type]\n",
    "\n",
    "\n",
    "        #  # Test responsiveness.\n",
    "        # if cell_type == 'allcells':\n",
    "        #     base = []\n",
    "        #     resp = []\n",
    "        #     activity_UM = [activity_subtype[i] for i in [0,1,3,5,7]]\n",
    "        #     for day in activity_UM:\n",
    "        #         base.append(np.nanmean(day[:, :, baseline_win[0]:baseline_win[1]], axis=2))\n",
    "        #         resp.append(np.nanmean(day[:, :, win[0]:win[1]], axis=2))\n",
    "\n",
    "        #     # Test global responsiveness by pulling trials of all days together.\n",
    "        #     n_cells = base[0].shape[0]\n",
    "        #     base = np.concatenate(base, axis=1)\n",
    "        #     resp = np.concatenate(resp, axis=1)\n",
    "        #     p_values = np.zeros(n_cells)\n",
    "        #     for icell in range(n_cells):\n",
    "        #         if np.all(base[icell] == 0) or np.all(resp[icell] == 0):\n",
    "        #             p_values[icell] = 1\n",
    "        #         else:\n",
    "        #             _, p_values[icell] = wilcoxon(base[icell], resp[icell])\n",
    "        #             globally_responsive[mouse_id][cell_type] = p_values\n",
    "        # else:\n",
    "        #     globally_responsive[mouse_id][cell_type] = globally_responsive[mouse_id]['allcells'][metadata[mouse_id]['cell_types'] == cell_type]\n",
    "\n",
    "\n",
    "        if plot_save_figs:\n",
    "            corr_matrix = np.corrcoef(pop_vectors.T)\n",
    "            # corr_matrix = cosine_similarity(pop_vectors.T)\n",
    "            # corr_matrix = spearmanr(pop_vectors.T, axis=1)[0]\n",
    "\n",
    "            # Compute average correlation inside each days.\n",
    "            corr_avg_days[mouse_id][cell_type] = []\n",
    "            n_trials[mouse_id] = [arr.shape[1] for arr in activity_subtype]\n",
    "            for start, end in zip(np.cumsum([0] + n_trials[mouse_id][:-1]), np.cumsum(n_trials[mouse_id])):\n",
    "                upper_triangle = np.triu(corr_matrix[start:end, start:end], k=1)\n",
    "                corr_avg_days[mouse_id][cell_type].append(np.mean(upper_triangle))\n",
    "\n",
    "            # Compare correlation between inside pre training days,\n",
    "            # inside post training days and between pre and post training days.\n",
    "            trial_cumsum = np.cumsum([0] + n_trials[mouse_id])\n",
    "            pre_in_start_x, pre_in_end_x = trial_cumsum[1], trial_cumsum[2]\n",
    "            pre_in_start_y, pre_in_end_y = trial_cumsum[0], trial_cumsum[1]\n",
    "            pre_in = np.mean(corr_matrix[pre_in_start_x:pre_in_end_x, pre_in_start_y:pre_in_end_y])\n",
    "\n",
    "            post_in_start_x, post_in_end_x = trial_cumsum[4], trial_cumsum[5]\n",
    "            post_in_start_y, post_in_end_y = trial_cumsum[3], trial_cumsum[4]\n",
    "            post_in = np.mean(corr_matrix[post_in_start_x:post_in_end_x, post_in_start_y:post_in_end_y])\n",
    "\n",
    "            pre_post_start_x, pre_post_end_x = trial_cumsum[3], trial_cumsum[5]\n",
    "            pre_post_start_y, pre_post_end_y = trial_cumsum[0], trial_cumsum[2]\n",
    "            pre_post = np.mean(corr_matrix[pre_post_start_x:pre_post_end_x, pre_post_start_y:pre_post_end_y])\n",
    "\n",
    "            corr_avg_pre_post[mouse_id][cell_type] = [pre_in, post_in, pre_post]\n",
    "\n",
    "\n",
    "            # Plot population vectors.\n",
    "            pdf_file = f'pop_vectors_learning_and_mapping_{mouse_id}_{cell_type}_{trial_type}.pdf'\n",
    "            with PdfPages(os.path.join(output_dir, pdf_file)) as pdf:\n",
    "                vmax = np.percentile(pop_vectors, 99)\n",
    "                vmin = np.percentile(pop_vectors, 1)\n",
    "\n",
    "                f = plt.figure()\n",
    "                im = plt.imshow(pop_vectors, cmap='viridis', vmin=vmin, vmax=vmax)\n",
    "                cbar = f.colorbar(im, ticks=[vmin, 0, vmax])\n",
    "                cbar.ax.set_yticklabels([f'{vmin:.2f}', '0', f'> {vmax:.2f}'])\n",
    "                cbar.ax.tick_params(size=0)\n",
    "                pdf.savefig(dpi=300)\n",
    "                plt.close()\n",
    "\n",
    "            # Plot correlation matrix.\n",
    "            pdf_file = f'correlation_matrices_learning_and_mapping_{mouse_id}_{cell_type}_{trial_type}.pdf'            \n",
    "            with PdfPages(os.path.join(output_dir, pdf_file)) as pdf:\n",
    "                \n",
    "                # Set color map limit to the max without the diagonal.\n",
    "                vmax = np.max(corr_matrix[~np.eye(corr_matrix.shape[0], dtype=bool)])\n",
    "                vmin = np.min(corr_matrix)\n",
    "                f = plt.figure()\n",
    "                im = plt.imshow(corr_matrix, vmin = vmin, vmax=vmax, cmap='viridis')\n",
    "                n_trials[mouse_id] = [arr.shape[1] for arr in activity]\n",
    "                for i in np.cumsum(n_trials[mouse_id])[:-1]:\n",
    "                    plt.axvline(x=i-1, color='#252525', linestyle='-', lw=0.5)\n",
    "                    plt.axhline(y=i-1, color='#252525', linestyle='-', lw=0.5)\n",
    "                if cell_type:\n",
    "                    plt.title(f'{mouse_id} {reward_group} {cell_type}')\n",
    "                else:\n",
    "                    plt.title(f'{mouse_id} {reward_group} all cells')\n",
    "                cbar_ax = f.add_axes([0.85, 0.15, 0.05, 0.7])\n",
    "                cbar = f.colorbar(im, cax=cbar_ax, ticks=[vmin, 0, vmax])\n",
    "                cbar.ax.set_yticklabels([f'{vmin:.2f}', '0', f'> {vmax:.2f}'])\n",
    "                cbar.ax.tick_params(size=0)\n",
    "                pdf.savefig(dpi=300)\n",
    "                plt.close()\n",
    "\n",
    "# Load lmi dicts.\n",
    "# lmi = {}  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "lmi = np.load(r'\\\\sv-nas1.rcp.epfl.ch\\Petersen-Lab\\analysis\\Anthony_Renard\\data_processed\\lmi.npy', allow_pickle=True).item()\n",
    "lmi_p = np.load(r'\\\\sv-nas1.rcp.epfl.ch\\Petersen-Lab\\analysis\\Anthony_Renard\\data_processed\\lmi_p.npy', allow_pickle=True).item()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Construction population vectors.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rewarded_mice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "# responsive_thr = 0.001\n",
    "# lmi_percentile_top = 90\n",
    "# lmi_percentile_bottom = 10\n",
    "\n",
    "rewarded_mice = [mouse_id for mouse_id in pop_vectors_dict.keys() if metadata[mouse_id]['reward_group']=='R+']\n",
    "unrewarded_mice = [mouse_id for mouse_id in pop_vectors_dict.keys() if metadata[mouse_id]['reward_group']=='R-']\n",
    "# unrewarded_mice = [m for m in unrewarded_mice if m not in ['MI069', 'MI072', 'AR143']]\n",
    "\n",
    "\n",
    "# # # Compute the LMI thresholds for the top 5% most modulated cells and bottom 5% least modulated cells\n",
    "# lmi_thr_rew_top = np.percentile(np.concatenate([lmi[mouse_id]['allcells'] for mouse_id in rewarded_mice]), lmi_percentile_top)\n",
    "# lmi_thr_rew_bottom = np.percentile(np.concatenate([lmi[mouse_id]['allcells'] for mouse_id in rewarded_mice]), lmi_percentile_bottom)\n",
    "# lmi_thr_unrew_top = np.percentile(np.concatenate([lmi[mouse_id]['allcells'] for mouse_id in unrewarded_mice]), lmi_percentile_top)\n",
    "# lmi_thr_unrew_bottom = np.percentile(np.concatenate([lmi[mouse_id]['allcells'] for mouse_id in unrewarded_mice]), lmi_percentile_bottom)\n",
    "\n",
    "rewarded_pop_vectors = np.concatenate(\n",
    "    [pop_vectors_dict[mouse_id]['allcells'] for mouse_id in rewarded_mice], axis=0)\n",
    "unrewarded_pop_vectors = np.concatenate(\n",
    "    [pop_vectors_dict[mouse_id]['allcells'] for mouse_id in unrewarded_mice], axis=0)\n",
    "\n",
    "rewarded_pop_vectors_wS2 = np.concatenate(\n",
    "    [pop_vectors_dict[mouse_id]['wS2'] for mouse_id in rewarded_mice if 'wS2' in pop_vectors_dict[mouse_id].keys()], axis=0)\n",
    "unrewarded_pop_vectors_wS2 = np.concatenate(\n",
    "    [pop_vectors_dict[mouse_id]['wS2'] for mouse_id in unrewarded_mice if 'wS2' in pop_vectors_dict[mouse_id].keys()], axis=0)\n",
    "\n",
    "rewarded_pop_vectors_wM1 = np.concatenate(\n",
    "    [pop_vectors_dict[mouse_id]['wM1'] for mouse_id in rewarded_mice if 'wM1' in pop_vectors_dict[mouse_id].keys()], axis=0)\n",
    "unrewarded_pop_vectors_wM1 = np.concatenate(\n",
    "    [pop_vectors_dict[mouse_id]['wM1'] for mouse_id in unrewarded_mice if 'wM1' in pop_vectors_dict[mouse_id].keys()], axis=0)\n",
    "\n",
    "\n",
    "# Select the top most modulated cells and bottom least modulated cells for each rewarded mouse\n",
    "rewarded_pop_vectors_top = np.concatenate(\n",
    "    [pop_vectors_dict[mouse_id]['allcells'][lmi_p[mouse_id]['allcells'] > 0.975] for mouse_id in rewarded_mice], axis=0\n",
    ")\n",
    "rewarded_pop_vectors_bottom = np.concatenate(\n",
    "    [pop_vectors_dict[mouse_id]['allcells'][lmi_p[mouse_id]['allcells'] < 0.025] for mouse_id in rewarded_mice], axis=0\n",
    ")\n",
    "rewarded_pop_vectors_lmi = np.concatenate((rewarded_pop_vectors_top, rewarded_pop_vectors_bottom))\n",
    "rewarded_pop_vectors_lmi_wS2_top = np.concatenate(\n",
    "    [pop_vectors_dict[mouse_id]['wS2'][lmi_p[mouse_id]['wS2'] > 0.975] for mouse_id in rewarded_mice if 'wS2' in lmi_p[mouse_id].keys()], axis=0\n",
    ")\n",
    "rewarded_pop_vectors_lmi_wM1_top = np.concatenate(\n",
    "    [pop_vectors_dict[mouse_id]['wM1'][lmi_p[mouse_id]['wM1'] > 0.975] for mouse_id in rewarded_mice if 'wM1' in lmi_p[mouse_id].keys()], axis=0\n",
    ")\n",
    "rewarded_pop_vectors_lmi_wS2_bottom = np.concatenate(\n",
    "    [pop_vectors_dict[mouse_id]['wS2'][lmi_p[mouse_id]['wS2'] < 0.025] for mouse_id in rewarded_mice if 'wS2' in lmi_p[mouse_id].keys()], axis=0\n",
    ")\n",
    "rewarded_pop_vectors_lmi_wM1_bottom = np.concatenate(\n",
    "    [pop_vectors_dict[mouse_id]['wM1'][lmi_p[mouse_id]['wM1'] < 0.025] for mouse_id in rewarded_mice if 'wM1' in lmi_p[mouse_id].keys()], axis=0\n",
    ")\n",
    "rewarded_pop_vectors_lmi_wS2 = np.concatenate((rewarded_pop_vectors_lmi_wS2_top, rewarded_pop_vectors_lmi_wS2_bottom))\n",
    "rewarded_pop_vectors_lmi_wM1 = np.concatenate((rewarded_pop_vectors_lmi_wM1_top, rewarded_pop_vectors_lmi_wM1_bottom))\n",
    "\n",
    "# Select the top 5% most modulated cells and bottom 5% least modulated cells for each unrewarded mouse\n",
    "unrewarded_pop_vectors_top = np.concatenate(\n",
    "    [pop_vectors_dict[mouse_id]['allcells'][lmi_p[mouse_id]['allcells'] > 0.975] for mouse_id in unrewarded_mice], axis=0\n",
    ")\n",
    "unrewarded_pop_vectors_bottom = np.concatenate(\n",
    "    [pop_vectors_dict[mouse_id]['allcells'][lmi_p[mouse_id]['allcells'] < 0.025] for mouse_id in unrewarded_mice], axis=0\n",
    ")\n",
    "unrewarded_pop_vectors_lmi = np.concatenate((unrewarded_pop_vectors_top, unrewarded_pop_vectors_bottom))\n",
    "unrewarded_pop_vectors_lmi_wS2_top = np.concatenate(\n",
    "    [pop_vectors_dict[mouse_id]['wS2'][lmi_p[mouse_id]['wS2'] > 0.975] for mouse_id in unrewarded_mice if 'wS2' in lmi[mouse_id].keys()], axis=0\n",
    ")\n",
    "unrewarded_pop_vectors_lmi_wM1_top = np.concatenate(\n",
    "    [pop_vectors_dict[mouse_id]['wM1'][lmi_p[mouse_id]['wM1'] > 0.975] for mouse_id in unrewarded_mice if 'wM1' in lmi[mouse_id].keys()], axis=0\n",
    ")\n",
    "unrewarded_pop_vectors_lmi_wS2_bottom = np.concatenate(\n",
    "    [pop_vectors_dict[mouse_id]['wS2'][lmi_p[mouse_id]['wS2'] < 0.025] for mouse_id in unrewarded_mice if 'wS2' in lmi[mouse_id].keys()], axis=0\n",
    ")\n",
    "unrewarded_pop_vectors_lmi_wM1_bottom = np.concatenate(\n",
    "    [pop_vectors_dict[mouse_id]['wM1'][lmi_p[mouse_id]['wM1'] < 0.025] for mouse_id in unrewarded_mice if 'wM1' in lmi[mouse_id].keys()], axis=0\n",
    ")\n",
    "unrewarded_pop_vectors_lmi_wS2 = np.concatenate((unrewarded_pop_vectors_lmi_wS2_top, unrewarded_pop_vectors_lmi_wS2_bottom))\n",
    "unrewarded_pop_vectors_lmi_wM1 = np.concatenate((unrewarded_pop_vectors_lmi_wM1_top, unrewarded_pop_vectors_lmi_wM1_bottom))\n",
    "\n",
    "\n",
    "# # Responsive cells\n",
    "# # Select the top 5% most modulated cells and bottom 5% least modulated cells for each rewarded mouse\n",
    "# rewarded_pop_vectors_responsive = np.concatenate(\n",
    "#     [pop_vectors_dict[mouse_id]['allcells'][globally_responsive[mouse_id]['allcells'] < responsive_thr] for mouse_id in rewarded_mice], axis=0)\n",
    "# unrewarded_pop_vectors_responsive = np.concatenate(\n",
    "#     [pop_vectors_dict[mouse_id]['allcells'][globally_responsive[mouse_id]['allcells'] < responsive_thr] for mouse_id in unrewarded_mice], axis=0)\n",
    "\n",
    "# # Responsive cells\n",
    "# # Select the top 5% most modulated cells and bottom 5% least modulated cells for each rewarded mouse\n",
    "# rewarded_pop_vectors_responsive_wS2 = np.concatenate(\n",
    "#     [pop_vectors_dict[mouse_id]['wS2'][globally_responsive[mouse_id]['wS2'] < responsive_thr] for mouse_id in rewarded_mice if 'wS2' in globally_responsive[mouse_id].keys()], axis=0)\n",
    "# unrewarded_pop_vectors_responsive_wS2 = np.concatenate(\n",
    "#     [pop_vectors_dict[mouse_id]['wS2'][globally_responsive[mouse_id]['wS2'] < responsive_thr] for mouse_id in unrewarded_mice if 'wS2' in globally_responsive[mouse_id].keys()], axis=0)\n",
    "\n",
    "# # Responsive cells\n",
    "# # Select the top 5% most modulated cells and bottom 5% least modulated cells for each rewarded mouse\n",
    "# rewarded_pop_vectors_responsive_wM1 = np.concatenate(\n",
    "#     [pop_vectors_dict[mouse_id]['wM1'][globally_responsive[mouse_id]['wM1'] < responsive_thr] for mouse_id in rewarded_mice if 'wM1' in globally_responsive[mouse_id].keys()], axis=0)\n",
    "# unrewarded_pop_vectors_responsive_wM1 = np.concatenate(\n",
    "#     [pop_vectors_dict[mouse_id]['wM1'][globally_responsive[mouse_id]['wM1'] < responsive_thr] for mouse_id in unrewarded_mice if 'wM1' in globally_responsive[mouse_id].keys()], axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Population matrices with learning. For all cells, modulated cells or responsive cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aprenard\\AppData\\Local\\Temp\\ipykernel_33704\\3108701476.py:24: UserWarning: Adding colorbar to a different Figure <Figure size 1111.25x815.5 with 2 Axes> than <Figure size 2616.25x2056.25 with 2 Axes> which fig.colorbar is called on.\n",
      "  cbar = f.colorbar(im, ticks=[vmin, 0, vmax])\n",
      "C:\\Users\\aprenard\\AppData\\Local\\Temp\\ipykernel_33704\\3108701476.py:41: UserWarning: Adding colorbar to a different Figure <Figure size 1111.25x815.5 with 2 Axes> than <Figure size 2616.25x2056.25 with 2 Axes> which fig.colorbar is called on.\n",
      "  cbar = f.colorbar(im, ticks=[vmin, 0, vmax])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([<matplotlib.axis.YTick at 0x1e865fa6360>,\n",
       "  <matplotlib.axis.YTick at 0x1e865fa5f70>,\n",
       "  <matplotlib.axis.YTick at 0x1e865e8a4e0>,\n",
       "  <matplotlib.axis.YTick at 0x1e800ccb2f0>,\n",
       "  <matplotlib.axis.YTick at 0x1e800cc9250>,\n",
       "  <matplotlib.axis.YTick at 0x1e8052c5b20>,\n",
       "  <matplotlib.axis.YTick at 0x1e800cc9280>],\n",
       " [Text(0, 44.5, '45'),\n",
       "  Text(0, 89.5, '90'),\n",
       "  Text(0, 129.5, '130'),\n",
       "  Text(0, 174.5, '175'),\n",
       "  Text(0, 214.5, '215'),\n",
       "  Text(0, 259.5, '260'),\n",
       "  Text(0, 299.5, '300')])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zscore = False\n",
    "\n",
    "# Subset of cells.\n",
    "vectors_rew = rewarded_pop_vectors_lmi_wM1\n",
    "vectors_unrew = unrewarded_pop_vectors_lmi_wM1\n",
    "\n",
    "n_trial_um = 45\n",
    "n_trial_rew = 40\n",
    "n_trial_nonrew = 40\n",
    "\n",
    "if zscore:\n",
    "    vectors_rew = (vectors_rew - np.mean(vectors_rew, axis=1, keepdims=True)) / np.std(vectors_rew, axis=1, keepdims=True)\n",
    "    vectors_unrew = (vectors_unrew - np.mean(vectors_unrew, axis=1, keepdims=True)) / np.std(vectors_unrew, axis=1, keepdims=True)\n",
    "    vectors_rew = np.nan_to_num(vectors_rew)\n",
    "    vectors_unrew = np.nan_to_num(vectors_unrew)\n",
    "\n",
    "block_edges_rew = np.cumsum([n_trial_um, n_trial_um, n_trial_rew, n_trial_um, n_trial_rew, n_trial_um, n_trial_rew, n_trial_um])\n",
    "corr_matrix = np.corrcoef(vectors_rew.T)\n",
    "vmax = np.percentile(corr_matrix[~np.eye(corr_matrix.shape[0], dtype=bool)], 99.5)\n",
    "vmin = np.percentile(corr_matrix, .5)\n",
    "\n",
    "plt.figure()\n",
    "im = plt.imshow(corr_matrix, cmap='viridis', vmin=vmin, vmax=vmax)\n",
    "cbar = f.colorbar(im, ticks=[vmin, 0, vmax])\n",
    "cbar.ax.set_yticklabels([f'{vmin:.2f}', '0', f'> {vmax:.2f}'])\n",
    "cbar.ax.tick_params(size=0)\n",
    "\n",
    "for i in block_edges_rew-0.5:\n",
    "    plt.axvline(x=i, color='white', linestyle='--', linewidth=1)\n",
    "    plt.axhline(y=i, color='white', linestyle='--', linewidth=1)\n",
    "plt.xticks(block_edges_rew-0.5, block_edges_rew)\n",
    "plt.yticks(block_edges_rew-0.5, block_edges_rew)\n",
    "\n",
    "block_edges_unrew = np.cumsum([n_trial_um, n_trial_um, n_trial_nonrew, n_trial_um, n_trial_nonrew, n_trial_um, n_trial_nonrew, n_trial_um])[:-1]\n",
    "corr_matrix = np.corrcoef(vectors_unrew.T)\n",
    "vmax = np.percentile(corr_matrix[~np.eye(corr_matrix.shape[0], dtype=bool)], 99.5)\n",
    "vmin = np.percentile(corr_matrix, .5)\n",
    "\n",
    "plt.figure()\n",
    "im = plt.imshow(corr_matrix, cmap='viridis', vmin=vmin, vmax=vmax)\n",
    "cbar = f.colorbar(im, ticks=[vmin, 0, vmax])\n",
    "cbar.ax.set_yticklabels([f'{vmin:.2f}', '0', f'> {vmax:.2f}'])\n",
    "cbar.ax.tick_params(size=0)\n",
    "\n",
    "for i in block_edges_unrew-0.5:\n",
    "    plt.axvline(x=i, color='white', linestyle='--', linewidth=1)\n",
    "    plt.axhline(y=i, color='white', linestyle='--', linewidth=1)\n",
    "plt.xticks(block_edges_unrew-0.5, block_edges_unrew)\n",
    "plt.yticks(block_edges_unrew-0.5, block_edges_unrew)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Population vector plot on the stim for the modulated cells. For WH and UM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(700, 240)"
      ]
     },
     "execution_count": 334,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Modulated cells -- R-')"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if wh_trial_type == 'WH':\n",
    "    block_edges_rew = np.cumsum([45, 45, 30, 45, 30, 45, 30, 45])[:-1]\n",
    "    block_edges_unrew = np.cumsum([45, 45, 5, 45, 5, 45, 5, 45])[:-1]\n",
    "elif wh_trial_type == 'WM':\n",
    "    block_edges_rew = np.cumsum([45, 45, 30, 45, 30, 45, 30, 45])[:-1]\n",
    "    block_edges_unrew = np.cumsum([45, 45, 10, 45, 10, 45, 10, 45])[:-1]\n",
    "elif wh_trial_type == 'W':\n",
    "    block_edges_rew = np.cumsum([45, 45, 40, 45, 40, 45, 40, 45])[:-1]\n",
    "    block_edges_unrew = np.cumsum([45, 45, 40, 45, 40, 45, 40, 45])[:-1]\n",
    "\n",
    "\n",
    "vmax = np.percentile(rewarded_pop_vectors_top, 99)\n",
    "vmin = np.percentile(rewarded_pop_vectors_top, 1)\n",
    "\n",
    "plt.figure()\n",
    "plt.imshow(rewarded_pop_vectors, cmap='viridis', vmin=vmin, vmax=vmax)\n",
    "for i in block_edges_rew-0.5:\n",
    "    plt.axvline(x=i, color='white', linestyle='--', linewidth=1)\n",
    "plt.xticks(block_edges_rew-0.5, block_edges_rew)\n",
    "plt.colorbar()\n",
    "plt.show()\n",
    "plt.title('Positively modulated cells for each mouse -- R+')\n",
    "\n",
    "\n",
    "\n",
    "# Plot for the top 5% positively modulated cells -- R-\n",
    "vmax = np.percentile(unrewarded_pop_vectors_top, 99)\n",
    "vmin = np.percentile(unrewarded_pop_vectors_top, 1)\n",
    "plt.figure()\n",
    "plt.imshow(unrewarded_pop_vectors, cmap='viridis', vmin=vmin, vmax=vmax)\n",
    "for i in block_edges_unrew-0.5:\n",
    "    plt.axvline(x=i, color='white', linestyle='--', linewidth=1)\n",
    "plt.xticks(block_edges_unrew-0.5, block_edges_unrew)\n",
    "plt.colorbar()\n",
    "plt.show()\n",
    "plt.title('Modulated cells -- R-')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scatter plot of the correlation of each D0 WH with post learning UM.\n",
    "\n",
    "First have a look with the global population."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 45  90 130 175 215 260 300]\n"
     ]
    }
   ],
   "source": [
    "sns.set_theme(context='paper', style='ticks', palette='deep', font='sans-serif', font_scale=1)\n",
    "\n",
    "vectors = rewarded_pop_vectors\n",
    "\n",
    "# block_edges = np.cumsum([45, 45, 30, 45, 30, 45, 30, 45])\n",
    "block_edges = np.cumsum([45, 45, 40, 45, 40, 45, 40, 45])\n",
    "print(block_edges_rew)\n",
    "# pre = rewarded_pop_vectors[:, :block_edges_rew[0]]\n",
    "# post = rewarded_pop_vectors[:, block_edges_rew[6]:block_edges_rew[7]]\n",
    "# d0_learning = rewarded_pop_vectors[:,block_edges_rew[1]:block_edges_rew[2]]\n",
    "pre = vectors[:, :block_edges[1]]\n",
    "post1 = vectors[:,block_edges[4]:block_edges[5]]\n",
    "post2 = vectors[:,block_edges[6]:block_edges[7]]\n",
    "post = np.concatenate((post1, post2), axis=1)\n",
    "pre_vect = np.mean(pre, axis=1)\n",
    "post_vect = np.mean(post, axis=1)\n",
    "learning_direction = post_vect - pre_vect\n",
    "d0_learning = vectors[:,block_edges[1]:block_edges[2]]\n",
    "\n",
    "# correlations = []\n",
    "\n",
    "# # Average correlation each trial and all the post trials.\n",
    "# # for i in range(pre.shape[1]):\n",
    "# #     correlations.append(np.mean(np.corrcoef(pre[:,i], post.T)[1:, 0]))\n",
    "# # for i in range(d0_learning.shape[1]):\n",
    "# #     correlations.append(np.mean(np.corrcoef(d0_learning[:, i], post.T)[1:, 0]))\n",
    "# # for i in range(post.shape[1]):\n",
    "# #     correlations.append(np.mean(np.corrcoef(post[:, i], post.T)[1:, 0]))\n",
    "# # correlation = np.array(correlations)\n",
    "\n",
    "# # or correlation between each trial and the average of the post trials.\n",
    "# for i in range(pre.shape[1]):\n",
    "#     correlations.append(np.mean(np.corrcoef(pre[:,i], post_vect)[1:, 0]))\n",
    "# for i in range(d0_learning.shape[1]):\n",
    "#     correlations.append(np.mean(np.corrcoef(d0_learning[:, i], post_vect)[1:, 0]))\n",
    "# for i in range(post.shape[1]):\n",
    "#     correlations.append(np.mean(np.corrcoef(post[:, i], post_vect)[1:, 0]))\n",
    "# correlation = np.array(correlations)\n",
    "\n",
    "projections = []\n",
    "for i in range(pre.shape[1]):\n",
    "    projections.append(np.dot(pre[:,i], learning_direction))\n",
    "for i in range(d0_learning.shape[1]):\n",
    "    projections.append(np.dot(d0_learning[:, i], learning_direction))\n",
    "for i in range(post.shape[1]):\n",
    "    projections.append(np.dot(post[:, i], learning_direction))\n",
    "projections = np.array(projections)\n",
    "\n",
    "\n",
    "palette = sns.color_palette([sns.color_palette('deep')[0], '#238443'])\n",
    "# palette = sns.color_palette([sns.color_palette('deep')[0], '#d51a1c'])\n",
    "colors = [palette[0]] * pre.shape[1] + [palette[1]] * d0_learning.shape[1] + [palette[0]] * post.shape[1]\n",
    "plt.figure()\n",
    "# plt.scatter(range(correlation.shape[0]), correlation, color=colors)\n",
    "data=pd.DataFrame({'projection': projections,\n",
    "                   'trial': range(projections.shape[0]),\n",
    "                   'block': ['pre'] * pre.shape[1] + ['d0_learning'] * d0_learning.shape[1] + ['post'] * post.shape[1]})\n",
    "# sns.lmplot(data=data, x='trial', y='correlation', fit_reg=True, scatter=True, hue='block', palette=palette, ci=None)\n",
    "\n",
    "\n",
    "# from scipy.optimize import curve_fit\n",
    "# # Define the sigmoid function\n",
    "# def sigmoid(x, L, x0, k, b):\n",
    "#     return L / (1 + np.exp(-k * (x - x0))) + b\n",
    "\n",
    "# # Fit the sigmoid function to the data\n",
    "# p0 = [max(data['correlation']), np.median(data['trial']), 1, min(data['correlation'])]  # Initial guess for the parameters\n",
    "# params, _ = curve_fit(sigmoid, data['trial'], data['correlation'], p0, method='dogbox')\n",
    "\n",
    "# # Plot the fitted sigmoid curve\n",
    "plt.scatter(range(projections.shape[0]), projections, color=colors)\n",
    "# x_fit = np.linspace(min(data['trial']), max(data['trial']), 200)\n",
    "# y_fit = sigmoid(x_fit, *params)\n",
    "# plt.plot(x_fit, y_fit, label='Sigmoid fit', color='red')\n",
    "\n",
    "\n",
    "# plt.title('Correlation pretraining and D0 learning with post training -- R-')\n",
    "# edges = np.cumsum([45, 45, 30, 45, 45])\n",
    "edges = np.cumsum([45, 45, 40, 45, 45])\n",
    "plt.xticks(edges, edges)\n",
    "# plt.ylim([-0.4, 1])\n",
    "sns.despine()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Projection on learning dimension but across mice (not for global population)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aprenard\\AppData\\Local\\Temp\\ipykernel_33704\\2428410888.py:85: UserWarning: \n",
      "The palette list has fewer values (2) than needed (3) and will cycle, which may produce an uninterpretable plot.\n",
      "  sns.lineplot(data=projections_all, x='trial', y='projection', hue='block', errorbar='ci', palette=palette)\n"
     ]
    }
   ],
   "source": [
    "# Define the cell type to use: 'allcells', 'responsive', or 'lmi'\n",
    "cell_type_to_use = 'lmi'  # Change this to 'responsive' or 'lmi' as needed\n",
    "zscore = True\n",
    "\n",
    "rewarded_mice = [mouse_id for mouse_id in pop_vectors_dict.keys() if metadata[mouse_id]['reward_group']=='R+']\n",
    "unrewarded_mice = [mouse_id for mouse_id in pop_vectors_dict.keys() if metadata[mouse_id]['reward_group']=='R-']\n",
    "\n",
    "mice = unrewarded_mice\n",
    "if mice == rewarded_mice:\n",
    "    palette = sns.color_palette([sns.color_palette('deep')[0], '#238443'])\n",
    "else:\n",
    "    palette = sns.color_palette([sns.color_palette('deep')[0], '#d51a1c'])\n",
    "\n",
    "# Plot the same projection across time but for each individual mouse\n",
    "projections_all = []\n",
    "\n",
    "for mouse_id in mice:\n",
    "    if cell_type_to_use == 'allcells':\n",
    "        vectors = pop_vectors_dict[mouse_id]['allcells']\n",
    "    elif cell_type_to_use == 'responsive':\n",
    "        vectors = pop_vectors_dict[mouse_id]['allcells'][globally_responsive[mouse_id]['allcells'] < responsive_thr]\n",
    "    elif cell_type_to_use == 'lmi':\n",
    "        vectors = pop_vectors_dict[mouse_id]['allcells'][(lmi_p[mouse_id]['allcells'] >= 0.975) | (lmi_p[mouse_id]['allcells'] <= 0.025)]\n",
    "        # vectors = pop_vectors_dict[mouse_id]['allcells'][(lmi_p[mouse_id]['allcells'] >= 0.975) ]\n",
    "        # vectors = pop_vectors_dict[mouse_id]['allcells'][(lmi_p[mouse_id]['allcells'] <= 0.025)]\n",
    "\n",
    "\n",
    "\n",
    "    block_edges = np.cumsum([45, 45, 40, 45, 40, 45, 40, 45])\n",
    "    pre = vectors[:, :block_edges[1]]\n",
    "\n",
    "    post1 = vectors[:, block_edges[4]:block_edges[5]]\n",
    "    post2 = vectors[:, block_edges[6]:block_edges[7]]\n",
    "    post = np.concatenate((post1, post2), axis=1)\n",
    "    d0_learning = vectors[:, block_edges[1]:block_edges[2]]\n",
    "\n",
    "\n",
    "    # Average the 2D arrays pre and post by group of 5 vectors along axis 1\n",
    "    # avg_size = 3\n",
    "    # pre = np.concatenate([pre, np.zeros((pre.shape[0], avg_size - pre.shape[1] % avg_size))], axis=1)\n",
    "    # post = np.concatenate([post, np.zeros((post.shape[0], avg_size - post.shape[1] % avg_size))], axis=1)\n",
    "    # d0_learning = np.concatenate([d0_learning, np.zeros((d0_learning.shape[0], avg_size - d0_learning.shape[1] % avg_size))], axis=1)\n",
    "    # pre = pre.reshape(pre.shape[0], -1, avg_size).mean(axis=2)\n",
    "    # post = post.reshape(post.shape[0], -1, avg_size).mean(axis=2) \n",
    "    # d0_learning = d0_learning.reshape(d0_learning.shape[0], -1, avg_size).mean(axis=2)\n",
    "\n",
    "    # if zscore:\n",
    "    #     pre = (pre - np.mean(pre, axis=1, keepdims=True)) / np.std(pre, axis=1, keepdims=True)\n",
    "    #     post = (post - np.mean(post, axis=1, keepdims=True)) / np.std(post, axis=1, keepdims=True)\n",
    "    #     pre = np.nan_to_num(pre)\n",
    "    #     post = np.nan_to_num(post)\n",
    "    #     d0_learning = (d0_learning - np.mean(d0_learning, axis=1, keepdims=True)) / np.std(d0_learning, axis=1, keepdims=True)\n",
    "    #     d0_learning = np.nan_to_num(d0_learning)\n",
    "\n",
    "    pre_vect = np.mean(pre, axis=1)\n",
    "    post_vect = np.mean(post, axis=1)\n",
    "    learning_direction = post_vect - pre_vect\n",
    "\n",
    "\n",
    "    projections = []\n",
    "    for i in range(pre.shape[1]):\n",
    "        projection = np.dot(pre[:, i], learning_direction) / np.linalg.norm(learning_direction)\n",
    "        projections.append(projection)\n",
    "    for i in range(d0_learning.shape[1]):\n",
    "        projection = np.dot(d0_learning[:, i], learning_direction) / np.linalg.norm(learning_direction)\n",
    "        projections.append(projection)\n",
    "    for i in range(post.shape[1]):\n",
    "        projection = np.dot(post[:, i], learning_direction) / np.linalg.norm(learning_direction)\n",
    "        projections.append(projection)\n",
    "\n",
    "    projections = np.array(projections)\n",
    "\n",
    "    projections_all.append(pd.DataFrame({\n",
    "        'projection': projections,\n",
    "        'trial': range(projections.shape[0]),\n",
    "        'block': ['pre'] * pre.shape[1] + ['d0_learning'] * d0_learning.shape[1] + ['post'] * post.shape[1],\n",
    "        'mouse_id': mouse_id\n",
    "    }))\n",
    "\n",
    "projections_all = pd.concat(projections_all)\n",
    "\n",
    "\n",
    "# Plot the line plot with variance across mice\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.lineplot(data=projections_all, x='trial', y='projection', hue='block', errorbar='ci', palette=palette)\n",
    "# edges = np.cumsum([45, 45, 40, 45, 45])\n",
    "# plt.xticks(edges, edges)\n",
    "plt.title('Projection across time with variance across mice')\n",
    "sns.despine()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Amplitude of the response during D0 for positively and negatively modulated cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aprenard\\AppData\\Local\\Temp\\ipykernel_33704\\3578411985.py:38: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.\n",
      "  sns.lineplot(data=amplitude, x='trial', y='amplitude', palette=palette)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Axes: xlabel='trial', ylabel='amplitude'>"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cell_type_to_use = 'lmi'  # Change this to 'responsive' or 'lmi' as needed\n",
    "zscore = True\n",
    "\n",
    "rewarded_mice = [mouse_id for mouse_id in pop_vectors_dict.keys() if metadata[mouse_id]['reward_group']=='R+']\n",
    "unrewarded_mice = [mouse_id for mouse_id in pop_vectors_dict.keys() if metadata[mouse_id]['reward_group']=='R-']\n",
    "\n",
    "mice = rewarded_mice\n",
    "if mice == rewarded_mice:\n",
    "    palette = sns.color_palette(['#238443'])\n",
    "else:\n",
    "    palette = sns.color_palette(['#d51a1c'])\n",
    "\n",
    "block_edges = np.cumsum([45, 45, 60, 45, 60, 45, 60, 45])\n",
    "# Plot the same projection across time but for each individual mouse\n",
    "amplitude = []\n",
    "\n",
    "for mouse_id in mice:\n",
    "\n",
    "    if cell_type_to_use == 'allcells':\n",
    "        vectors = pop_vectors_dict[mouse_id]['allcells']\n",
    "    elif cell_type_to_use == 'responsive':\n",
    "        vectors = pop_vectors_dict[mouse_id]['allcells'][globally_responsive[mouse_id]['allcells'] < responsive_thr]\n",
    "    elif cell_type_to_use == 'lmi':\n",
    "        # vectors = pop_vectors_dict[mouse_id]['allcells'][(lmi_p[mouse_id]['allcells'] >= 0.975) | (lmi_p[mouse_id]['allcells'] <= 0.025)]\n",
    "        # vectors = pop_vectors_dict[mouse_id]['allcells'][(lmi_p[mouse_id]['allcells'] >= 0.975) ]\n",
    "        vectors = pop_vectors_dict[mouse_id]['allcells'][(lmi_p[mouse_id]['allcells'] <= 0.025)]\n",
    "\n",
    "    # Average activity across cells.\n",
    "    d0_learning = (vectors[:, block_edges[1]:block_edges[2]]).mean(axis=0)\n",
    "\n",
    "    amplitude.append(pd.DataFrame({\n",
    "    'amplitude': d0_learning,\n",
    "    'trial': range(d0_learning.shape[0]),\n",
    "    'mouse_id': mouse_id\n",
    "    }))\n",
    "\n",
    "amplitude = pd.concat(amplitude)\n",
    "\n",
    "sns.lineplot(data=amplitude, x='trial', y='amplitude', palette=palette)\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Same scatter plot for amplitude of the population for each trial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 45  90 120 165 195 240 270 315]\n"
     ]
    }
   ],
   "source": [
    "block_edges = np.cumsum([45, 45, 30, 45, 30, 45, 30, 45])\n",
    "# block_edges = np.cumsum([45, 45, 5, 45, 5, 45, 5, 45])\n",
    "print(block_edges)\n",
    "\n",
    "pre = rewarded_pop_vectors_wS2[:, :block_edges[1]]\n",
    "post1 = rewarded_pop_vectors_wS2[:,block_edges[4]:block_edges[5]]\n",
    "post2 = rewarded_pop_vectors_wS2[:,block_edges[6]:block_edges[7]]\n",
    "post = np.concatenate((post1, post2), axis=1)\n",
    "post_vect = np.mean(post, axis=1)\n",
    "d0_learning = rewarded_pop_vectors_wS2[:,block_edges[1]:block_edges[2]]\n",
    "\n",
    "amp = np.concatenate((np.mean(pre, axis=0), np.mean(d0_learning, axis=0), np.mean(post, axis=0)))\n",
    "\n",
    "palette = sns.color_palette([sns.color_palette('deep')[0], '#238443'])\n",
    "# palette = sns.color_palette([sns.color_palette('deep')[0], '#d51a1c'])\n",
    "colors = [palette[0]] * pre.shape[1] + [palette[1]] * d0_learning.shape[1] + [palette[0]] * post.shape[1]\n",
    "plt.figure()\n",
    "data=pd.DataFrame({'amplitude': amp,\n",
    "                   'trial': range(amp.shape[0]),\n",
    "                   'block': ['pre'] * pre.shape[1] + ['d0_learning'] * d0_learning.shape[1] + ['post'] * post.shape[1]})\n",
    "# sns.regplot(data=data, x='trial', y='amplitude', fit_reg=True, scatter=True, ci=None, order=3)\n",
    "\n",
    "# from scipy.optimize import curve_fit\n",
    "# # Define the sigmoid function\n",
    "# def sigmoid(x, L, x0, k, b):\n",
    "#     return L / (1 + np.exp(-k * (x - x0))) + b\n",
    "\n",
    "# # Fit the sigmoid function to the data\n",
    "# p0 = [max(data['amplitude']), np.median(data['trial']), 1, min(data['amplitude'])]  # Initial guess for the parameters\n",
    "# params, _ = curve_fit(sigmoid, data['trial'], data['amplitude'], p0, method='dogbox')\n",
    "\n",
    "# Plot the fitted sigmoid curve\n",
    "plt.scatter(range(amp.shape[0]), amp, color=colors)\n",
    "# x_fit = np.linspace(min(data['trial']), max(data['trial']), 200)\n",
    "# y_fit = sigmoid(x_fit, *params)\n",
    "# plt.plot(x_fit, y_fit, label='Sigmoid fit', color='red')\n",
    "\n",
    "\n",
    "plt.title('Amplitude population response pretraining and D0 learning with post training -- R+')\n",
    "edges = np.cumsum([45, 45, 30, 45, 45])\n",
    "# edges = np.cumsum([45, 45, 5, 45, 45])\n",
    "plt.xticks(edges, edges)\n",
    "# plt.ylim([-0.4, 1])\n",
    "sns.despine()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.X Quantify correlation between first WH and pre post learning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Correlation matrix for resposnive cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "cell_selection = 'responsive'\n",
    "responsiveness_thr = 0.001\n",
    "percent_best_lmi = 15\n",
    "sns.set_theme(context='paper', style='ticks', palette='deep', font='sans-serif', font_scale=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\envs\\fast-learning\\Lib\\site-packages\\numpy\\lib\\_function_base_impl.py:562: RuntimeWarning: Mean of empty slice.\n",
      "  avg = a.mean(axis, **keepdims_kw)\n",
      "c:\\ProgramData\\anaconda3\\envs\\fast-learning\\Lib\\site-packages\\numpy\\_core\\_methods.py:139: RuntimeWarning: invalid value encountered in divide\n",
      "  ret = um.true_divide(\n",
      "c:\\ProgramData\\anaconda3\\envs\\fast-learning\\Lib\\site-packages\\numpy\\lib\\_function_base_impl.py:2991: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  c = cov(x, y, rowvar, dtype=dtype)\n",
      "c:\\ProgramData\\anaconda3\\envs\\fast-learning\\Lib\\site-packages\\numpy\\lib\\_function_base_impl.py:2848: RuntimeWarning: divide by zero encountered in divide\n",
      "  c *= np.true_divide(1, fact)\n",
      "c:\\ProgramData\\anaconda3\\envs\\fast-learning\\Lib\\site-packages\\numpy\\lib\\_function_base_impl.py:2848: RuntimeWarning: invalid value encountered in multiply\n",
      "  c *= np.true_divide(1, fact)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cell type allcells\n",
      "Cell type allcells Reward group R+ Comp post: p-value = 0.3953072503151053\n",
      "Cell type allcells Reward group R- Comp post: p-value = 0.7074539677020747\n",
      "Cell type wS2\n",
      "Cell type wS2 Reward group R+ Comp post: p-value = 1.0\n",
      "Cell type wS2 Reward group R- Comp post: p-value = 0.06495726495726495\n",
      "Cell type wM1\n",
      "Cell type wM1 Reward group R+ Comp post: p-value = 0.8852339144732017\n",
      "Cell type wM1 Reward group R- Comp post: p-value = 0.30952380952380953\n"
     ]
    }
   ],
   "source": [
    "output_dir = fr'//sv-nas1.rcp.epfl.ch/Petersen-Lab/analysis/Anthony_Renard/analysis_output/sensory_plasticity/correlation_matrices'\n",
    "pdf_file = f'correlation_first_wh_with_avg_pre_post_{win_length}_ms_cell_selection_{cell_selection}.pdf'\n",
    "\n",
    "corr_pre = {}\n",
    "corr_post = {}\n",
    "\n",
    "mice = [mouse_id for mouse_id in mice if mouse_id != 'AR132']\n",
    "\n",
    "for mouse_id in mice:\n",
    "\n",
    "    corr_pre[mouse_id] = {}\n",
    "    corr_post[mouse_id] = {}\n",
    "\n",
    "    for cell_type in ['allcells', 'wS2', 'wM1']:\n",
    "\n",
    "        if cell_type not in response_amp[mouse_id].keys():\n",
    "            continue\n",
    "        \n",
    "        if cell_selection == 'no_selection':\n",
    "            selected_cells = np.ones(response_amp[mouse_id][cell_type][0].shape[0], dtype=bool)\n",
    "        elif cell_selection == 'responsive':\n",
    "            selected_cells = globally_responsive[mouse_id][cell_type] <= responsiveness_thr\n",
    "        elif cell_selection == 'lmi':\n",
    "            lmi_thr = np.percentile(np.abs(np.concatenate([lmi[mouse_id]['allcells'] for mouse_id in mice])), 100-percent_best_lmi)\n",
    "            selected_cells = lmi[mouse_id][cell_type] >= lmi_thr\n",
    "\n",
    "        pre = np.concatenate((response_amp[mouse_id][cell_type][0][selected_cells],\n",
    "                             response_amp[mouse_id][cell_type][1][selected_cells]),\n",
    "                        axis=1)\n",
    "        # pre = np.mean(pre, axis=1)\n",
    "        post = np.concatenate((response_amp[mouse_id][cell_type][5][selected_cells],\n",
    "                                response_amp[mouse_id][cell_type][7][selected_cells]),\n",
    "                                axis=1)\n",
    "        # post = np.mean(post, axis=1)\n",
    "        first_trial = response_amp[mouse_id][cell_type][2][selected_cells, 0]\n",
    "        # first_trial = np.mean(response_amp[mouse_id][cell_type][2][selected_cells, :5], axis=1)\n",
    "\n",
    "        # Compute correlation.\n",
    "        corr_pre[mouse_id][cell_type] = np.sum(np.corrcoef(first_trial, pre.T)[0, :])\n",
    "        corr_post[mouse_id][cell_type] = np.sum(np.corrcoef(first_trial, post.T)[0, :])\n",
    "\n",
    "\n",
    "# Convert to pandas.\n",
    "# ------------------\n",
    "\n",
    "df_corr = []\n",
    "for mouse_id in mice:\n",
    "    for cell_type in corr_pre[mouse_id].keys():\n",
    "        for comp in ['pre', 'post']:\n",
    "            if comp == 'pre':\n",
    "                corr = corr_pre[mouse_id][cell_type]\n",
    "            else:\n",
    "                corr = corr_post[mouse_id][cell_type]\n",
    "            temp = pd.DataFrame([[corr, comp, cell_type, mouse_id, metadata[mouse_id]['reward_group']]],\n",
    "                            columns=['corr', 'training_phase', 'cell_type', 'mouse_id', 'reward_group'])\n",
    "            df_corr.append(temp)\n",
    "df_corr = pd.concat(df_corr, ignore_index=True)\n",
    "\n",
    "\n",
    "\n",
    "# Save plot and stats.\n",
    "# --------------------\n",
    "\n",
    "with PdfPages(os.path.join(output_dir, pdf_file)) as pdf:\n",
    "    \n",
    "    palette = sns.color_palette(['#238443', '#d51a1c'])\n",
    "    for ct in ['allcells', 'wS2', 'wM1']:\n",
    "        print(f'Cell type {ct}')\n",
    "        plt.figure()\n",
    "        sns.barplot(data=df_corr.loc[df_corr.cell_type==ct], x='training_phase', y='corr', hue='reward_group', palette=palette, hue_order=['R+', 'R-'])\n",
    "        sns.despine()\n",
    "        plt.title(f'Correlation between first trial and average pre/post training - {ct}')\n",
    "        pdf.savefig(dpi=300)\n",
    "        # plt.close()\n",
    "\n",
    "        # Perform Mann-Whitney U test to check if the difference between the two reward groups is significant for each day.\n",
    "        p_values = []\n",
    "        for reward_group in ['R+', 'R-']:\n",
    "            pre = df_corr[(df_corr['training_phase'] == 'pre') & (df_corr['reward_group'] == reward_group) & (df_corr.cell_type==ct)]['corr']\n",
    "            pre = pre[~np.isnan(pre)]\n",
    "            post = df_corr[(df_corr['training_phase'] == 'post') & (df_corr['reward_group'] == reward_group) & (df_corr.cell_type==ct)]['corr']\n",
    "            post = post[~np.isnan(post)]\n",
    "            stat, p = mannwhitneyu(pre, post)\n",
    "            print(f'Cell type {ct} Reward group {reward_group} Comp {comp}: p-value = {p}')\n",
    "            # p_values.append(p)\n",
    "        # # Add p-values to the dataframe for visualization\n",
    "        # df_p_values = pd.DataFrame({'comp': ['pre', 'post'], 'p_value': p_values, 'cell_type': ct})\n",
    "        # print(df_p_values)\n",
    "        # df_p_values.to_csv(os.path.join(output_dir, f'correlation_first_wh_with_avg_pre_post_{win_length}_ms_{cell_selection}.csv'), index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = []\n",
    "block_labels = [f'block_{i}' for i in range(1, 8)]\n",
    "\n",
    "df = []\n",
    "for mouse_id in mouse_ids:\n",
    "    for cell_type in corr_avg_days[mouse_id].keys():\n",
    "        if pop_vectors_dict[mouse_id][cell_type].shape[0] < 5:\n",
    "            continue\n",
    "        trial_boundaries = np.cumsum([0] + n_trials[mouse_id])\n",
    "        post_training = np.mean(pop_vectors_dict[mouse_id][cell_type][:, trial_boundaries[-2]:], axis=1, keepdims=True)\n",
    "        corr = np.corrcoef(pop_vectors_dict[mouse_id][cell_type], post_training, rowvar=False)[-1, :-1]\n",
    "        \n",
    "        # blocks = [i for i in range(0, 8) for _ in range(trial_boundaries[i],trial_boundaries[i+1])]\n",
    "        # trial_id_in_blocks = np.concat([np.arange(0, n_trials[mouse_id][i]) for i in range(8)])\n",
    "        # block_trial_id = [(block, trial) for block, trial in zip(blocks, trial_id_in_blocks)]\n",
    "        trial_ids = np.arange(corr.shape[0])\n",
    "\n",
    "        # multi_index = pd.MultiIndex.from_tuples([('block', 'trial_id')], names=['level_1', 'level_2'])\n",
    "        df.append(pd.DataFrame([[c, i, cell_type, mouse_id, metadata[mouse_id]['reward_group']] for c, i in zip(corr, trial_ids)],\n",
    "                            columns=['correlation', 'trial', 'cell_type', 'mouse_id', 'reward_group']))\n",
    "df = pd.concat(df, ignore_index=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.axis.XTick at 0x1fd779938c0>,\n",
       " <matplotlib.axis.XTick at 0x1fd5a1a7e60>,\n",
       " <matplotlib.axis.XTick at 0x1fd47bbafc0>,\n",
       " <matplotlib.axis.XTick at 0x1fd5d194110>,\n",
       " <matplotlib.axis.XTick at 0x1fd5d177320>,\n",
       " <matplotlib.axis.XTick at 0x1fd5d177e60>,\n",
       " <matplotlib.axis.XTick at 0x1fd5d1646b0>,\n",
       " <matplotlib.axis.XTick at 0x1fd5d165190>,\n",
       " <matplotlib.axis.XTick at 0x1fd5d194470>,\n",
       " <matplotlib.axis.XTick at 0x1fd5d165490>,\n",
       " <matplotlib.axis.XTick at 0x1fd5d166240>,\n",
       " <matplotlib.axis.XTick at 0x1fd5d166ae0>,\n",
       " <matplotlib.axis.XTick at 0x1fd5d167590>,\n",
       " <matplotlib.axis.XTick at 0x1fd5d167230>]"
      ]
     },
     "execution_count": 271,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sns.pointplot(data=df.loc[df.cell_type=='allcells'], x='trial', y='correlation', linestyles='none', errorbar=None)\n",
    "plt.ylim([-1,1])\n",
    "ax = plt.gca()\n",
    "ax.set_xticks(range(0,280,20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 260)"
      ]
     },
     "execution_count": 268,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pop_vectors_dict[mouse_id][cell_type].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(133, 315)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pop_vectors_dict[mouse_id][cell_type].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_blocks = 8\n",
    "mapping_block = [0, 1, 3, 5, 7]\n",
    "learning_block = [2, 4, 6]\n",
    "\n",
    "sns.set_theme(context='paper', style='ticks', palette='deep')\n",
    "palette = sns.color_palette()\n",
    "f, axes = plt.subplots(2, 1, figsize=(15, 6))\n",
    "\n",
    "for i in range(n_blocks):\n",
    "    if i in learning_block:\n",
    "        # color = '#238443'\n",
    "        color = 'red'\n",
    "\n",
    "    else:\n",
    "        color = '#eea429ff'\n",
    "    axes[0].scatter(range(trial_boundaries[i], trial_boundaries[i+1]),\n",
    "                    correlations[trial_boundaries[i]:trial_boundaries[i+1]],\n",
    "                    color=color)\n",
    "axes[0].set_ylim(-1, 1)\n",
    "# if apply_pca:\n",
    "#     plt.title('Correlation\\n' \\\n",
    "#               f'mice {mouse_list} ' \\\n",
    "#               f'variance retained: {variance_to_retain}')\n",
    "# else:   \n",
    "plt.title('Correlation\\n' \\\n",
    "            f'mice {mouse_id} ' \\\n",
    "            'full data (no dim reduction)')\n",
    "\n",
    "behav_table = nwb_read.get_trial_table(nwb_files[2])\n",
    "behav_table = compute_performance(behav_table, session_list[2], db_path)\n",
    "\n",
    "palette = sns.color_palette()\n",
    "plot_single_session(behav_table, session_list[2], axes[1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4 Functional maps across learning days\n",
    "\n",
    "- amplitude of response\n",
    "- significance levels (p-value maps)\n",
    "- LMI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['GF319', 'GF348', 'GF350', 'MI062', 'MI069', 'MI072', 'MI075', 'MI076', 'AR132', 'AR137', 'AR139', 'AR131']\n"
     ]
    }
   ],
   "source": [
    "# Load data needed to compute before and after learning.\n",
    "\n",
    "sampling_rate = 30\n",
    "win = (1, 1.3)  # from stimulus onset to 300 ms after.\n",
    "win = (int(win[0] * sampling_rate), int(win[1] * sampling_rate))\n",
    "baseline_win = (0, 1)\n",
    "baseline_win = (int(baseline_win[0] * sampling_rate), int(baseline_win[1] * sampling_rate))\n",
    "reward_group = 'R-'\n",
    "\n",
    "_, _, mice, _ = io.select_sessions_from_db(db_path,\n",
    "                                            nwb_dir,\n",
    "                                            two_p_imaging='yes',\n",
    "                                            reward_group=reward_group)\n",
    "print(mice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GF319\n",
      "['GF319_24122020_120204', 'GF319_25122020_142951', 'GF319_26122020_144746', 'GF319_27122020_135842', 'GF319_28122020_132438']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\envs\\fast-learning\\Lib\\site-packages\\hdmf\\spec\\namespace.py:535: UserWarning: Ignoring cached namespace 'hdmf-common' version 1.5.1 because version 1.8.0 is already loaded.\n",
      "  warn(\"Ignoring cached namespace '%s' version %s because version %s is already loaded.\"\n",
      "c:\\ProgramData\\anaconda3\\envs\\fast-learning\\Lib\\site-packages\\hdmf\\spec\\namespace.py:535: UserWarning: Ignoring cached namespace 'core' version 2.6.0-alpha because version 2.7.0 is already loaded.\n",
      "  warn(\"Ignoring cached namespace '%s' version %s because version %s is already loaded.\"\n",
      "c:\\ProgramData\\anaconda3\\envs\\fast-learning\\Lib\\site-packages\\hdmf\\spec\\namespace.py:535: UserWarning: Ignoring cached namespace 'hdmf-experimental' version 0.2.0 because version 0.5.0 is already loaded.\n",
      "  warn(\"Ignoring cached namespace '%s' version %s because version %s is already loaded.\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found image mask in plane segmentation\n",
      "GF348\n",
      "['GF348_29052021_100151', 'GF348_30052021_110107', 'GF348_31052021_102411', 'GF348_01062021_095758', 'GF348_02062021_084344']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\envs\\fast-learning\\Lib\\site-packages\\hdmf\\spec\\namespace.py:535: UserWarning: Ignoring cached namespace 'hdmf-common' version 1.5.1 because version 1.8.0 is already loaded.\n",
      "  warn(\"Ignoring cached namespace '%s' version %s because version %s is already loaded.\"\n",
      "c:\\ProgramData\\anaconda3\\envs\\fast-learning\\Lib\\site-packages\\hdmf\\spec\\namespace.py:535: UserWarning: Ignoring cached namespace 'core' version 2.6.0-alpha because version 2.7.0 is already loaded.\n",
      "  warn(\"Ignoring cached namespace '%s' version %s because version %s is already loaded.\"\n",
      "c:\\ProgramData\\anaconda3\\envs\\fast-learning\\Lib\\site-packages\\hdmf\\spec\\namespace.py:535: UserWarning: Ignoring cached namespace 'hdmf-experimental' version 0.2.0 because version 0.5.0 is already loaded.\n",
      "  warn(\"Ignoring cached namespace '%s' version %s because version %s is already loaded.\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found image mask in plane segmentation\n",
      "GF350\n",
      "['GF350_29052021_124022', 'GF350_30052021_123155', 'GF350_31052021_135001', 'GF350_01062021_122420', 'GF350_02062021_142138']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\envs\\fast-learning\\Lib\\site-packages\\hdmf\\spec\\namespace.py:535: UserWarning: Ignoring cached namespace 'hdmf-common' version 1.5.1 because version 1.8.0 is already loaded.\n",
      "  warn(\"Ignoring cached namespace '%s' version %s because version %s is already loaded.\"\n",
      "c:\\ProgramData\\anaconda3\\envs\\fast-learning\\Lib\\site-packages\\hdmf\\spec\\namespace.py:535: UserWarning: Ignoring cached namespace 'core' version 2.6.0-alpha because version 2.7.0 is already loaded.\n",
      "  warn(\"Ignoring cached namespace '%s' version %s because version %s is already loaded.\"\n",
      "c:\\ProgramData\\anaconda3\\envs\\fast-learning\\Lib\\site-packages\\hdmf\\spec\\namespace.py:535: UserWarning: Ignoring cached namespace 'hdmf-experimental' version 0.2.0 because version 0.5.0 is already loaded.\n",
      "  warn(\"Ignoring cached namespace '%s' version %s because version %s is already loaded.\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found image mask in plane segmentation\n",
      "MI062\n",
      "['MI062_30092021_091006', 'MI062_01102021_091233', 'MI062_02102021_105027', 'MI062_03102021_103851', 'MI062_04102021_092339']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\envs\\fast-learning\\Lib\\site-packages\\hdmf\\spec\\namespace.py:535: UserWarning: Ignoring cached namespace 'hdmf-common' version 1.5.1 because version 1.8.0 is already loaded.\n",
      "  warn(\"Ignoring cached namespace '%s' version %s because version %s is already loaded.\"\n",
      "c:\\ProgramData\\anaconda3\\envs\\fast-learning\\Lib\\site-packages\\hdmf\\spec\\namespace.py:535: UserWarning: Ignoring cached namespace 'core' version 2.6.0-alpha because version 2.7.0 is already loaded.\n",
      "  warn(\"Ignoring cached namespace '%s' version %s because version %s is already loaded.\"\n",
      "c:\\ProgramData\\anaconda3\\envs\\fast-learning\\Lib\\site-packages\\hdmf\\spec\\namespace.py:535: UserWarning: Ignoring cached namespace 'hdmf-experimental' version 0.2.0 because version 0.5.0 is already loaded.\n",
      "  warn(\"Ignoring cached namespace '%s' version %s because version %s is already loaded.\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found image mask in plane segmentation\n",
      "MI069\n",
      "['MI069_19122021_100830', 'MI069_20122021_095058', 'MI069_21122021_090648', 'MI069_22122021_090212', 'MI069_23122021_085758']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\envs\\fast-learning\\Lib\\site-packages\\hdmf\\spec\\namespace.py:535: UserWarning: Ignoring cached namespace 'hdmf-common' version 1.5.1 because version 1.8.0 is already loaded.\n",
      "  warn(\"Ignoring cached namespace '%s' version %s because version %s is already loaded.\"\n",
      "c:\\ProgramData\\anaconda3\\envs\\fast-learning\\Lib\\site-packages\\hdmf\\spec\\namespace.py:535: UserWarning: Ignoring cached namespace 'core' version 2.6.0-alpha because version 2.7.0 is already loaded.\n",
      "  warn(\"Ignoring cached namespace '%s' version %s because version %s is already loaded.\"\n",
      "c:\\ProgramData\\anaconda3\\envs\\fast-learning\\Lib\\site-packages\\hdmf\\spec\\namespace.py:535: UserWarning: Ignoring cached namespace 'hdmf-experimental' version 0.2.0 because version 0.5.0 is already loaded.\n",
      "  warn(\"Ignoring cached namespace '%s' version %s because version %s is already loaded.\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found image mask in plane segmentation\n",
      "MI072\n",
      "['MI072_19122021_140553', 'MI072_20122021_125805', 'MI072_21122021_132704', 'MI072_22122021_132651', 'MI072_23122021_132111']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\envs\\fast-learning\\Lib\\site-packages\\hdmf\\spec\\namespace.py:535: UserWarning: Ignoring cached namespace 'hdmf-common' version 1.5.1 because version 1.8.0 is already loaded.\n",
      "  warn(\"Ignoring cached namespace '%s' version %s because version %s is already loaded.\"\n",
      "c:\\ProgramData\\anaconda3\\envs\\fast-learning\\Lib\\site-packages\\hdmf\\spec\\namespace.py:535: UserWarning: Ignoring cached namespace 'core' version 2.6.0-alpha because version 2.7.0 is already loaded.\n",
      "  warn(\"Ignoring cached namespace '%s' version %s because version %s is already loaded.\"\n",
      "c:\\ProgramData\\anaconda3\\envs\\fast-learning\\Lib\\site-packages\\hdmf\\spec\\namespace.py:535: UserWarning: Ignoring cached namespace 'hdmf-experimental' version 0.2.0 because version 0.5.0 is already loaded.\n",
      "  warn(\"Ignoring cached namespace '%s' version %s because version %s is already loaded.\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found image mask in plane segmentation\n",
      "MI075\n",
      "['MI075_19122021_152533', 'MI075_20122021_155245', 'MI075_21122021_151949', 'MI075_22122021_152806', 'MI075_23122021_150004']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\envs\\fast-learning\\Lib\\site-packages\\hdmf\\spec\\namespace.py:535: UserWarning: Ignoring cached namespace 'hdmf-common' version 1.5.1 because version 1.8.0 is already loaded.\n",
      "  warn(\"Ignoring cached namespace '%s' version %s because version %s is already loaded.\"\n",
      "c:\\ProgramData\\anaconda3\\envs\\fast-learning\\Lib\\site-packages\\hdmf\\spec\\namespace.py:535: UserWarning: Ignoring cached namespace 'core' version 2.6.0-alpha because version 2.7.0 is already loaded.\n",
      "  warn(\"Ignoring cached namespace '%s' version %s because version %s is already loaded.\"\n",
      "c:\\ProgramData\\anaconda3\\envs\\fast-learning\\Lib\\site-packages\\hdmf\\spec\\namespace.py:535: UserWarning: Ignoring cached namespace 'hdmf-experimental' version 0.2.0 because version 0.5.0 is already loaded.\n",
      "  warn(\"Ignoring cached namespace '%s' version %s because version %s is already loaded.\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found image mask in plane segmentation\n",
      "MI076\n",
      "['MI076_19122021_120004', 'MI076_20122021_113038', 'MI076_21122021_112146', 'MI076_22122021_114039', 'MI076_23122021_113818']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\envs\\fast-learning\\Lib\\site-packages\\hdmf\\spec\\namespace.py:535: UserWarning: Ignoring cached namespace 'hdmf-common' version 1.5.1 because version 1.8.0 is already loaded.\n",
      "  warn(\"Ignoring cached namespace '%s' version %s because version %s is already loaded.\"\n",
      "c:\\ProgramData\\anaconda3\\envs\\fast-learning\\Lib\\site-packages\\hdmf\\spec\\namespace.py:535: UserWarning: Ignoring cached namespace 'core' version 2.6.0-alpha because version 2.7.0 is already loaded.\n",
      "  warn(\"Ignoring cached namespace '%s' version %s because version %s is already loaded.\"\n",
      "c:\\ProgramData\\anaconda3\\envs\\fast-learning\\Lib\\site-packages\\hdmf\\spec\\namespace.py:535: UserWarning: Ignoring cached namespace 'hdmf-experimental' version 0.2.0 because version 0.5.0 is already loaded.\n",
      "  warn(\"Ignoring cached namespace '%s' version %s because version %s is already loaded.\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found image mask in plane segmentation\n",
      "AR132\n",
      "['AR132_20240424_112338', 'AR132_20240425_102625', 'AR132_20240426_093953', 'AR132_20240427_122605', 'AR132_20240428_122206']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\envs\\fast-learning\\Lib\\site-packages\\hdmf\\spec\\namespace.py:535: UserWarning: Ignoring cached namespace 'hdmf-common' version 1.5.1 because version 1.8.0 is already loaded.\n",
      "  warn(\"Ignoring cached namespace '%s' version %s because version %s is already loaded.\"\n",
      "c:\\ProgramData\\anaconda3\\envs\\fast-learning\\Lib\\site-packages\\hdmf\\spec\\namespace.py:535: UserWarning: Ignoring cached namespace 'core' version 2.6.0-alpha because version 2.7.0 is already loaded.\n",
      "  warn(\"Ignoring cached namespace '%s' version %s because version %s is already loaded.\"\n",
      "c:\\ProgramData\\anaconda3\\envs\\fast-learning\\Lib\\site-packages\\hdmf\\spec\\namespace.py:535: UserWarning: Ignoring cached namespace 'hdmf-experimental' version 0.2.0 because version 0.5.0 is already loaded.\n",
      "  warn(\"Ignoring cached namespace '%s' version %s because version %s is already loaded.\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found image mask in plane segmentation\n",
      "AR137\n",
      "['AR137_20240424_172627', 'AR137_20240425_170755', 'AR137_20240426_152510', 'AR137_20240427_171535', 'AR137_20240428_163224']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\envs\\fast-learning\\Lib\\site-packages\\hdmf\\spec\\namespace.py:535: UserWarning: Ignoring cached namespace 'hdmf-common' version 1.5.1 because version 1.8.0 is already loaded.\n",
      "  warn(\"Ignoring cached namespace '%s' version %s because version %s is already loaded.\"\n",
      "c:\\ProgramData\\anaconda3\\envs\\fast-learning\\Lib\\site-packages\\hdmf\\spec\\namespace.py:535: UserWarning: Ignoring cached namespace 'core' version 2.6.0-alpha because version 2.7.0 is already loaded.\n",
      "  warn(\"Ignoring cached namespace '%s' version %s because version %s is already loaded.\"\n",
      "c:\\ProgramData\\anaconda3\\envs\\fast-learning\\Lib\\site-packages\\hdmf\\spec\\namespace.py:535: UserWarning: Ignoring cached namespace 'hdmf-experimental' version 0.2.0 because version 0.5.0 is already loaded.\n",
      "  warn(\"Ignoring cached namespace '%s' version %s because version %s is already loaded.\"\n",
      "c:\\ProgramData\\anaconda3\\envs\\fast-learning\\Lib\\site-packages\\pynwb\\base.py:203: UserWarning: RoiResponseSeries 'F0': Length of data does not match length of timestamps. Your data may be transposed. Time should be on the 0th dimension\n",
      "  warn(\"%s '%s': Length of data does not match length of timestamps. Your data may be transposed. \"\n",
      "c:\\ProgramData\\anaconda3\\envs\\fast-learning\\Lib\\site-packages\\pynwb\\base.py:203: UserWarning: RoiResponseSeries 'F_cor': Length of data does not match length of timestamps. Your data may be transposed. Time should be on the 0th dimension\n",
      "  warn(\"%s '%s': Length of data does not match length of timestamps. Your data may be transposed. \"\n",
      "c:\\ProgramData\\anaconda3\\envs\\fast-learning\\Lib\\site-packages\\pynwb\\base.py:203: UserWarning: RoiResponseSeries 'F_raw': Length of data does not match length of timestamps. Your data may be transposed. Time should be on the 0th dimension\n",
      "  warn(\"%s '%s': Length of data does not match length of timestamps. Your data may be transposed. \"\n",
      "c:\\ProgramData\\anaconda3\\envs\\fast-learning\\Lib\\site-packages\\pynwb\\base.py:203: UserWarning: RoiResponseSeries 'dff': Length of data does not match length of timestamps. Your data may be transposed. Time should be on the 0th dimension\n",
      "  warn(\"%s '%s': Length of data does not match length of timestamps. Your data may be transposed. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found image mask in plane segmentation\n",
      "AR139\n",
      "['AR139_20240424_185913', 'AR139_20240425_181627', 'AR139_20240426_165725', 'AR139_20240427_183701', 'AR139_20240428_180459']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\envs\\fast-learning\\Lib\\site-packages\\hdmf\\spec\\namespace.py:535: UserWarning: Ignoring cached namespace 'hdmf-common' version 1.5.1 because version 1.8.0 is already loaded.\n",
      "  warn(\"Ignoring cached namespace '%s' version %s because version %s is already loaded.\"\n",
      "c:\\ProgramData\\anaconda3\\envs\\fast-learning\\Lib\\site-packages\\hdmf\\spec\\namespace.py:535: UserWarning: Ignoring cached namespace 'core' version 2.6.0-alpha because version 2.7.0 is already loaded.\n",
      "  warn(\"Ignoring cached namespace '%s' version %s because version %s is already loaded.\"\n",
      "c:\\ProgramData\\anaconda3\\envs\\fast-learning\\Lib\\site-packages\\hdmf\\spec\\namespace.py:535: UserWarning: Ignoring cached namespace 'hdmf-experimental' version 0.2.0 because version 0.5.0 is already loaded.\n",
      "  warn(\"Ignoring cached namespace '%s' version %s because version %s is already loaded.\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found image mask in plane segmentation\n",
      "AR131\n",
      "['AR131_20240301_145952', 'AR131_20240302_123034', 'AR131_20240303_171032', 'AR131_20240304_133332', 'AR131_20240305_140141']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\envs\\fast-learning\\Lib\\site-packages\\hdmf\\spec\\namespace.py:535: UserWarning: Ignoring cached namespace 'hdmf-common' version 1.5.1 because version 1.8.0 is already loaded.\n",
      "  warn(\"Ignoring cached namespace '%s' version %s because version %s is already loaded.\"\n",
      "c:\\ProgramData\\anaconda3\\envs\\fast-learning\\Lib\\site-packages\\hdmf\\spec\\namespace.py:535: UserWarning: Ignoring cached namespace 'core' version 2.6.0-alpha because version 2.7.0 is already loaded.\n",
      "  warn(\"Ignoring cached namespace '%s' version %s because version %s is already loaded.\"\n",
      "c:\\ProgramData\\anaconda3\\envs\\fast-learning\\Lib\\site-packages\\hdmf\\spec\\namespace.py:535: UserWarning: Ignoring cached namespace 'hdmf-experimental' version 0.2.0 because version 0.5.0 is already loaded.\n",
      "  warn(\"Ignoring cached namespace '%s' version %s because version %s is already loaded.\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found image mask in plane segmentation\n"
     ]
    }
   ],
   "source": [
    "output_dir = r'//sv-nas1.rcp.epfl.ch/Petersen-Lab/analysis/Anthony_Renard/analysis_output/functional_maps'\n",
    "pdf_file = f'functional_maps_{reward_group}.pdf'\n",
    "with PdfPages(os.path.join(output_dir, pdf_file)) as pdf:\n",
    "    for mouse_id in mice:\n",
    "        print(mouse_id)\n",
    "        session_list, nwb_files, _, db_filtered = io.select_sessions_from_db(db_path,\n",
    "                                                                            nwb_dir,\n",
    "                                                                            two_p_imaging='yes',\n",
    "                                                                            day=days,\n",
    "                                                                            subject_id=mouse_id)\n",
    "        print(session_list)\n",
    "        data = []\n",
    "        for session_id in session_list:\n",
    "            arr, metadata = imaging_utils.load_session_2p_imaging(mouse_id,\n",
    "                                                                session_id,\n",
    "                                                                processed_dir)\n",
    "            arr = imaging_utils.substract_baseline(arr, 3, baseline_win)\n",
    "            data.append(arr)\n",
    "\n",
    "        # Select UM trials.\n",
    "        data = [arr[:, -1] for arr in data]\n",
    "        # Remove trials with NaNs.\n",
    "        data = [arr[:, ~np.isnan(arr).all(axis=(0,2))] for arr in data]\n",
    "\n",
    "        # Load image masks.\n",
    "        roi_masks = nwb_read.get_image_mask(nwb_files[0])\n",
    "        roi_masks = np.stack(roi_masks, axis=0)\n",
    "        \n",
    "        # Compute significance map.\n",
    "        # -------------------------\n",
    "        \n",
    "        # Compute average response and baseline for each trial, each day.\n",
    "        baseline_avg = []\n",
    "        response_avg = []\n",
    "        for day in data:\n",
    "            baseline_avg.append(np.nanmean(day[:, :, baseline_win[0]:baseline_win[1]], axis=2))\n",
    "            response_avg.append(np.nanmean(day[:, :, win[0]:win[1]], axis=2))\n",
    "\n",
    "        # Compare response amplitude to baseline.\n",
    "        n_cells = data[0].shape[0]\n",
    "        p_values = [np.zeros(n_cells) for _ in range(len(data))]\n",
    "        for iday, day in enumerate(data):\n",
    "            for icell in range(n_cells):\n",
    "                _, p_values[iday][icell] = wilcoxon(baseline_avg[iday][icell], response_avg[iday][icell])\n",
    "        p_values = np.stack(p_values, axis=0)\n",
    "\n",
    "        # Categories p-values.\n",
    "        p_values_masks = np.copy(p_values)\n",
    "        p_values_masks[p_values>0.05] = 1\n",
    "        p_values_masks[p_values<=0.05] = 2\n",
    "        p_values_masks[p_values<=0.01] = 3\n",
    "        p_values_masks[p_values<=0.001] = 4\n",
    "        \n",
    "        map_significance = []\n",
    "        for iday in range(5):\n",
    "            maps = roi_masks * p_values_masks[iday, :, None, None]\n",
    "            map_significance.append(np.max(maps, axis=0))\n",
    "            \n",
    "\n",
    "        # Compute amplitude map.\n",
    "        # ----------------------\n",
    "        \n",
    "        # Compute average response amplitude for each cell.\n",
    "        response_amplitude = []\n",
    "        for day in response_avg:\n",
    "            response_amplitude.append(np.nanmean(day, axis=1))\n",
    "        response_amplitude = np.stack(response_amplitude, axis=0)\n",
    "        \n",
    "        map_amplitude = []\n",
    "        for iday in range(5):\n",
    "            maps = roi_masks * response_amplitude[iday, :, None, None]\n",
    "            map_amplitude.append(np.max(maps, axis=0))\n",
    "    \n",
    "\n",
    "        # Plot maps.\n",
    "        # ----------\n",
    "        \n",
    "        f, axes = plt.subplots(2,5, figsize=(20, 8), sharex=True, sharey=True)\n",
    "        \n",
    "        # Plot amplitude maps.\n",
    "        cmap = sns.color_palette(\"viridis\", as_cmap=True)\n",
    "        # vmin = np.nanmin(response_amplitude)\n",
    "        vmin = 0\n",
    "        vmax = np.percentile(response_amplitude, 98)\n",
    "        \n",
    "        for iday in range(5):\n",
    "            a = axes[0,iday].imshow(map_amplitude[iday],\n",
    "                                interpolation='nearest',\n",
    "                                cmap=cmap,\n",
    "                                vmin=vmin, vmax=vmax)\n",
    "        cbar_ax = f.add_axes([.91,.124,.04,.754])\n",
    "        f.colorbar(a, cax=cbar_ax, location='right')\n",
    "        \n",
    "        \n",
    "        cmap = ['white', '#d9d9d9', '#fdbb84', '#ef6548', '#990000']\n",
    "        cmap = colors.ListedColormap(cmap)\n",
    "        bounds = range(cmap.N+1)\n",
    "        norm = colors.BoundaryNorm(bounds, cmap.N)\n",
    "        # Plot responsivity maps.\n",
    "        for iday in range(5):\n",
    "            axes[1, iday].imshow(map_significance[iday], cmap=cmap, norm=norm, interpolation='nearest')\n",
    "            # axes[iday].imshow(map_significance[iday])\n",
    "            \n",
    "        plt.suptitle(mouse_id)\n",
    "        pdf.savefig()\n",
    "        plt.close()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5 Decoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 536,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['GF305', 'GF306', 'GF307', 'GF308', 'GF310', 'GF311', 'GF313', 'GF314', 'GF317', 'GF318', 'GF323', 'GF333', 'GF334', 'AR133', 'AR135', 'AR127', 'AR143', 'AR144']\n"
     ]
    }
   ],
   "source": [
    "# Load data needed to compute before and after learning.\n",
    "\n",
    "sampling_rate = 30\n",
    "win = (1, 1.180)  # from stimulus onset to 300 ms after.\n",
    "win = (int(win[0] * sampling_rate), int(win[1] * sampling_rate))\n",
    "baseline_win = (0, 1)\n",
    "baseline_win = (int(baseline_win[0] * sampling_rate), int(baseline_win[1] * sampling_rate))\n",
    "reward_group = 'R+'\n",
    "plot_save_figs = False\n",
    "days = ['-2', '-1', '0', '+1', '+2']\n",
    "wh_trial_type = 'WH'\n",
    "\n",
    "_, _, mice, _ = io.select_sessions_from_db(db_path,\n",
    "                                            nwb_dir,\n",
    "                                            two_p_imaging='yes',\n",
    "                                            reward_group=reward_group)\n",
    "print(mice)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 537,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['GF305_27112020_083119', 'GF305_28112020_103938', 'GF305_29112020_103331', 'GF305_30112020_110255', 'GF305_02122020_132229']\n",
      "['GF306_27112020_104436', 'GF306_28112020_125555', 'GF306_29112020_131929', 'GF306_30112020_133249', 'GF306_02122020_161611']\n",
      "['GF308_17112020_105052', 'GF308_18112020_093627', 'GF308_19112020_103527', 'GF308_20112020_122826', 'GF308_21112020_135515']\n",
      "['GF311_17112020_155501', 'GF311_18112020_151838', 'GF311_19112020_160412', 'GF311_20112020_171609', 'GF311_21112020_180049']\n",
      "['GF313_27112020_141857', 'GF313_28112020_154236', 'GF313_29112020_154625', 'GF313_30112020_154904', 'GF313_03122020_082147']\n",
      "['GF314_27112020_160459', 'GF314_28112020_171800', 'GF314_29112020_174831', 'GF314_30112020_171906', 'GF314_03122020_102249']\n",
      "['GF317_15122020_081931', 'GF317_16122020_082007', 'GF317_17122020_080715', 'GF317_18122020_104834', 'GF317_20122020_120604']\n",
      "['GF318_15122020_095616', 'GF318_16122020_095516', 'GF318_17122020_144100', 'GF318_18122020_132105', 'GF318_19122020_155806']\n",
      "['GF323_07012021_092005', 'GF323_08012021_083725', 'GF323_09012021_111716', 'GF323_11012021_084126', 'GF323_12012021_090219']\n",
      "['GF334_21012021_160130', 'GF334_22012021_153815', 'GF334_24012021_173019', 'GF334_25012021_163843', 'GF334_26012021_171010']\n",
      "['AR133_20240424_130306', 'AR133_20240425_115233', 'AR133_20240426_113430', 'AR133_20240427_142253', 'AR133_20240428_134911']\n",
      "['AR127_20240221_133407', 'AR127_20240222_152629', 'AR127_20240223_131820', 'AR127_20240224_140853', 'AR127_20240225_142858']\n",
      "['AR143_20240518_174556', 'AR143_20240519_141725', 'AR143_20240520_130137', 'AR143_20240521_125833', 'AR143_20240522_172846']\n"
     ]
    }
   ],
   "source": [
    "corr_avg_days = {}\n",
    "corr_avg_pre_post = {}\n",
    "metadata = {}\n",
    "pop_vectors_dict = {}\n",
    "lmi = {}\n",
    "\n",
    "# Disregard these mice as the number of trials is too low.\n",
    "mice =  [mouse for mouse in mice if mouse not in ['GF307', 'GF310', 'GF333', 'MI075', 'AR144', 'AR135']]\n",
    "\n",
    "for mouse_id in mice:\n",
    "    output_dir = fr'//sv-nas1.rcp.epfl.ch/Petersen-Lab/analysis/Anthony_Renard/analysis_output/mice/{mouse_id}'\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "\n",
    "    session_list, nwb_files, _, db_filtered = io.select_sessions_from_db(db_path,\n",
    "                                                                        nwb_dir,\n",
    "                                                                        two_p_imaging='yes',\n",
    "                                                                        subject_id=mouse_id,\n",
    "                                                                        day=days,)\n",
    "    print(session_list)\n",
    "    \n",
    "    data = []\n",
    "    mdata_list = []\n",
    "    for session_id in session_list:\n",
    "        arr, mdata = imaging_utils.load_session_2p_imaging(mouse_id,\n",
    "                                                            session_id,\n",
    "                                                            processed_dir)\n",
    "        arr = imaging_utils.substract_baseline(arr, 3, baseline_win)\n",
    "        data.append(arr)\n",
    "        mdata_list.append(mdata)\n",
    "\n",
    "    reward_group = io.get_reward_group_from_db(db_path, session_list[0])\n",
    "    metadata[mouse_id] = {}\n",
    "    metadata[mouse_id]['reward_group'] = reward_group\n",
    "    \n",
    "    # Extract UM trials.\n",
    "    for i, arr in enumerate(data):\n",
    "        arr = imaging_utils.extract_trials(arr, mdata_list[i], 'UM', n_trials=45)\n",
    "        data[i] = arr\n",
    "\n",
    "    corr_avg_days[mouse_id] = {}\n",
    "    corr_avg_pre_post[mouse_id] = {}\n",
    "    pop_vectors_dict[mouse_id] = {}\n",
    "    \n",
    "    for cell_type in ['allcells', 'wS2', 'wM1']:\n",
    "        # Select cell type.\n",
    "        if cell_type == 'allcells':\n",
    "            data_subtype = data\n",
    "        else:\n",
    "            data_subtype = []\n",
    "            cell_type_mask = mdata_list[0]['cell_types']==cell_type\n",
    "            data_subtype = [arr[cell_type_mask] for arr in data]\n",
    "\n",
    "        # if cell_type == 'allcells':  \n",
    "        #     # Example with and without strong cells for mouse AR127.\n",
    "        #     strong_cells = [3,11,33,48,57,67,80,86,104,153,166,175]\n",
    "        #     mask = np.ones(data_subtype[0].shape[0], dtype=bool)\n",
    "        #     mask[strong_cells] = False\n",
    "        #     data_subtype = [arr[mask] for arr in data_subtype]\n",
    "\n",
    "        # If no cells of the specified type, skip.\n",
    "        if data_subtype[0].shape[0] == 0:\n",
    "            continue\n",
    "\n",
    "        # Compute average response for each trial, each day.\n",
    "        \n",
    "        response_avg = []\n",
    "        for day in data_subtype:\n",
    "            response_avg.append(np.nanmean(day[:, :, win[0]:win[1]], axis=2))\n",
    "\n",
    "        pop_vectors = np.concatenate(response_avg, axis=1)\n",
    "        pop_vectors_dict[mouse_id][cell_type] = pop_vectors\n",
    "\n",
    "                # Compute LMI.\n",
    "        if cell_type == 'allcells':\n",
    "            # pre = np.mean(np.concatenate(response_avg[0:2], axis=1), axis=1)\n",
    "            # print(pre.shape)\n",
    "            # post = np.mean(np.concatenate((response_avg[5], response_avg[7]), axis=1), axis=1)\n",
    "            # lmi[mouse_id] = (post - pre) / (np.abs(post) + np.abs(pre))\n",
    "            lmis = []\n",
    "            for icell in range(pop_vectors.shape[0]):\n",
    "                # mapping trials of D-2, D-1, D+1, D+2.\n",
    "                X = np.r_[response_avg[0][icell],\n",
    "                          response_avg[1][icell],\n",
    "                          response_avg[3][icell],\n",
    "                          response_avg[4][icell]]\n",
    "                y = np.r_[np.zeros(response_avg[0][icell].shape[0]),\n",
    "                          np.zeros(response_avg[1][icell].shape[0]),\n",
    "                          np.ones(response_avg[3][icell].shape[0]),\n",
    "                          np.ones(response_avg[4][icell].shape[0])]\n",
    "                fpr, tpr, _ = roc_curve(y, X)\n",
    "                roc_auc = auc(fpr, tpr)\n",
    "                lmis.append((roc_auc - 0.5) * 2)\n",
    "            lmi[mouse_id] = np.array(lmis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 538,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "\n",
    "\n",
    "# Compute the LMI thresholds for the top 5% most modulated cells and bottom 5% least modulated cells\n",
    "percent_to_keep = range(5, 105, 5)\n",
    "\n",
    "# Initialize a list to store accuracy for each mouse\n",
    "accuracy_list = []\n",
    "for percent in percent_to_keep:\n",
    "    pop_vectors_lmi = {}\n",
    "\n",
    "    for mouse_id in mice:\n",
    "        lmi_threshold = np.percentile(np.abs(lmi[mouse_id]), percent)\n",
    "        temp = pop_vectors_dict[mouse_id]['allcells'][(np.abs(lmi[mouse_id]) <= lmi_threshold)]\n",
    "        pop_vectors_lmi[mouse_id] = temp\n",
    "\n",
    "\n",
    "    # Loop through each mouse in pop_vectors_dict\n",
    "    for mouse_id  in pop_vectors_lmi.keys():\n",
    "        # Prepare data for SVM\n",
    "        pre = pop_vectors_lmi[mouse_id][:, :90]  # First 90 trials\n",
    "        post = pop_vectors_lmi[mouse_id][:, -90:]  # Last 90 trials\n",
    "        X = np.concatenate([pre, post], axis=1)\n",
    "        y = np.concatenate([np.zeros(90), np.ones(90)])  # First 90 trials labeled as 0, last 90 trials labeled as 1\n",
    "\n",
    "        # Z-score the data\n",
    "        X = (X - np.mean(X, axis=1, keepdims=True)) / np.std(X, axis=1, keepdims=True)\n",
    "\n",
    "        # Initialize KFold with the desired number of splits\n",
    "        kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "        # List to store accuracy for each fold\n",
    "        fold_accuracies = []\n",
    "\n",
    "        # Loop through each fold\n",
    "        for train_index, test_index in kf.split(X.T):\n",
    "            X_train, X_test = X.T[train_index], X.T[test_index] \n",
    "            y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "            # Train SVM classifier\n",
    "            svm = SVC(kernel='linear')\n",
    "            svm.fit(X_train, y_train)\n",
    "\n",
    "            # Predict and evaluate\n",
    "            y_pred = svm.predict(X_test)\n",
    "            accuracy = accuracy_score(y_test, y_pred)\n",
    "            fold_accuracies.append(accuracy)\n",
    "        \n",
    "        # Calculate the average accuracy for the folds\n",
    "        avg_fold_accuracy = np.mean(fold_accuracies)\n",
    "        accuracy_list.append({'mouse_id': mouse_id, 'accuracy': avg_fold_accuracy, 'percent': 100-percent})\n",
    "\n",
    "# Convert accuracy list to DataFrame\n",
    "df_accuracy = pd.DataFrame(accuracy_list)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 539,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sns.set_theme(context='paper', style='ticks', palette='deep', font='sans-serif', font_scale=1)\n",
    "# Plot the average accuracy across mice as a function of percent\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.lineplot(data=df_accuracy, x='percent', y='accuracy', marker='o')\n",
    "plt.xlabel('Percent of cell removed')\n",
    "plt.ylabel('Average Accuracy')\n",
    "plt.title('Average Accuracy Across Mice as a Function of Percent cells removed')\n",
    "sns.despine()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 519,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "range(5, 100, 5)"
      ]
     },
     "execution_count": 519,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "percent_to_keep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fast-learning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
